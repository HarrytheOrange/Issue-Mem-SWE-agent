{
    "search_index": {
        "description_for_embedding": "Documentation fix in Optuna clarifying that trial 'step' values are zero-based for Trial.report and pruners (MedianPruner, PercentilePruner, SuccessiveHalvingPruner, HyperbandPruner), preventing off-by-one misunderstandings in warmup and resource calculations.",
        "keywords": [
            "Optuna",
            "Trial.report",
            "step parameter",
            "zero-based indexing",
            "n_warmup_steps",
            "MedianPruner",
            "PercentilePruner",
            "SuccessiveHalvingPruner",
            "HyperbandPruner",
            "off-by-one",
            "pruning behavior",
            "documentation clarification"
        ]
    },
    "agent_memory": {
        "episodic_memory": "In this incident, users of Optuna’s pruning algorithms could easily misunderstand how the 'step' argument should be numbered when reporting intermediate results via Trial.report. The pruners (MedianPruner, PercentilePruner, SuccessiveHalvingPruner, and HyperbandPruner) internally assume that 'step' starts from zero. However, this was not clearly documented, especially for parameters like n_warmup_steps and for resource calculations in SuccessiveHalvingPruner and HyperbandPruner. This ambiguity could lead to off-by-one behavior: for example, users starting step at 1 would find that warmup and pruning thresholds triggered earlier or later than expected. The pull request addressed this by updating the documentation: Trial.report now explicitly states that pruners assume zero-based steps and gives MedianPruner/n_warmup_steps as a concrete example. MedianPruner and PercentilePruner’s n_warmup_steps docs were updated to note that the feature assumes step starts at zero. SuccessiveHalvingPruner and HyperbandPruner initially got explicit notes about zero-based steps, but to avoid duplication, these were replaced with a '..seealso::' directive pointing to Trial.report, which now centralizes the zero-based step explanation. No runtime logic changed; this PR purely clarifies and centralizes documentation to prevent misinterpretations of step indexing in pruning.",
        "semantic_memory": "This case illustrates the importance of explicitly documenting indexing and counting conventions, especially for parameters named 'step', 'epoch', 'iteration', or similar. Many users naturally assume one-based counting (1, 2, 3, ...) while low-level algorithms and libraries often use zero-based indexing (0, 1, 2, ...). When these conventions are not clearly stated, it can lead to subtle off-by-one errors, particularly in features like warmup periods, pruning thresholds, or resource scheduling logic where boundary conditions matter. A good practice is to document: (1) whether a given step/epoch/index is zero-based or one-based; (2) how configuration parameters (e.g., 'n_warmup_steps') are compared to these indices (e.g., 'pruning is disabled while step < n_warmup_steps'); and (3) to centralize such explanations in one authoritative place (like Trial.report) and cross-reference it (via 'seealso' or similar mechanisms) from other relevant APIs to avoid documentation drift and duplication. Clear, centralized documentation of these conventions prevents misconfiguration and debugging churn, especially in ML/optimization frameworks where behavior is influenced by step-based logic.",
        "procedural_memory": [
            "When you see unexpected warmup, pruning, or step-based behavior in an optimization or ML framework, suspect off-by-one or indexing convention issues and verify how 'step' or similar parameters are defined.",
            "Step 1: Identify the APIs that deal with steps/iterations/epochs (e.g., Trial.report, pruner parameters like n_warmup_steps, scheduling or resource allocation logic). List where 'step' is passed, stored, and compared.",
            "Step 2: Inspect the implementation of those APIs (or their docs if you cannot change code) to determine what they assume about indexing: do they start counting steps from 0 or from 1? Look for comparisons such as 'if step < n_warmup_steps' or arrays indexed by 'step'.",
            "Step 3: Check how users are expected to call the API: in example code, tests, or existing integrations, see what initial step value they pass (0 or 1) and confirm if it matches the implementation’s assumptions.",
            "Step 4: If there is a mismatch or ambiguity between user expectations and internal assumptions, clarify the documentation. Explicitly state whether the step is zero-based or one-based, and explain any derived behavior (e.g., 'pruning is disabled while step < n_warmup_steps').",
            "Step 5: Centralize the explanation in a primary API or concept (e.g., the core 'report' method) and use cross-references (such as '..seealso::' or links) from related components (pruners, schedulers, etc.) instead of duplicating the same detailed note everywhere. This reduces the risk of documentation divergence.",
            "Step 6: Optionally, add example snippets that show correct usage and boundary behavior (e.g., a loop with step starting at 0, demonstrating when pruning starts relative to n_warmup_steps). Ensure tests and examples are consistent with the documented convention.",
            "Step 7: If possible, consider adding runtime validation or warnings (e.g., detecting typical misuses like starting at step=1) to help guide users, but prioritize documenting the convention clearly first."
        ]
    }
}