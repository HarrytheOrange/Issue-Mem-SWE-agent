{
    "search_index": {
        "description_for_embedding": "Bug fix in napari Tracks layer: when allowing unsorted track data (track_id, t, ...), only the track coordinates were being sorted by ID then time, leaving the associated properties unsorted and misaligned. The fix centralizes sorting in the track utils, stores the sort index, and applies the same ordering to properties so that each property row stays aligned with its track row.",
        "keywords": [
            "napari",
            "tracks layer",
            "track properties",
            "sorting bug",
            "track_id",
            "time dimension",
            "lexsort",
            "data and metadata alignment",
            "unsorted input",
            "properties misalignment"
        ]
    },
    "agent_memory": {
        "episodic_memory": "In this incident, the napari Tracks layer had recently been updated to accept track data that was not pre-sorted by track ID and time. The track data array was being sorted internally in the Tracks layer __init__ using np.lexsort on columns [track_id, t]. However, the corresponding track properties (metadata per row) were not sorted in the same way. This caused properties to become misaligned with the track coordinates whenever users supplied unsorted data.\n\nThe fix moved the sorting responsibility into the underlying track utility class. In the TrackData-like helper (napari/layers/tracks/_track_utils.py), the data setter now computes a sort index _order = np.lexsort((data[:, 1], data[:, 0])) and applies it to the data before validation. This sort index is stored on the object. In the properties setter, the code first copies the properties dict (to avoid mutating the caller's object), converts DataFrames to dict if needed, ensures a 'track_id' field exists, and then reorders every property array using the same self._order. This guarantees that properties rows are aligned with the sorted track data.\n\nIn Tracks.__init__ (napari/layers/tracks/tracks.py), the previous inline sorting of data was removed to avoid double-sorting and to centralize ordering logic in the track utils. A new test, test_track_layer_properties_flipped, constructs track data whose rows are flipped in order and passes various properties representations (dict, empty dict, DataFrame). It asserts that layer.properties are flipped consistently, proving that properties are sorted and aligned with the track data.\n\nThe result is that users can provide unsorted track data and properties, and napari will now correctly sort both by track ID then time, maintaining consistent alignment between positional data and metadata.",
        "semantic_memory": "This fix illustrates a common pattern: whenever a core data structure is reordered, every associated metadata structure must be reordered using the exact same index to preserve alignment. In visualization and data-processing pipelines, it is common to allow unsorted or arbitrarily ordered input for convenience. If the system internally normalizes the ordering (e.g., sorts by ID and time), this normalization must be applied uniformly to all parallel arrays (coordinates, properties, labels, etc.).\n\nKey concepts and best practices derived from this case:\n\n1. **Single source of truth for ordering**: Compute a single ordering index (e.g., via np.argsort or np.lexsort) and store it. Apply it to all related arrays instead of recomputing separate sorts for each one.\n\n2. **Data–metadata alignment**: For any design where you hold a primary array (e.g., positions) and secondary arrays (properties, labels, features) that are row-aligned, you must maintain invariant: `len(data) == len(property[i])` for all i, and the k-th row across all arrays refers to the same logical entity. Any operation that reorders data must update the metadata accordingly.\n\n3. **Centralize ordering logic**: Rather than sorting in multiple high-level entry points, centralize sorting in a lower-level utility or model class. This reduces duplication and the chance of one path forgetting to apply the sort to all relevant structures.\n\n4. **Non-mutating API behavior**: When reordering user-provided containers (like property dicts), copy them before mutation to avoid surprising side effects in calling code.\n\n5. **Testing for alignment by permutation**: A robust way to test alignment is to intentionally scramble or flip the input data and properties and assert that, after internal normalization, the outputs are consistent and correctly matched.\n\nThese principles generalize to any system that manages synchronized arrays or tables: datasets with features and labels, time series with annotations, graph nodes with attribute vectors, etc. Maintaining a consistent ordering map across all such structures is critical for correctness.",
        "procedural_memory": [
            "When diagnosing and fixing issues where associated properties/metadata become misaligned with core data after sorting or reordering, follow these steps:",
            "Step 1: Reproduce and observe misalignment",
            "- Create a minimal example where the primary data structure (e.g., track coordinates) is intentionally unsorted or permuted (e.g., flipped order).",
            "- Provide associated metadata/properties that you expect to stay aligned with each data row.",
            "- Run the code and inspect whether the properties still match the corresponding data rows after any internal processing. Misalignment will show as properties appearing in a different order than expected.",
            "Step 2: Identify where reordering occurs",
            "- Search for places in the code where the primary data array is sorted, reindexed, or subset (e.g., using np.sort, np.lexsort, argsort, fancy indexing).",
            "- Determine whether this reordering is applied only to the main data or also to related metadata arrays.",
            "- Confirm whether each reordering operation uses a reusable index (argsort-like) or a full sort that cannot easily be reproduced for metadata.",
            "Step 3: Introduce a single, reusable order index",
            "- Refactor the reordering logic to compute a single order index array (e.g., order = np.lexsort((col1, col0))).",
            "- Store this index on the model/manager object responsible for the data (e.g., self._order) so it is accessible when setting properties or other related arrays.",
            "- Apply this index to the primary data array exactly once, in a centralized location (e.g., in the data setter or a dedicated normalization method).",
            "Step 4: Apply the same order to all associated properties",
            "- In the properties/metadata setter, first normalize the input format (e.g., convert pandas DataFrame to a dict of numpy arrays).",
            "- If needed, add derived or required fields (e.g., a 'track_id' property) derived from the sorted data.",
            "- For each property array, convert it to a numpy array if it is not already, then reorder it using the stored index: `arr = np.array(prop)[self._order]`.",
            "- Replace the property entries with the reordered arrays. Avoid mutating the caller’s original dict by working on a copy.",
            "Step 5: Remove duplicate or inconsistent sorting logic",
            "- Ensure that high-level entry points (like layer __init__ methods) do not independently resort the data, which could conflict with or double-apply the sort.",
            "- Centralize sorting in a single lower-level utility or model class that is guaranteed to run before properties are set.",
            "Step 6: Add regression tests focused on ordering and alignment",
            "- Write tests that construct data in a non-sorted order (e.g., reversed, randomized, or grouped by ID but shuffled times).",
            "- Provide corresponding properties that reflect the original order (e.g., np.arange(N), or a known pattern).",
            "- After creating the object (layer, model, etc.), assert that both `layer.data` and `layer.properties` are in the expected canonical order and that each property row corresponds to the correct data row (e.g., using np.testing.assert_equal on appropriately permuted expected arrays).",
            "Step 7: Verify non-mutating behavior and edge cases",
            "- Ensure the original properties containers provided by the caller are not modified in-place (e.g., by checking identity or by reusing them in other contexts).",
            "- Test edge cases: empty properties dict, missing required fields, DataFrame vs dict input, and already-sorted input.",
            "- Confirm that the behavior is consistent across all accepted input types and that no warnings or errors are raised unexpectedly."
        ]
    }
}