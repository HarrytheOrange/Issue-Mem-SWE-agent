{
    "search_index": {
        "description_for_embedding": "HomeKit controller could overload the system by queuing multiple concurrent async_update polls when the system or network was under backpressure. The fix introduces an asyncio lock around polling and skips new polls if a previous one is still in flight, with one-time warnings and a recovery info log to prevent thread pool exhaustion.",
        "keywords": [
            "HomeKit",
            "homekit_controller",
            "async_update",
            "polling",
            "backpressure",
            "overload",
            "thread pool exhaustion",
            "asyncio.Lock",
            "concurrent polling",
            "rate limiting",
            "Home Assistant"
        ]
    },
    "agent_memory": {
        "episodic_memory": "In this incident, a Home Assistant setup using the homekit_controller integration had many HomeKit entities (e.g., 75 entities across 15 pairings). A prior optimization reduced thread pool usage by polling per pairing rather than per entity, but under poor Wi-Fi conditions or a heavily loaded system, the integration could still queue more HomeKit polls than it could complete. This produced backpressure: async_update calls would stack up, potentially overwhelming the executor/thread pool and making the instance slow or unrecoverable.\n\nThe fix modifies homeassistant/components/homekit_controller/connection.py:\n- A per-connection asyncio lock (self._polling_lock) is introduced to prevent concurrent polling of the same accessory/bridge.\n- In async_update, before starting a poll, the code checks if the lock is already held. If it is locked, the method now returns early instead of waiting, effectively skipping that poll.\n- On the first detected skip due to lock contention, a warning is logged: \"HomeKit controller update skipped as previous poll still in flight\". A flag (self._polling_lock_warned) ensures this warning is emitted only once during a backpressure episode.\n- When the system recovers (i.e., async_update runs and the lock is not locked after previously having logged a warning), an info-level message is logged: \"HomeKit controller no longer detecting back pressure - not skipping poll\", and the warning flag is reset.\n- The poll body (get_characteristics, process_new_events) is executed only within the async with self._polling_lock block, ensuring strictly serialized polling.\n\nThis change prevents piling up queued poll operations when the system is already struggling, reducing load on the thread pool and making the system more robust during transient network issues or CPU overload.",
        "semantic_memory": "This fix demonstrates a general pattern for handling backpressure and concurrent polling in asynchronous systems:\n\n1. **Avoid concurrent work on the same resource:** When multiple asynchronous tasks might operate on the same external resource (e.g., networked accessory, API, database), it's often safer to serialize those operations using a lock. This avoids duplicated work, race conditions, and resource contention.\n\n2. **Prefer skipping non-critical work over blocking under load:** For periodic or best-effort tasks (like polling sensors), it's usually better to drop or skip some runs when the system is overloaded rather than queueing them and increasing latency and load. Non-critical background tasks should not block the event loop or saturate the thread pool.\n\n3. **Use locks as a backpressure signal:** A lock that is already held during a scheduling point can be treated as a signal that previous work is still in progress. Instead of waiting for the lock, one can decide to skip the operation and thereby apply backpressure at the task-scheduling layer.\n\n4. **Log sparingly but meaningfully during overload episodes:** Repeated warnings in a hot loop can flood logs and become noise. Emitting a single warning when entering a degraded state (e.g., first skipped poll) and an info message on recovery provides operators with clear signals without log spam.\n\n5. **Design periodic polling to be self-throttling:** Periodic update loops (timers, scheduled jobs) should consider the duration of the previous run. If a new run would overlap significantly with the previous one, either skip or delay. This is especially important when the work depends on external I/O with unpredictable latency.\n\n6. **Thread pool / executor protection:** In systems that mix async I/O with executor-based blocking calls, naive scheduling can easily swamp the executor when each async trigger enqueues new blocking work. Introducing limits (locks, semaphores, or explicit queues) around those calls is a robust way to protect the executor and maintain system responsiveness.",
        "procedural_memory": [
            "Step-by-step instructions on how to diagnose and fix similar issues.",
            "Step 1: Identify symptoms of backpressure or overload",
            "  - Observe high CPU usage, long response times, or unresponsive behavior in the application.",
            "  - Check logs for frequent or overlapping executions of periodic tasks (e.g., multiple async_update calls, repeated network calls).",
            "  - Look for evidence of thread pool or executor saturation (e.g., tasks waiting a long time before running, queued work growing).",
            "  - For integrations that poll external devices, note if multiple polls are in-flight concurrently for the same resource.",
            "Step 2: Inspect the polling or periodic update logic",
            "  - Locate the code responsible for periodic updates (e.g., async_update, scheduled callbacks, timer handlers).",
            "  - Verify whether these functions can overlap: does the scheduler trigger them at fixed intervals regardless of the duration of the previous run?",
            "  - Check if the function performs network or blocking I/O (e.g., HTTP requests, device communication, disk access) that may be routed through a thread pool.",
            "Step 3: Determine desired behavior under load",
            "  - Decide if overlapping invocations add value. For periodic sensor polling, overlapping calls often do not provide extra benefit and only add load.",
            "  - Choose a strategy: serialize calls (one at a time) and either queue or skip new calls when one is in progress.",
            "  - For non-critical or best-effort tasks, prefer skipping over queuing; for critical tasks, consider bounded queuing with backoff.",
            "Step 4: Introduce a per-resource async lock",
            "  - Add an asyncio.Lock (or equivalent) as an instance attribute associated with the resource (e.g., per accessory/bridge or per connection).",
            "    - Example: self._polling_lock = asyncio.Lock() in __init__.",
            "  - Ensure that any code that performs the actual polling/work is wrapped within `async with self._polling_lock`.",
            "Step 5: Implement skip-on-lock behavior instead of awaiting the lock",
            "  - In the periodic update entry point (e.g., async_update), before acquiring the lock, check if it is already held using lock.locked().",
            "  - If the lock is locked, return early instead of awaiting it. This effectively drops the current cycle when the previous one is still running.",
            "  - This avoids building up a backlog of work and mitigates pressure on the thread pool and external resources.",
            "Step 6: Add controlled logging for backpressure detection and recovery",
            "  - Introduce a flag (e.g., self._polling_lock_warned = False) to track whether a backpressure warning has been logged.",
            "  - When you detect lock.locked() and are about to skip, if the flag is False, log a warning (e.g., \"update skipped as previous poll still in flight\") and set the flag to True.",
            "  - When the lock is not locked after having previously warned (i.e., before acquiring lock, if flag is True and lock is now free), log a one-time info message indicating recovery and reset the flag.",
            "  - This provides operators with a clear signal that backpressure is happening, without spamming logs on every skip.",
            "Step 7: Handle error conditions inside the locked section",
            "  - Keep network calls and result processing inside the `async with self._polling_lock` block to guarantee serialization.",
            "  - Catch relevant exceptions (e.g., connection timeouts, transient disconnections) and decide whether to mark resources as unavailable or simply return.",
            "  - Ensure that the lock is always released (using async with ensures this even when exceptions occur).",
            "Step 8: Test behavior under normal and overloaded conditions",
            "  - Under normal load: verify that async_update runs as expected, that the lock is acquired and released properly, and that no warning messages are logged.",
            "  - Under simulated overload: intentionally delay the polling operation (e.g., by mocking network latency) so that the scheduler triggers another async_update before the previous one finishes.",
            "  - Confirm that the second (and subsequent overlapping) calls detect lock.locked(), skip work, and produce only one warning.",
            "  - Confirm that when the system recovers (polls finish within the interval), the info-level recovery log is emitted and the warning flag resets.",
            "Step 9: Monitor in production",
            "  - Watch for the backpressure warning log; if it appears frequently, consider increasing the polling interval or optimizing the underlying work.",
            "  - Ensure that the system remains responsive despite occasional skips; if data freshness is critical, evaluate whether a different throttling strategy or dynamic interval adjustment is needed."
        ]
    }
}