{
    "search_index": {
        "description_for_embedding": "Home Assistant opentherm_gw integration extended to expose OpenTherm Gateway internal data as sensors. Adds a dedicated sensor platform (sensor.opentherm_gw), a monitored_variables configuration option, maps pyotgw data constants to sensor entities (with device classes and units), and updates the pyotgw dependency to v0.2b1 to fix/align variable names (e.g. DATA_CH_BURNER_* → DATA_TOTAL_BURNER_*). Uses dispatcher-based push updates, validates configuration, uses discovery_info for platform setup, and broadens .coveragerc exclusion to all opentherm_gw platforms.",
        "keywords": [
            "opentherm_gw",
            "OpenTherm Gateway",
            "Home Assistant",
            "sensor.opentherm_gw",
            "monitored_variables",
            "pyotgw",
            "DATA_TOTAL_BURNER_STARTS",
            "DATA_TOTAL_BURNER_HOURS",
            "async_load_platform",
            "dispatcher",
            "non-polling sensors",
            "configuration validation",
            "requirements_all.txt",
            ".coveragerc wildcard"
        ]
    },
    "agent_memory": {
        "episodic_memory": "In this change, the Home Assistant opentherm_gw integration was enhanced to expose internal OpenTherm Gateway and boiler/thermostat variables as standard sensors.\n\nPreviously, opentherm_gw mainly provided a climate entity and did not offer configurable sensor entities for the rich set of OpenTherm data points. The issue requested an option to expose this internal data as sensors.\n\nTo implement this, the developer:\n- Added a new configuration option `monitored_variables` under the `opentherm_gw` domain in configuration.yaml. It is validated as a list of strings using `vol.All(cv.ensure_list, [cv.string])`.\n- Introduced a helper coroutine `setup_monitored_vars` in `homeassistant/components/opentherm_gw.py` that:\n  - Reads the pyotgw variable constants from `hass.data[DATA_OPENTHERM_GW][DATA_GW_VARS]`.\n  - Builds a sensor type map (currently only for sensors, but structured as a dict so it can be extended e.g. for binary_sensors later).\n  - Filters the user-configured `monitored_variables`, logging an error for each unsupported name, and collects the supported ones.\n  - If there are supported variables, it calls `await async_load_platform(hass, COMP_SENSOR, DOMAIN, sensors)` to dynamically set up the `sensor` platform with the selected variable keys passed via `discovery_info`.\n- Added a full sensor platform at `homeassistant/components/sensor/opentherm_gw.py` that:\n  - Declares `DEPENDENCIES = ['opentherm_gw']` so the main component is loaded first.\n  - In `async_setup_platform`, exits early if `discovery_info` is `None` (prevents direct manual setup; intended for discovery-only use via the main component).\n  - Builds a `sensor_info` mapping from each pyotgw data constant to a triple: `[device_class, unit_of_measurement, friendly_name]`. This includes both generic OpenTherm boiler/thermostat values (temperature, pressure, flow, modulation levels, burner starts/hours) and gateway-specific OTGW_ variables (firmware version, build, LED modes, GPIO modes, setback temperature, override modes, smart power, thermostat detection, reference voltage).\n  - For each requested var in `discovery_info` it generates a stable `entity_id` via `async_generate_entity_id(ENTITY_ID_FORMAT, var, hass=hass)` and instantiates an `OpenThermSensor` with the entity_id, var key, device_class, unit, and friendly_name.\n  - Adds the created entities via `async_add_entities`.\n- Implemented `OpenThermSensor` as a push-based `Entity` that:\n  - Sets `should_poll` to False.\n  - Subscribes in `async_added_to_hass` to the `SIGNAL_OPENTHERM_GW_UPDATE` dispatcher signal from the main opentherm_gw component using `async_dispatcher_connect`.\n  - On updates via `receive_report`, extracts its specific variable from the `status` dict, formats floats to one decimal `'{:2.1f}'.format(value)`, stores the value, and schedules a state update.\n  - Exposes the friendly name, device class, and unit.\n\nThe developer initially also introduced a `binary_sensor` platform for various boolean gateway/boiler flags (heating on, faults, service required, etc.), but then explicitly reverted that commit, leaving only the sensor platform in this PR.\n\nTo support new variables correctly, the integration’s dependency on pyotgw was updated from `0.1b0` to `0.2b1` in both `homeassistant/components/opentherm_gw.py` (REQUIREMENTS) and `requirements_all.txt`. The new pyotgw version corrected some variable constant names. The code was updated accordingly to use `DATA_TOTAL_BURNER_STARTS` and `DATA_TOTAL_BURNER_HOURS` instead of `DATA_CH_BURNER_STARTS` and `DATA_CH_BURNER_HOURS` both in the component’s monitored-variable map and in the sensor platform’s `sensor_info` mapping.\n\nOther cleanups included:\n- Importing the sensor domain symbolically via `from homeassistant.components.sensor import DOMAIN as COMP_SENSOR` instead of hardcoding the string 'sensor'.\n- Fixing the documentation URL in the sensor platform docstring from `components/opentherm_gw/` to `components/sensor.opentherm_gw/`.\n- Reordering imports to conform to style guidelines.\n- Updating `.coveragerc` from excluding only `homeassistant/components/climate/opentherm_gw.py` to `homeassistant/components/*/opentherm_gw.py`, covering all platform modules under this integration.\n\nReview feedback resulted in tightening config validation for `monitored_variables`, ensuring `async_setup_platform` exits when not called via discovery, generating entity IDs outside the entity constructor, and awaiting `async_load_platform` when setting up sensors. The net effect is a clean, configurable way for users to expose arbitrary OpenTherm Gateway and boiler variables as Home Assistant sensors, backed by a corrected underlying library.",
        "semantic_memory": "This change illustrates several reusable patterns and best practices for building featureful, well-integrated sensor platforms in Home Assistant (and more generally in event-driven IoT frameworks):\n\n1. **Separation of core integration and platforms**\n   - The core integration (`opentherm_gw` component) is responsible for device communication and state aggregation. It maintains a shared data structure (`hass.data[DATA_OPENTHERM_GW][DATA_GW_VARS]`) and dispatches structured status updates via a dispatcher signal.\n   - Platform modules (`sensor/opentherm_gw.py`) focus on representing slices of that data as entities (sensors, binary sensors, etc.) and do not directly talk to the hardware or external library.\n   - This separation allows multiple platforms (climate, sensor, binary_sensor, etc.) to share a single connection and model of the device.\n\n2. **Dispatcher-based push updates instead of polling**\n   - Rather than polling the device per-entity, the integration pushes updates centrally and broadcasts them to subscribers via signals.\n   - Entities subscribe with `async_dispatcher_connect` and simply extract their piece of state from the shared update payload.\n   - This reduces I/O duplication, respects device limits, and simplifies consistency (all entity states are derived from the same update message).\n\n3. **Configurable monitored variables and dynamic platform setup**\n   - Exposing a `monitored_variables` list gives users fine-grained control over which measurements become entities, mitigating entity bloat and allowing customized dashboards.\n   - The main component translates user-facing string identifiers into internal constants and validates them against a whitelist. Unsupported values are logged explicitly.\n   - Dynamic platform loading via `async_load_platform(..., discovery_info=sensors)` is a flexible pattern: the core integration decides which specific variables to expose, while the platform just consumes `discovery_info` and builds entities accordingly.\n\n4. **Discovery-only platforms and guard clauses**\n   - The sensor platform’s `async_setup_platform` returns early if `discovery_info is None`, clearly signalling that manual configuration (platform-level config in configuration.yaml) is not supported.\n   - This avoids misconfigurations and keeps setup flows coherent: all opentherm_gw configuration is centralised under the main domain.\n\n5. **Strong configuration validation**\n   - Using `vol.All(cv.ensure_list, [cv.string])` ensures `monitored_variables` is always a list of strings, regardless of how it’s provided, and prevents non-string items.\n   - Early validation reduces runtime errors and simplifies platform code (it can assume correctly-typed values).\n\n6. **Stable, predictable entity IDs**\n   - Generating entity IDs with `async_generate_entity_id` using the variable key produces consistent IDs across restarts.\n   - Passing the entity_id into the entity constructor decouples ID generation from entity implementation, simplifies testing, and matches HA patterns.\n\n7. **Aligning with upstream dependencies and constants**\n   - When a dependency changes variable names (e.g. pyotgw changing from CH-specific burner counts to TOTAL_*), integration code and sensor definitions must be updated to stay in sync.\n   - Keeping REQUIREMENTS and `requirements_all.txt` consistent is critical in monorepos where centralized tooling relies on requirements_all.txt.\n\n8. **Source discovery and documentation**\n   - Docstrings include direct links to component documentation, helping users and contributors find relevant usage docs quickly.\n   - Using symbolic imports for component domains (e.g. `DOMAIN as COMP_SENSOR`) reduces hard-coded strings and improves robustness under refactors.\n\n9. **Coverage configuration for multi-platform integrations**\n   - When an integration spans multiple platform modules, coverage settings should be wildcarded (e.g. `components/*/opentherm_gw.py`) instead of per-platform files, to keep the testing strategy coherent as new platforms are added.\n\nOverall, the PR demonstrates a clean pattern for exposing rich device data as user-selected sensor entities via push-based updates and dynamic platform setup, with solid configuration validation and close coordination with the underlying protocol library.",
        "procedural_memory": [
            "Step-by-step approach for adding configurable sensors to an existing event-driven integration:",
            "Step 1: Identify the data source and shared state model",
            " - Ensure your core integration already has a clear data model for the external device (e.g., a dict of variable names to values) and a mechanism to receive updates (callbacks, events, etc.).",
            " - If not, refactor the integration so that all I/O with the device is centralized in one component/module, which then exposes updates through a single, well-defined interface.",
            "Step 2: Set up a dispatcher or event bus for updates",
            " - Use a dispatcher or message bus (in Home Assistant, `async_dispatcher_send` / `async_dispatcher_connect`) to broadcast updates to any number of listening entities.",
            " - Define a constant signal name (e.g. `SIGNAL_<INTEGRATION>_UPDATE`) shared between the integration and platform modules.",
            " - On each device update, send a payload that includes the entire status snapshot, so entities can pick the fields they need.",
            "Step 3: Introduce a configuration option for monitored variables",
            " - In the main integration’s config schema, add a list option like `monitored_variables`.",
            " - Validate it with something robust (e.g., `vol.All(cv.ensure_list, [cv.string])`) to ensure you always get a list of strings.",
            " - Document the supported values in the integration’s docs and keep them in sync with your code.",
            "Step 4: Map user-facing variable names to internal constants",
            " - In the core integration, derive a mapping between user-specified variable names and the internal keys/constants your library uses.",
            " - Construct a dictionary grouped by platform type if needed (e.g. sensor, binary_sensor) so it can be extended easily later.",
            " - Iterate over the configured `monitored_variables`, and for each:\n   - If supported, add it to a list specific to that platform.\n   - If unsupported, log an explicit error or warning to help the user correct their config.",
            "Step 5: Dynamically load platform modules with discovery_info",
            " - For each platform with at least one selected variable (e.g. sensors), call the framework’s dynamic platform loader (in HA: `await async_load_platform(hass, COMP_SENSOR, DOMAIN, sensors)`), passing the list of variable keys via `discovery_info`.",
            " - Use a symbolic domain import instead of a raw string (e.g., `from homeassistant.components.sensor import DOMAIN as COMP_SENSOR`) to avoid typos and ease refactoring.",
            "Step 6: Implement the platform’s async_setup_platform with discovery-only semantics",
            " - In the platform module’s `async_setup_platform`, accept the `discovery_info` parameter and return early if it is `None`. This enforces discovery-only setup and prevents unsupported manual configuration.",
            " - Retrieve shared integration state from something like `hass.data[<INTEGRATION>][<CONSTANTS>]`.",
            " - Build a `sensor_info` dictionary mapping internal variable constants to metadata: `[device_class, unit_of_measurement, friendly_name]`.",
            " - For each var in `discovery_info`:\n   - Lookup its metadata in `sensor_info`.\n   - Generate an entity ID via a helper (e.g. `async_generate_entity_id(ENTITY_ID_FORMAT, var, hass=hass)`).\n   - Instantiate the entity with the pre-generated entity_id and relevant metadata.",
            "Step 7: Implement push-based entities subscribing to the dispatcher",
            " - In each entity’s constructor, store the variable key and metadata (name, unit, device class). Do not perform I/O in the constructor.",
            " - In `async_added_to_hass`, subscribe to the integration’s dispatcher signal using `async_dispatcher_connect`. The callback should:\n   - Extract the entity’s variable from the update payload (e.g. `status.get(self._var)`).\n   - Optionally normalize/format the value (e.g. format floats, cast booleans).\n   - Cache the new value on the entity and schedule a state update (`async_schedule_update_ha_state()`).",
            " - Set `should_poll` to False to reflect that the entity is push-based.",
            "Step 8: Keep dependency versions and constants in sync",
            " - If your integration depends on a library that defines constants (e.g. pyotgw’s `DATA_*` attributes), lock the library version in both the integration’s REQUIREMENTS and any central requirements listings (like `requirements_all.txt`).",
            " - When the library updates and renames constants (e.g. `DATA_CH_BURNER_STARTS` to `DATA_TOTAL_BURNER_STARTS`), update all references in your integration and platform metadata maps.",
            " - Run tests after such updates to catch mismatches early (missing attributes will often surface as AttributeError or sensor setup failures).",
            "Step 9: Validate coverage and documentation configuration",
            " - If your integration spans multiple platform modules (e.g. climate, sensor, binary_sensor), adjust coverage configuration to use wildcards (e.g. `components/*/your_integration.py`) rather than listing each file individually.",
            " - Ensure that docstrings in each platform link to the correct documentation page (e.g. `components/sensor.your_integration/`) and that docs reference the new configuration options (such as `monitored_variables`).",
            "Step 10: Handling future extensions (like binary sensors)",
            " - If you plan to add other platforms (binary_sensor, switch, etc.), design your configuration and mapping logic from the start to be platform-agnostic: e.g. a dict keyed by platform type (`sensor`, `binary_sensor`) each containing a list of supported internal variables.",
            " - Implement and test new platforms in separate commits/PRs if needed; if one is reverted, keep the shared mapping structures generic so they still make sense.",
            "By following this procedure, a developer can systematically extend an existing integration to provide configurable, push-updated entities (sensors, binary sensors, etc.) while keeping configuration, dependencies, and internal constants well-aligned and maintainable."
        ]
    }
}