{
    "search_index": {
        "description_for_embedding": "Fixes and clarifications for the PokemonGo-Bot Sniper task: correct VIP determination and name/ID mapping, fix homing_shots behavior under social mode, avoid misclassification of pokemons as VIP due to wrong indices and bad external data, add per-source enabled flags and only validate/fetch enabled sources, only validate Sniper config when the task is enabled, handle missing expiration timestamps by assigning a default, tweak logging levels, and update docs/config examples accordingly.",
        "keywords": [
            "PokemonGo-Bot",
            "Sniper task",
            "social mode",
            "homing_shots bug",
            "VIP classification bug",
            "pokemon VIP list",
            "id/name mapping off-by-one",
            "external sniping sources",
            "JSON mapping validation",
            "config validation only when enabled",
            "per-source enabled flag",
            "missing expiration default",
            "Sniper order priority",
            "pokesnipers bad data",
            "timeout handling"
        ]
    },
    "agent_memory": {
        "episodic_memory": "This pull request refines and stabilizes the Sniper task in PokemonGo-Bot, primarily focusing on correcting VIP classification, improving social/url sniping behavior, and making configuration safer and clearer.\n\nPreviously, the Sniper used `Pokemons.name_for(id - 1)` when building pokemon objects and VIP flags from external data. That off-by-one usage caused some pokemons to be misidentified and thus misclassified as VIPs (or not VIPs) incorrectly. In `SniperSource.fetch`, this was fixed by using `Pokemons.name_for(id)` instead, and in `_parse_pokemons` the code was rewritten to prefer an existing `pokemon_name` field, otherwise derive it via `Pokemons.name_for(pokemon_id)`. The VIP flag is now computed as `pokemon['pokemon_name'] in self.bot.config.vips`, and the `priority` is taken from the same name-based `catch_list`, eliminating the previous mismatch between ids and names.\n\nThe `is_snipeable` logic was reworked so that the decision order is clearer: a pokemon is immediately considered catchable if its name is in the catch list. If not, its IV can optionally justify catching it (using `special_iv`), and if that still isn't enough, being in the VIP list can still make it a valid target. Only when a pokemon is not in the catch list, has low/absent IV, and is not VIP is it skipped. Additionally, when a pokemon is not snipeable, the code now logs at trace level rather than error level to avoid noisy logs for expected behavior.\n\nA subtle bug with homing shots in social mode was also addressed. In `snipe`, the logic that determined whether a social-mode pokemon already had verified encounter/spawn data (and thus could be trusted without re-verification) was updated. A `success` flag is initialized based on the pre-existing `exists` value, and verification logic only runs when necessary. This prevents homing shots from repeatedly trying or incorrectly rejecting social snipes due to misinterpreted verification state.\n\nThe PR also hardened interactions with external sniping sources. Each `SniperSource` now has an `enabled` flag. The Sniper task will only validate and fetch from sources where `enabled` is true; disabled sources are skipped with trace logging. During initialization, Sniper only performs its own configuration and source validation if the task itself (`config.enabled`) is true, preventing startup failures when Sniper is configured but intentionally disabled.\n\nSource validation (`SniperSource.validate`) was tightened: when a source is enabled, it fetches sample data with a longer timeout (10 seconds), then checks that all configured mapping parameters (iv, id, name, latitude, longitude, expiration, encounter, spawnpoint) actually exist on the returned JSON objects. Any missing mappings are collected and reported in a single `LookupError` for better usability. If the response is empty, a `ValueError(\"Empty reply\")` is raised; if the source is disabled, validation raises a `ValueError(\"Source is not enabled\")`. Exceptions due to timeouts and connection errors are caught and re-raised as more user-friendly messages.\n\nAnother real-world issue emerged from sources that do not provide expiration timestamps, leading to invalid or effectively immortal entries in the sniping list. To fix this, `SniperSource.fetch` now sets a default expiration if the source provides no expiration value: it assigns an expiration timestamp equal to the current time plus a small fixed number of minutes (3 minutes in the code), expressed in milliseconds, so such entries automatically age out instead of persisting indefinitely.\n\nThe request throttling logic for URL sources was preserved and clarified: `_get_pokemons_from_url` only fetches when enough time has elapsed since the last request (`MIN_SECONDS_ALLOWED_FOR_REQUESTING_DATA`), thereby protecting external services from over-polling. When fetching from each enabled source, results from different sources are merged using a location-based hash key to avoid duplicates.\n\nMinor internal cleanups were done as well: a constant was renamed from `CACHE_LIST_MAX_SIZE` to `MAX_CACHE_LIST_SIZE`, and the caching logic still ensures that once the cache reaches that size, the oldest entry is dropped. For time conversion, variable naming around UTC-to-local conversion was made clearer.\n\nConfig and docs were brought in sync with the behavior:\n- In `configs/config.json.example` and `config.json.map.example`, the Sniper task is now present with sensible defaults, but `enabled` is false by default, and each example source has `\"enabled\": false`. The global `enable_social` flag was also defaulted to false.\n- The order array in examples (and docs) was updated to `['missing', 'vip', 'priority']` instead of the previous `['missing', 'vip', 'threshold']` or including extra fields like `iv` and `expiration_timestamp_ms`.\n- Example sources now illustrate multiple real services: a local raw_data endpoint, Pokewatchers, and PokeSnipers. The docs explicitly call out that PokeSnipers' ID field is known to be wrong and should not be mapped.\n- Documentation for Sniper options was clarified: bullets are defined explicitly as attempts; homing_shots behavior is fully described; `special_iv` is explained as a threshold that can bypass the catch list; `order` semantics were updated to use `priority` instead of `threshold`, and the reference to `special_iv` replaces the old `min_iv_to_ignore_catch_list` wording. New documentation fields were added for `sources.key`, `sources.url`, and `sources.enabled`. A typo in the docs (describing `sources` instead of `enabled` as the task toggle) was corrected.\n\nOverall, the incident was driven by real-world user reports: wrong VIP classification, confusion around Sniper configs, issues with external services providing bad/missing data, and homing shots misbehavior. The fix centralized around making Sniper’s decisions explicitly name-based, guarding against bad external data, respecting enabled/disabled flags, providing safe defaults for optional data, and aligning docs/config examples with the actual behavior.",
        "semantic_memory": "From this fix, several general lessons emerge about designing and maintaining features that consume external data and are controlled by configuration:\n\n1. **Use stable identifiers and avoid off-by-one errors in mapping logic.**\n   When mapping between external IDs and internal representations (e.g., pokemon IDs to names), it's easy to introduce off-by-one errors or rely on assumptions about indexing. Instead of doing arithmetic on IDs, prefer explicit lookup APIs (like `name_for(id)` and `id_for(name)`) and avoid manual offsets. Always verify that your mapping aligns with the external system's indexing.\n\n2. **Treat external data providers as unreliable and configurable.**\n   Third-party JSON APIs can be slow, return empty data, change schemas, or have incorrect fields (e.g., a known-bad ID field). Your code should:\n   - Support an \"enabled\" flag per source so that failing or experimental sources can be turned off without code changes.\n   - Validate mappings against actual payloads (e.g., checking that configured JSON keys exist) and fail with clear, aggregated error messages.\n   - Use reasonable timeouts and catch network errors, surfacing terse, actionable messages to the user instead of raw stack traces.\n\n3. **Only validate what is actually in use.**\n   Running full validation on disabled tasks or disabled sources can cause unnecessary failures. Gating validation and remote calls behind `enabled` checks reduces friction for users and makes features safer to ship. Configuration should allow a user to have a task fully specified but disabled without breaking startup.\n\n4. **Establish safe defaults for optional or missing fields.**\n   Some external sources may omit important fields like expiration timestamps. Rather than assuming this won't happen, define safe defaults (e.g., a short default lifetime) that allow the system to function and prevent stale data from persisting indefinitely. This also prevents crashes from None/empty values being used as timestamps.\n\n5. **Clarify selection and priority rules in both code and documentation.**\n   Whenever entities are selected based on multiple criteria (e.g., catch list, VIP status, IV threshold, expiration), the precedence rules should be explicit in code and described clearly in docs. This reduces confusion and makes it easier to reason about edge cases. Changing a concept name from `threshold` to `priority`, and aligning it with behavior, helps users understand how the system decides what to act on.\n\n6. **Log expected control-flow at appropriate levels.**\n   Not every rejection or skipped entity is an error; it's often a normal outcome of business rules. For example, a pokemon not being snipeable is expected and should be logged at trace/debug level, not error level. This keeps error logs reserved for actual failures, improving operational signal-to-noise.\n\n7. **Throttle polling to external services and deduplicate results.**\n   When aggregating from multiple sources, it's important to:\n   - Throttle request frequency to avoid overloading APIs and to respect rate limits.\n   - Merge results by a deterministic key (such as location) to avoid duplicates, particularly when multiple providers report the same entity.\n\n8. **Keep config examples and documentation tightly aligned with actual behavior.**\n   Configuration examples should be realistic, safe defaults (often disabled by default for risky features) and reflect the current code behavior. When behavior changes (e.g., new `enabled` flags or new order semantics), docs and example configs need to be updated to prevent users from misconfiguring the system or misunderstanding the feature.\n\n9. **Be cautious about acting on unverified or community-provided data.**\n   For features like sniping, external data (e.g., from community services or message brokers) can be spoofed or invalid, leading to unexpected behavior or even user bans in game contexts. Systems should be designed to verify critical details when possible, treat unverified information conservatively, and allow users to disable problematic sources.\n\nThese patterns apply broadly to any system that consumes external APIs, has complex selection criteria, or is heavily driven by configuration: always validate what you use, guard against bad data, express rules clearly, and make risky components opt-in and observable.",
        "procedural_memory": [
            "Step-by-step instructions on how to diagnose and fix similar issues.",
            "Step 1: Verify identifier mapping and classification logic\n- Inspect where external identifiers (like numeric IDs) are converted into internal representations (names, enums, etc.).\n- Check for any arithmetic adjustments (e.g., `id - 1`) that might rely on assumptions about indexing.\n- Compare mapping results with ground truth (e.g., known pokemon IDs/names) to detect off-by-one or misalignment.\n- Ensure classification flags (like VIP, priority) are derived from stable, unambiguous keys (usually names or canonical IDs) rather than ambiguous or transformed values.",
            "Step 2: Reproduce the incorrect behavior\n- Log the full data flow for a misclassified item: raw JSON payload, mapping outputs (id, name), and the resulting flags (VIP, missing, priority, IV).\n- Add temporary debug/trace logs to the selection logic (`is_snipeable` or equivalent) to print why an item is considered valid or skipped.\n- Confirm that reported misbehavior (e.g., a non-VIP reported as VIP) correlates with mapping or classification logic, not some other component.",
            "Step 3: Fix mapping and selection logic\n- Replace arithmetic-based ID-to-name conversions with API-based or table-based lookups (`name_for(id)`, `id_for(name)`) that reflect the external system’s actual indexing.\n- Centralize the building of entity objects: ensure each entity has a canonical `name` and/or `id`, and derive classification flags (VIP, priority) consistently from those fields.\n- Clarify selection rules: reorder logic so that high-level rules (e.g., explicit catch list) are checked first, then secondary criteria (IV thresholds), then fallback rules (VIP status). Document these rules inline as comments.\n- Adjust log levels so that normal rejections (not selected) are trace/debug, while genuine failures (exceptions, invalid data) are warnings/errors.",
            "Step 4: Introduce and use enabled flags for tasks and sources\n- Add an `enabled` flag for any non-essential task or external source, defaulting to false in examples and config templates if the feature is risky or experimental.\n- Wrap initialization and validation logic in checks for `task.enabled`: if the task is disabled, skip heavy validation and external calls.\n- Similarly, wrap per-source validation and fetching in `source.enabled` checks: validate and fetch only from enabled sources, log disabled sources at trace/debug level.\n- Confirm that disabling a task or a source no longer causes startup failures or runtime exceptions.",
            "Step 5: Harden source validation and network interactions\n- Implement a `validate()` method per external source that:\n  - Fetches sample data with a conservative timeout.\n  - Checks that all configured mapping paths (id, name, iv, latitude, longitude, expiration, etc.) exist in the returned JSON objects.\n  - Aggregates all missing mappings and reports them in a single error message (e.g., `The following params dont exist: iv, encounter_id`).\n  - Handles empty responses explicitly (e.g., raising `Empty reply`) and wraps network timeouts or connection errors in user-friendly error messages.\n- Ensure that validation is only run for enabled sources to avoid unnecessary failures.\n- Add tests or manual scripts to quickly revalidate sources when their APIs change.",
            "Step 6: Define safe defaults for missing optional fields\n- Identify fields that may be missing from some sources but are required for core logic (e.g., expiration timestamps).\n- Decide on a safe default behavior: for expirations, a short default lifetime (e.g., 3–5 minutes) prevents stale data from lingering indefinitely.\n- Implement default assignment in the data parsing stage (e.g., in `fetch`), so downstream logic always sees a valid value.\n- Document this behavior clearly so users understand why certain entries may disappear after a default time even if the source provided no expiration.",
            "Step 7: Rate-limit and deduplicate results from external services\n- Maintain timestamps of the last successful fetch per aggregated operation.\n- Before fetching from external sources, check if the configured minimum interval has passed; if not, skip fetching and log a trace/debug message.\n- When merging results from multiple sources, define a deterministic hash key (e.g., by location or a combination of id and coordinates) and store results in a map keyed by that hash.\n- Only add new entries when the hash key is not present, effectively deduplicating entries across sources.\n- After merging, log how many results survived deduplication.",
            "Step 8: Align configuration and documentation with actual behavior\n- Update configuration examples to reflect realistic, safe defaults (e.g., Sniper and sources disabled by default, correct `order` attributes, new `enabled` fields).\n- Update documentation of each option to match the current code, including new flags (`enabled` for tasks and sources), altered behaviors (order semantics, IV handling), and known caveats (e.g., certain providers having wrong ID fields that should not be mapped).\n- Cross-check config keys and doc names to avoid typos (e.g., describing `enabled`, not `sources`, as the task toggle).\n- Consider adding comments in example configs around risky or commonly misunderstood options.",
            "Step 9: Regression test the feature end-to-end\n- With corrected mapping and configuration, run the sniping feature in both social and url modes.\n- Confirm that:\n  - VIP and catch list behavior matches expectations (only configured VIPs/catch-list entries are always targeted).\n  - High-IV overrides and VIP fallbacks work as intended.\n  - Homing shots behave consistently: they retry until bullets are spent, and behave correctly in social mode with/without verification data.\n  - Disabled sources are skipped cleanly, and enabled sources validate and fetch successfully.\n  - Entries from sources with missing expiration expire at the default time.\n- Monitor logs to ensure that errors are reserved for exceptional conditions and that trace/debug logs provide enough detail to diagnose future issues."
        ]
    }
}