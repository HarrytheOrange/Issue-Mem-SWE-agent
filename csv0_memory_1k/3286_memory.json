{
    "search_index": {
        "description_for_embedding": "Refactor StackStorm Mistral workflow result tracking from a custom querier/resultstracker into a polling sensor that dispatches triggers and uses a rule + action to update action executions. Fixes sluggish workflow status updates by dogfooding the sensor/rules engine and using a last_polled timestamp in the key-value store.",
        "keywords": [
            "StackStorm",
            "Mistral",
            "workflow status",
            "result tracker",
            "resultstracker",
            "polling sensor",
            "sensor_service",
            "trigger",
            "rule",
            "liveaction",
            "executions.update_execution",
            "performance",
            "sluggish status updates",
            "workflow_progress_sensor",
            "update_workflow_status"
        ]
    },
    "agent_memory": {
        "episodic_memory": "In this change, the project had a sluggish Mistral 'querier' component that was responsible for tracking workflow results and updating StackStorm action executions. Instead of running a separate dedicated process (st2resultstracker) and custom logic, the team refactored the functionality into a standard StackStorm polling sensor and a rule-based workflow.\n\nA new 'mistral' pack was introduced. Inside it, a polling sensor `WorkflowStatusPoller` was added (`contrib/mistral/sensors/workflow_progress_sensor.py`) and wired via `workflow_progress_sensor.yaml`. The sensor uses the Mistral v2 API (configured via `cfg.CONF.mistral`) to poll workflow executions with `updated_at >= last_polled`, where `last_polled` is stored in StackStorm's key-value store under the key `last_polled`. If there is no stored timestamp, it uses a very old default (`1900-01-01...`) to bootstrap.\n\nFor each updated Mistral execution, the sensor retrieves detailed execution data and associated tasks. It normalizes Mistral states (SUCCESS, ERROR, CANCELLED, RUNNING) into StackStorm LiveAction statuses using two mappings (`DONE_STATES` and `ACTIVE_STATES`) and the helper `_determine_execution_status`. That helper takes into account whether the LiveAction has been canceled or is canceling and whether there are still active tasks, handling edge cases where Mistral marks the workflow done while tasks are still running. It uses `action_service.is_action_canceled_or_canceling` and the tasks' states to compute the final StackStorm status (RUNNING, CANCELING, SUCCEEDED, FAILED, CANCELED).\n\nThe sensor builds a unified result payload that includes the workflow output, the original `params` (including `env.st2_liveaction_id`), the workflow state, state_info, and a list of formatted tasks. It dispatches a trigger `mistral.workflow.status.update` with payload `{id: st2_liveaction_id, status: computed_status, result: result_object}` and a new `trace_tag` (UUID hex).\n\nA new trigger-driven rule `workflow_status_updated.yaml` maps this trigger to a new action `mistral.update_workflow_status`. The action implementation (`update_workflow_status.py`) directly manipulates the LiveAction database record: it loads the LiveAction by ID, updates the status (unless already CANCELED), sets the result, and if the status is in a completed state and `end_timestamp` is not set, it sets `end_timestamp` to the current UTC time. Then it persists and publishes the update using `LiveAction.add_or_update(..., publish=False)`, `executions.update_execution(updated_liveaction)`, and `LiveAction.publish_update(updated_liveaction)`. A helper `_invoke_post_run` is implemented to run `runner.post_run(...)` for the underlying runner, but it is not wired into the main `run` method in this patch.\n\nFinally, `tools/launchdev.sh` was updated to stop starting the legacy `st2resultstracker` process (those commands were commented out) because the new sensor + trigger + rule replaces its function.\n\nOverall, the incident was a performance and architecture improvement: the old custom Mistral result tracker was slow and non-standard. The fix was to 'dogfood' the existing sensor/rule infrastructure, improving robustness and maintainability while solving the sluggish workflow status updates.",
        "semantic_memory": "This change illustrates several generalizable patterns and best practices:\n\n1. **Dogfooding core primitives instead of building one-off services**:\n   - Rather than maintaining a bespoke 'result tracker' daemon, the system now leverages the existing StackStorm sensor + trigger + rule + action architecture. This reduces maintenance burden, reuses battle-tested infrastructure, and benefits from improvements made to the core engine.\n\n2. **Use polling sensors with incremental timestamps for external systems that lack push hooks**:\n   - When an external workflow engine (like Mistral) does not push events, a polling sensor can efficiently track changes using an \"updated since\" filter (`updated_at >= last_polled`).\n   - Persisting `last_polled` in a key-value store allows the sensor to be stateless across restarts and avoids re-processing old items.\n\n3. **Normalize external state machines to internal status models**:\n   - External systems often have their own status values. Mapping those to internal, canonical states (e.g., Mistral SUCCESS/ERROR/CANCELLED to StackStorm SUCCEEDED/FAILED/CANCELED) simplifies reasoning, UI, and downstream logic.\n   - Edge cases where external and internal states diverge (e.g., workflow marked DONE while tasks are still RUNNING) are handled by combining external status with internal knowledge (active tasks, cancellation flags) in a dedicated normalization function.\n\n4. **Cancellation-aware status computation**:\n   - Before finalizing an execution status, check whether the user/system has requested cancellation. If there are still active tasks, keep the status as CANCELING rather than immediately moving to CANCELED or another terminal state.\n   - This design improves the accuracy of lifecycle tracking and keeps the UI and automation behavior in sync with reality.\n\n5. **Decouple polling from state mutation via triggers and rules**:\n   - The sensor is responsible only for observing external state and emitting standardized triggers.\n   - A rule then supports flexible routing to one or more actions, and the action encapsulates the logic for updating internal state (DB + event publication). This separation makes the system more composable and testable.\n\n6. **Ensure DB updates are consistent and publish lifecycle events**:\n   - When updating execution records, always perform these steps: update the LiveAction DB object, set timestamps for completion, call `executions.update_execution` to keep the Execution model in sync, and publish LiveAction updates so that other components (e.g., notifiers, UI) react correctly.\n\n7. **Refactoring out legacy services requires updating operational tooling**:\n   - When a long-running process (st2resultstracker) is replaced with a sensor, tools and scripts (like `launchdev.sh`) must be updated to stop starting the obsolete service. This avoids duplication, conflicts, or unexpected side effects.",
        "procedural_memory": [
            "How to migrate a custom workflow result tracker or poller into a StackStorm polling sensor and rule-based action pipeline.",
            "Step 1: Identify the legacy tracker behavior",
            "- Determine what the custom service is doing: which external system it polls (e.g., Mistral), how often, how it filters changed records (e.g., updated_at), and how it updates internal state (e.g., LiveAction statuses and results).",
            "- Identify any hand-coded mappings between external states and internal execution statuses, plus any special handling (like cancellations).",
            "Step 2: Design the sensor and triggers",
            "- Create a new pack (if needed) to contain the sensor, triggers, rules, and actions (e.g., a 'mistral' pack).",
            "- Decide on a trigger type for status updates (e.g., `mistral.workflow.status.update`) and its payload schema: minimally include an internal execution ID, a normalized status, and the raw result payload.",
            "Step 3: Implement the polling sensor",
            "- Subclass `st2reactor.sensor.base.PollingSensor` and implement the `setup`, `poll`, and optionally `cleanup` methods.",
            "- In `setup`, initialize database access if needed (`database_setup.db_setup()`), get a logger from `self.sensor_service.get_logger`, configure a poll interval (`self._poll_interval`), and instantiate any external clients (e.g., Mistral client using `cfg.CONF`).",
            "- Use StackStorm's key-value store to cache the last polled timestamp: on each `poll`, fetch it via `self.sensor_service.get_value('last_polled')` and default to a very old date on first run.",
            "- Call the external API to list executions updated since that timestamp (e.g., `executions.list(updated_at='gte:%s' % last_polled)`), then update the timestamp at the end of the poll with the current time using `set_value`.",
            "Step 4: Fetch detailed execution and task data",
            "- For each updated execution, call a helper to fetch the full execution object and parse its fields (e.g., `params`, `output`, `state`, `state_info`).",
            "- Safely parse JSON fields using helpers like `json.loads` or `jsonify.try_loads`, guarding against invalid JSON.",
            "- Fetch associated tasks (e.g., `tasks.list(workflow_execution_id=exec_id)` then `tasks.get(task.id)`), and normalize them into a stable, unified structure suitable for downstream consumers (id, name, state, timestamps, input, result, published).",
            "Step 5: Implement status normalization logic",
            "- Define mappings from external workflow states to internal actions states (e.g., `DONE_STATES = {'SUCCESS': SUCCEEDED, 'ERROR': FAILED, 'CANCELLED': CANCELED}` and `ACTIVE_STATES = {'RUNNING': RUNNING}`).",
            "- Implement a helper (e.g., `_determine_execution_status(execution_id, wf_state, tasks)`) that:\n  - Checks if the internal action has been canceled or is canceling (e.g., `is_action_canceled_or_canceling(execution_id)`).\n  - Identifies active tasks (`task['state'] in ACTIVE_STATES`).\n  - Applies rules: keep status RUNNING if there are active tasks, return CANCELING when a cancellation is requested but tasks are still running, only move to a terminal state when there are no active tasks and the workflow state is a done state.",
            "Step 6: Dispatch a trigger for each updated execution",
            "- For each execution, construct a payload containing:\n  - The internal LiveAction ID (e.g., `params['env']['st2_liveaction_id']`).\n  - The computed internal status.\n  - The full result object (including tasks and any metadata).\n  - Optionally a trace tag (e.g., `uuid.uuid4().hex`).",
            "- Use `self.sensor_service.dispatch(trigger='mistral.workflow.status.update', payload=payload, trace_tag=...)` to emit the trigger.",
            "Step 7: Implement the action that applies updates to internal executions",
            "- Define an action (e.g., `update_workflow_status.py`) using the `run-python` runner with parameters for `action_exec_id`, `status`, and `result`.",
            "- In the action implementation:\n  - Initialize DB access (`database_setup.db_setup()`).\n  - Load the LiveAction DB object by ID (`LiveAction.get_by_id`).\n  - If no object is found, raise a descriptive exception.\n  - If the LiveAction is not already CANCELED, set its status to the provided status.\n  - Set the `result` field to the provided result object.\n  - If the new status is a completed state and `end_timestamp` is not set, set `end_timestamp` using `date_util.get_datetime_utc_now()`.\n  - Persist the change with `LiveAction.add_or_update(..., publish=False)`, update the corresponding Execution model via `executions.update_execution(updated_liveaction)`, and then publish the LiveAction update with `LiveAction.publish_update(updated_liveaction)`.",
            "Step 8: Wire the trigger to the action via a rule",
            "- Create a rule YAML that listens to the trigger and calls the action, mapping fields from the trigger payload to action parameters (e.g., `action_exec_id: \"{{trigger.id}}\"`, `status: \"{{trigger.status}}\"`, `result: \"{{trigger.result}}\"`).",
            "- Enable the rule so that every dispatched trigger updates the local execution state.",
            "Step 9: Remove or disable the legacy tracker",
            "- Update operational and development scripts (like `launchdev.sh`) to stop starting the old result tracker service (e.g., comment out or remove the `st2resultstracker` screen session).",
            "- Verify that workflow status updates are now handled solely by the sensor/rule/action chain.",
            "Step 10: Validate behavior and edge cases",
            "- Test with workflows that succeed, fail, and get canceled to ensure state mappings and timestamps are correct.",
            "- Confirm that timelines (start/end timestamps) and statuses in the UI and via API match the actual Mistral executions and tasks, especially in boundary cases where Mistral marks workflows complete before all tasks finish.",
            "- Monitor performance: verify that status updates are timely and that the sensor polling interval and last_polled logic prevent unnecessary load or missed updates."
        ]
    }
}