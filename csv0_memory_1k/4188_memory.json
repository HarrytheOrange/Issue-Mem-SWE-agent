{
    "search_index": {
        "description_for_embedding": "Implements a configurable daily catch limit in PokemonGo-Bot by logging each successful catch into a new catch_log table with timestamps, then querying the last 24 hours of data before each catch attempt to enforce a per-24-hour quota. Adds configuration, migrations, and logging/event hooks to avoid hitting server ban thresholds.",
        "keywords": [
            "PokemonGo-Bot",
            "daily catch limit",
            "rate limiting",
            "catch_log table",
            "SQLite datetime window",
            "24 hour quota",
            "configurable limit",
            "yoyo migration",
            "event logging",
            "anti-ban behavior"
        ]
    },
    "agent_memory": {
        "episodic_memory": "Community members observed that catching more than ~1000 Pokémon per 24 hours seemed to correlate with bans. To mitigate this, the PR introduces a daily catch limit mechanism to the PokemonGo-Bot.\n\nConcretely, a new configuration option `daily_catch_limit` (default 800) is added and loaded in `pokecli.py`. All config example files (`config.json.example`, `config.json.cluster.example`, `config.json.map.example`, `config.json.optimizer.example`, `config.json.path.example`, `config.json.pokemon.example`) are updated to expose this setting. Documentation is updated (with a minor typo) to mention the new limit.\n\nA new database table `catch_log` is created via a yoyo migration placed under `pokemongo_bot/cell_workers/migrations/catch_log.py`. The table schema is:\n\n- pokemon (text)\n- cp (real)\n- iv (real)\n- encounter_id (text)\n- pokemon_id (real)\n- dated (datetime DEFAULT CURRENT_TIMESTAMP)\n\nAn earlier migration placed in `pokemongo_bot/migrations/catch_log.py` is deleted in favor of the new location.\n\nIn `pokemon_catch_worker.py`, additional imports are added (`os`, `json`, `logging`, `_base_dir`, `datetime`). Before catching any Pokémon, the worker now queries the database:\n\n```sql\nSELECT DISTINCT COUNT(encounter_id) FROM catch_log WHERE dated >= datetime('now','-1 day')\n```\n\nThis counts distinct encounter IDs logged in the last 24 hours (the `DISTINCT` is used defensively to avoid double-counting in case of duplicate rows). The result is compared against `self.bot.config.daily_catch_limit`. If the count is below the limit, the bot proceeds to perform the catch using the existing `_do_catch` logic. If the limit has been reached or exceeded, it does not attempt the catch and instead emits a `catch_limit` event with a warning message. The `catch_limit` event is registered in `pokemongo_bot.__init__` and wired to display in red in `colored_logging_handler.py`.\n\nWhen a catch is successful (`CATCH_STATUS_SUCCESS`), the bot now logs the capture to two places:\n\n1. Database: using `conn.execute('INSERT INTO catch_log (pokemon, cp, iv, encounter_id, pokemon_id) VALUES (?, ?, ?, ?, ?)', (pokemon.name, pokemon.cp, pokemon.iv, str(encounter_id), pokemon.pokemon_id))` inside `with self.bot.database as conn:`.\n2. File: appending to a per-user JSON lines file at `data/caught-<username>.json` (under `_base_dir`). Each line includes the current timestamp (via `datetime.now()` string) and a small JSON object with `pokemon`, `cp`, `iv`, `encounter_id`, and `pokemon_id`.\n\nIf writing the file fails (IOError), it logs an error via the worker logger. The change overall introduces a DB-backed per-24-hour catch counter with a configurable threshold, plus logging and events to make the behavior visible.\n\nThere are some design details/quirks: the limit is enforced globally (all accounts share one `catch_log` table; there is no per-account field), the SQL uses `DISTINCT COUNT(encounter_id)` instead of `COUNT(DISTINCT encounter_id)`, and the logic is wrapped in a `while True` loop that always breaks after one iteration (effectively an `if/else`). These aspects could be refined in future work (e.g., per-account limits, simplified control flow, more precise SQL).",
        "semantic_memory": "Generalizable lessons and patterns from this change:\n\n1. **Implementing Rate Limits via Persistent Logs**\n   - To enforce a daily or rolling time-window limit, log each successful operation (here, a Pokémon catch) in a persistent store with a timestamp.\n   - Before performing the operation, query the log for actions within the relevant time window (e.g., `WHERE timestamp >= NOW() - INTERVAL 1 DAY`).\n   - Compare the count against a configurable limit; if the limit is reached, skip the operation and notify the user/system.\n   - This pattern is applicable for any quota-like constraint such as API calls, login attempts, emails sent, or resource allocations.\n\n2. **Config-Driven Limits**\n   - Expose operational limits as configuration values (`daily_catch_limit`) instead of hard-coding them. This allows tuning based on empirical data or environment (development vs production vs conservative anti-ban mode).\n   - Provide sensible defaults aligned with observed safe thresholds (e.g., 800 < 1000 to stay under suspected ban triggers).\n   - Ensure configuration is wired through the CLI and demonstrated in example configs so users are aware and can adjust.\n\n3. **Database Migrations and Schema Placement**\n   - When adding new tables (e.g., `catch_log`), create versioned migrations using the project's migration framework (here, yoyo's `step()`), rather than creating tables ad hoc at runtime.\n   - Place migrations in the correct module-path so the migration system discovers them. If a file is mistakenly placed elsewhere, remove or relocate it to avoid duplicate or conflicting migrations.\n\n4. **Separation of Logging and Behavior**\n   - Logging successful actions (DB + file) serves multiple purposes: enforcing limits, auditing behavior, debugging, and post-analysis.\n   - Emitting specific events (`catch_limit`) allows the rest of the system (UI, log handler, or higher-level orchestration) to react appropriately, instead of encoding all responses in the worker logic.\n\n5. **Time-window Queries in SQL**\n   - Using the database's time functions (e.g., SQLite's `datetime('now','-1 day')`) is a simple way to express rolling windows without maintaining in-memory state.\n   - Ensure the timestamp column defaults to the current time (`DEFAULT CURRENT_TIMESTAMP`) so inserts are straightforward.\n   - Be aware of nuances: counting distinct items (`DISTINCT`) vs rows, per-user scoping, and time zone assumptions.\n\n6. **Design Considerations for Multi-Account Systems**\n   - When tracking limits in a shared database, add an account or user identifier column if limits must be per-account rather than global.\n   - Decide whether limits are per IP, per account, per bot instance, or global, and model the schema accordingly.\n\nOverall, the pattern is: \"log each action with timestamps; query by time window; compare with configurable limits; and notify/block when exceeded,\" implemented with proper migrations and event signaling.",
        "procedural_memory": [
            "How to implement or debug a daily action limit based on a logged history:",
            "Step 1: Identify the operation to limit and the time window.",
            "  - Decide what action needs a quota (e.g., 'catch Pokémon', 'send API request').",
            "  - Define the window (e.g., last 24 hours, per hour, per minute).",
            "",
            "Step 2: Design and add a logging table (or collection).",
            "  - Create a schema with at least: an identifier for the action (e.g., pokemon_id or action_type), optional metadata (cp, iv, etc.), and a timestamp column.",
            "  - Example (SQL):",
            "    CREATE TABLE action_log (",
            "      user_id TEXT,",
            "      action TEXT,",
            "      metadata TEXT,",
            "      created_at DATETIME DEFAULT CURRENT_TIMESTAMP",
            "    );",
            "  - Add a migration using the project's migration tool (e.g., yoyo, Alembic, Django migrations) and ensure it is placed in the correct migrations directory.",
            "",
            "Step 3: Wire logging into the success path of the operation.",
            "  - After a successful operation, insert a record into the log table within the existing database transaction/context.",
            "  - Example (Python/SQLite):",
            "    with db as conn:",
            "        conn.execute('INSERT INTO action_log (user_id, action, metadata) VALUES (?, ?, ?)', (user_id, 'catch', json.dumps(meta)))",
            "  - Optionally, also log to a file (JSON lines, CSV) for audit or analytics purposes.",
            "",
            "Step 4: Add a configuration option for the limit.",
            "  - Introduce a new config key (e.g., 'daily_catch_limit') with a safe default.",
            "  - Load it from the config file in the CLI/bootstrap code and attach it to the runtime config object.",
            "  - Update example configuration files and documentation to mention and explain the new option.",
            "",
            "Step 5: Enforce the limit before performing the operation.",
            "  - At the start of the operation, query the log table for the number of actions within the window.",
            "  - Example (SQLite):",
            "    SELECT COUNT(*) FROM action_log",
            "    WHERE user_id = ? AND created_at >= datetime('now', '-1 day');",
            "  - Compare the count to the configured limit:",
            "    if count >= config.daily_limit: skip the action; else proceed.",
            "  - Avoid unnecessary loops; a simple if/else with a clear early-return is sufficient.",
            "",
            "Step 6: Provide feedback via events or logging.",
            "  - Emit a dedicated event when the limit is reached (e.g., 'catch_limit').",
            "  - Register the event in the event manager and map it to an appropriate log color/level in your logging handler.",
            "  - Include a clear message so operators understand why the action was skipped.",
            "",
            "Step 7: Consider multi-user / multi-account scoping.",
            "  - If the system can run multiple accounts, include an account/user identifier in the log schema.",
            "  - Scope the limit query by this identifier; otherwise all accounts will share one global limit.",
            "  - Decide whether limits should be per account, per IP, per process, or global and implement accordingly.",
            "",
            "Step 8: Test the behavior.",
            "  - Run the migration and start the app; verify the `catch_log` (or equivalent) table exists.",
            "  - Perform actions and confirm records are inserted correctly (check timestamps and metadata).",
            "  - Lower the limit for testing (e.g., set to 1 or 2) and verify:",
            "    - The action is allowed until the limit is reached.",
            "    - Subsequent attempts are blocked and the warning event/log appears.",
            "  - Test across process restarts to ensure the limit persists across sessions (thanks to DB-backed logs).",
            "",
            "Step 9: Monitor and refine.",
            "  - Use the logged data to validate that the limit is reasonable and adjust the default or recommended values.",
            "  - If bans or throttling still occur, consider tightening the limit or changing the time window.",
            "  - Refine schema or indexing if queries become slow at scale (e.g., add index on timestamp and user_id)."
        ]
    }
}