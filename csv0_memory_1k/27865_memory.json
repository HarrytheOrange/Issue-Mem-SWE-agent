{
    "search_index": {
        "description_for_embedding": "Home Assistant ebusd integration: fixed non-deterministic sensor updates caused by a shared throttled data fetch method, added configurable cache TTL, and support for multiple ebusd circuits. Throttling is now applied per sensor entity instead of on the shared data client.",
        "keywords": [
            "homeassistant",
            "ebusd",
            "eBUS",
            "sensor update race",
            "Throttle decorator",
            "per-entity throttling",
            "shared resource throttling",
            "cache_ttl configuration",
            "multiple circuits support",
            "MIN_TIME_BETWEEN_UPDATES"
        ]
    },
    "agent_memory": {
        "episodic_memory": "In the Home Assistant ebusd integration, users observed that sensor updates were non-deterministic: some sensors would sporadically fail to update. The root cause was the use of the @Throttle decorator on the shared EbusdData.update method, which serves all sensors. Since @Throttle suppresses calls made within a configured interval, successive sensor update calls routed through this shared method could be silently skipped. This produced a race-like behavior where only some sensors would successfully refresh during each cycle, depending on call timing.\n\nTo resolve this, the PR refactored the integration in several steps:\n1. Introduced a configurable cache TTL (cache_ttl) in the ebusd configuration, replacing the hard-coded 900-second CACHE_TTL constant. The configuration is validated to ensure cache_ttl is not less than MIN_TIME_BETWEEN_UPDATES (15 seconds) to avoid requesting fresher data than the throttling interval.\n2. Added support for multiple ebusd circuits by introducing a circuits list in the config. Each circuit entry includes its circuit id, an optional name, and the monitored_conditions. The setup logic now iterates over all circuits, loading sensors for each and passing the circuit id into the sensor platform and the write service.\n3. Reworked the throttling strategy. The @Throttle decorator was removed from EbusdData.update and moved to the EbusdSensor.update method. EbusdData.update remains a simple function that reads from ebusd for a specific circuit/name/type combination and stores results in a shared value dict. Each EbusdSensor instance now applies @Throttle(MIN_TIME_BETWEEN_UPDATES) to its own update method, so throttling is per-sensor rather than per-shared-data object.\n\nAdditionally, the code centralized MIN_TIME_BETWEEN_UPDATES in const.py, adjusted configuration validation to work with multiple circuits, and updated the ebusd service description to require a circuit field for write operations. After these changes, all sensors have equal opportunity to read from ebusd; no single sensor can starve others due to shared throttling, and the user can tune the cache TTL according to their needs.",
        "semantic_memory": "This fix illustrates a common concurrency and scheduling pitfall in polling-based integrations: applying a global throttle on a shared data-fetch method that serves multiple consumers (e.g., multiple sensors) can create subtle non-determinism and perceived 'race conditions'. When one throttled method is called by many entities, calls made within the throttling window are ignored, which means only some entities will successfully trigger a fetch, and others will see stale or missing data.\n\nA more robust pattern is to throttle at the granularity of each consumer (e.g., each sensor entity) rather than on a shared client method, especially in frameworks like Home Assistant where each entity's update is scheduled independently. Per-entity throttling enforces a minimum fetch interval for each entity while allowing all entities fair access to the shared backend.\n\nAnother key concept is aligning caching policies with throttling behavior. If a backend library has its own cache TTL, that TTL should be configurable and validated relative to the entity update interval to avoid contradictory settings (e.g., requesting updates more frequently than the cache can provide fresh data). Centralizing constants such as MIN_TIME_BETWEEN_UPDATES and using configuration schemas with validation (e.g., voluptuous) helps keep the integration consistent and safe as it grows.\n\nFinally, when external systems support multiple logical channels (like ebusd circuits), the integration should reflect this by allowing multiple circuits in configuration and by passing circuit identifiers through all relevant read/write code paths and services. This avoids hidden, global assumptions (e.g., one circuit only) that complicate extension and debugging.",
        "procedural_memory": [
            "When multiple entities share a throttled data-fetch method and some entities are not updating reliably, suspect shared throttling and race-like behavior in the update pipeline.",
            "Step 1: Identify the shared resource and throttling point.\n- Locate the code where data is fetched for multiple entities (e.g., a shared client or Data class).\n- Check if this shared method is decorated with a throttling mechanism (e.g., @Throttle) or wrapped in rate-limiting logic.\n- Confirm how many entities call this method and how often.\n\nStep 2: Reproduce and observe the issue.\n- Increase logging around the shared update method and per-entity update methods.\n- Observe which entities trigger the underlying fetch and which do not (e.g., some entity updates log calls while others show no fetch activity).\n- Verify that multiple sequential calls to the shared update method within the throttle window cause some calls to be skipped.\n\nStep 3: Redesign throttling to be per-entity rather than per-shared-client.\n- Remove the throttling decorator or logic from the shared data-fetch method (e.g., EbusdData.update).\n- Instead, apply throttling at the entity level (e.g., annotate each sensor's update method with @Throttle(MIN_TIME_BETWEEN_UPDATES)).\n- Ensure that each entity calls the shared data client with enough identifying parameters (e.g., circuit, name, type) so the client can fetch or cache appropriately.\n\nStep 4: Ensure configuration and caching are coherent.\n- If there is an underlying cache TTL (e.g., in a lower-level library like ebusdpy), expose it as a configuration option (cache_ttl) instead of hard-coding it.\n- Validate this TTL relative to your throttling interval (e.g., cache_ttl >= MIN_TIME_BETWEEN_UPDATES.seconds) to prevent users from configuring contradictory values.\n- Centralize common timing-related constants (e.g., MIN_TIME_BETWEEN_UPDATES) in a constants module and import them consistently to avoid drift.\n\nStep 5: Support multiple logical channels cleanly (if applicable).\n- If the external system supports multiple channels/circuits, change the config model to represent them as a list (e.g., circuits: [ { circuit, name, monitored_conditions }, ... ]).\n- Validate each circuit configuration individually (e.g., each monitored condition must be valid for its specific circuit).\n- Pass the circuit identifier through all read and write methods (e.g., update(self, circuit, name, type), write(circuit, name, value)).\n- Update service descriptions and examples to include the circuit field so users know it’s required.\n\nStep 6: Test and verify fairness and determinism.\n- Configure multiple entities (e.g., sensors) that use the shared client and ensure all of them reliably update over time.\n- Confirm via logs that each entity’s update calls the shared client and that throttling is applied individually, not suppressing other entities’ updates.\n- Adjust cache_ttl and MIN_TIME_BETWEEN_UPDATES to realistic values and confirm no validation errors and no unexpected stale data.\n\nStep 7: Document behavior and configuration.\n- Document the meaning and constraints of cache_ttl and the minimum update interval.\n- Explain that throttling is per-entity and that the underlying library may cache results, so users understand the refresh characteristics.\n- If multiple circuits are supported, provide examples in config and service docs that show specifying the circuit for both monitoring and write operations."
        ]
    }
}