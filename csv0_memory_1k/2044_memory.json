{
    "search_index": {
        "description_for_embedding": "Optuna RDBStorage was creating a new SQLAlchemy engine per storage instance, risking exhausting the database's max connections (e.g., PostgreSQL). A proposed fix introduced a global engine factory function `_get_engine` that caches a single `Engine` instance, avoids pickling the engine, and reuses it after unpickling. Ultimately this change was deemed unnecessary because the same effect can be achieved by sharing a single storage instance via `optuna.storages.get_storage(conn_str)`.",
        "keywords": [
            "Optuna",
            "RDBStorage",
            "SQLAlchemy",
            "engine reuse",
            "global engine",
            "connection pool",
            "database connection exhaustion",
            "PostgreSQL max connections",
            "pickling storage",
            "optuna.storages.get_storage",
            "_get_engine",
            "_VersionManager"
        ]
    },
    "agent_memory": {
        "episodic_memory": "The issue revolved around Optuna's RDBStorage creating a SQLAlchemy engine per storage instance, which can lead to many simultaneous database connections when many studies/storages are instantiated (e.g., hitting PostgreSQL's default 100 connection limit). To address this, a pull request introduced a module-level `_engine` variable and a helper `_get_engine(url: str, engine_kwargs: dict) -> Engine` that lazily creates and caches a single SQLAlchemy `Engine`. The RDBStorage constructor (`__init__`) and unpickling logic (`__setstate__`) were changed to call `_get_engine` instead of `create_engine` directly. The engine was removed from the pickled state (`__getstate__` stopped deleting `engine` because it was no longer stored; instead the engine was recreated via `_get_engine` after unpickling). The `_VersionManager` and the SQLAlchemy `scoped_session` were then bound to this shared `engine`. A small follow-up patch fixed a typo by updating `__init__` to call `_get_engine` instead of `create_engine` and added a return type annotation to `_get_engine`. In discussion, however, it was concluded that this global-engine implementation was not necessary. Optuna already allows reusing a single storage (and thereby a single engine/pool) via `optuna.storages.get_storage(conn_str)`. The author demonstrated that you can safely create many studies against the same shared storage without exceeding connection limits. Consequently, the PR was closed without merging, but the episode highlighted both the connection-pool concern and the recommended pattern: reuse a storage instance instead of adding global-engine hacks.",
        "semantic_memory": "When many components of an application create their own database engines or connection pools, you risk exhausting database connections and increasing resource usage unnecessarily. The naive pattern is to call the engine factory (e.g., SQLAlchemy's `create_engine`) inside each object constructor or per operation, which spawns multiple independent pools. A more robust pattern is to share engines/pools across components, either via a factory function, a registry (e.g., per-URL engine cache), a dependency injection container, or a library-provided helper (`get_storage` in Optuna). Sharing a single engine per database URL ensures efficient pooling, avoids connection storms, and simplifies connection management. However, introducing ad-hoc global singletons has pitfalls: a single global engine ignores differences in URLs or engine configuration, may break under multiprocessing, and complicates test isolation. Additionally, ORM engines and sessions are typically not pickle-friendly; correct patterns involve excluding them from serialized state and recreating them lazily after unpickling. The generalizable lesson is: (1) avoid creating many duplicate connection pools; (2) prefer explicit sharing or a well-designed cache keyed by configuration over unscoped module-level singletons; and (3) treat ORM engines/sessions as runtime resources, not persistent state, reinitializing them on deserialization.",
        "procedural_memory": [
            "Step-by-step instructions on how to diagnose and fix similar issues.",
            "Step 1: Detect symptoms of connection overuse.\n- Observe database errors such as 'too many connections' or connection timeouts when scaling up the number of concurrent tasks or objects using the database.\n- Inspect the database's active connection count (e.g., in PostgreSQL, query `pg_stat_activity`) while your application creates many storage/ORM instances.",
            "Step 2: Inspect how database engines/pools are instantiated.\n- Search the codebase for where `create_engine` (or equivalent DB engine/pool constructor) is called.\n- Check if this call occurs inside frequently constructed objects (e.g., per-request, per-study, per-job), which suggests many engines/pools are being created.\n- In serialization logic (`__getstate__/__setstate__`, pickling, joblib, etc.), verify whether engine/session objects are being serialized and recreated on every unpickle.",
            "Step 3: Confirm engine duplication in runtime behavior.\n- Add logging or debugging information around engine creation (e.g., log when `create_engine` is called with a given URL).\n- Run a stress test that creates many objects (e.g., many Optuna studies or storage instances) and check how often engine creation logs appear.\n- Cross-check with database metrics: if each engine uses its own pool, active connection counts may scale with object count.",
            "Step 4: Choose a sharing strategy instead of new engines per instance.\n- Prefer an existing library-level factory that returns a shared storage/engine when available. For Optuna, use `optuna.storages.get_storage(conn_str)` and reuse that storage when creating multiple studies instead of calling `create_study` with a bare URL each time.\n- If no such helper exists, implement an engine cache keyed by connection parameters (`(url, frozenset(engine_kwargs.items()))`), rather than a single global engine, so different databases/configs get distinct pools.",
            "Step 5: Refactor constructors to use the shared engine/storage.\n- Replace direct `create_engine(url, **engine_kwargs)` calls in constructors with a helper that retrieves or constructs a shared engine:\n  - Either inject the engine/storage via dependency injection (preferred for testability), or\n  - Use a factory/registry function like `_get_engine(url, engine_kwargs)` that returns a cached engine.\n- Ensure that sessions (`scoped_session` / `sessionmaker`) and version managers or other DB helpers are bound to the shared engine.",
            "Step 6: Handle serialization correctly.\n- Do not include non-serializable runtime resources like engines and sessions in the pickled state.\n- In `__getstate__`, remove/omit engine and session objects.\n- In `__setstate__`, lazily recreate engine and sessions from configuration fields such as `url` and `engine_kwargs` using your shared engine factory, then reinitialize dependent components (e.g., version manager, metadata creation).",
            "Step 7: Validate behavior after refactor.\n- Re-run the workload that previously exhausted connections and confirm that the number of database connections remains bounded and stable.\n- Ensure functionality is unchanged: all operations using the shared engine/storage still work, and migrations/metadata creation still occur correctly.\n- Add tests (if feasible) that create many logical objects (studies/storages) and assert that engine creation is invoked at most a small number of times (e.g., once per unique URL).",
            "Step 8: Avoid overly broad global singletons.\n- Be cautious about implementing a single module-level global engine without regard to URL or configuration; this can cause unexpected cross-contamination between databases or tests.\n- Prefer more controlled patterns (registry keyed by configuration, injected dependencies, or documented library helpers like `get_storage`) over unscoped globals for production-quality code."
        ]
    }
}