{
    "search_index": {
        "description_for_embedding": "CI was intermittently failing with segfaults in Qt/vispy-based tests, especially the performance monitoring (perfmon) and sys_info tests. The fix switched to running tests under an Xvfb GitHub Action, reworked the perfmon test to run napari in a subprocess using NAPARI_PERFMON config, and ensured sys_info runs with a pytest Qt application fixture, eliminating segfaults both in CI and locally.",
        "keywords": [
            "CI failure",
            "segfault",
            "Qt",
            "PySide2",
            "vispy",
            "perfmon",
            "performance tracing",
            "QApplication",
            "xvfb",
            "GabrielBB/xvfb-action",
            "pytest",
            "qapp fixture",
            "NAPARI_PERFMON",
            "subprocess testing",
            "sys_info",
            "napari"
        ]
    },
    "agent_memory": {
        "episodic_memory": "In this incident, the napari project’s CI was showing inconsistent behavior and segfaults when running Qt/vispy-related tests, particularly around performance monitoring (perfmon) and the sys_info utility. Some configurations, especially on Linux/Windows with PySide2 or Python 3.9, would crash rather than cleanly fail tests. Locally, developers also observed segfaults when running the perfmon and sys_info tests. Originally, the perfmon test instantiated a custom QApplicationWithTracing inside the test process and relied on special ordering (running this test last) due to the difficulty of tearing down such a QApplication safely. Additionally, the sys_info test could trigger vispy’s use_app behavior, which tried to start Qt in an unsafe way and caused crashes on CI.\n\nThe fix took several steps and iterations:\n\n1. **Xvfb for all Qt tests in CI**: The GitHub workflows were updated so that the main test job runs `tox` under the `GabrielBB/xvfb-action@v1` wrapper. This provides a virtual X display for headless environments, making Qt/vispy usage much safer. The prerelease and comprehensive workflows, as well as the pip-install smoke-test job, were similarly wrapped in the Xvfb action. Once that was done, the explicit `pytest-xvfb` dependency was removed from `tox.ini`, since the display layer is now managed at the CI level.\n\n2. **Rewriting the perfmon test to use a subprocess**: The previous perf test (in `napari/_qt/perf/_tests/test_perf.py`) created a `QApplicationWithTracing` and monkey-patched the perf timer inside the test process. This required special test ordering and was fragile, causing segfaults on some platforms. The new approach writes a small Python script (PERFMON_SCRIPT) that:\n   - Imports napari,\n   - Opens a simple viewer (`napari.view_points()`),\n   - Uses a Qt `QTimer.singleShot` to quit the app after a short delay, and\n   - Runs the Qt event loop via `napari.run()`.\n\n   The perf test now:\n   - Creates a `perfmon.json` config file in a temporary directory, configuring `trace_qt_events`, `trace_file_on_start` (pointing to a temp `trace.json`), and a list of callables to trace.\n   - Sets environment variables `NAPARI_PERFMON` to point to that config and `NAPARI_CONFIG` to an empty string (so napari doesn’t touch user config).\n   - Runs the small script in a **subprocess** via `subprocess.run([sys.executable, '-c', PERFMON_SCRIPT], env=env, check=True)`.\n   - After the subprocess exits, asserts that `trace.json` exists, is non-empty, and that each trace event contains the required fields (`pid`, `tid`, `name`, `ph`, `ts`, `args`).\n\n   This isolates the performance tracing logic in a separate process, avoids messing with the current test process’ QApplication lifecycle, and no longer requires special global test ordering. The test is also decorated with `@skip_local_popups` to avoid unwanted local popups.\n\n3. **Stabilizing sys_info test with a Qt app fixture**: The `sys_info` test was moved into `napari/_tests/test_sys_info.py` and changed from a pure function call to `test_sys_info(qapp)`. By requiring the `qapp` pytest fixture, the test ensures there is a properly initialized Qt application context before calling `sys_info()`. This prevents vispy’s `use_app` from trying to start Qt in an unsafe way, which had previously produced segfaults in headless CI. The test still asserts the expected behavior (plain text vs HTML and the presence of “Plugins”), but now runs reliably.\n\n4. **Restoring temporarily disabled Qt tests**: During investigation, several Qt-related test modules (`test_threading.py`, `test_threading_progress.py`, `test_qt_notifications.py`, `test_progress.py`) were fully commented out to narrow down the cause of the segfaults. Once the Xvfb-based CI setup and the new perf and sys_info strategies proved stable, these tests were fully restored to their original content.\n\n5. **Minor related changes**:\n   - The performance dock creation in `qt_viewer` was slightly modified to remove a hard-coded `Ctrl+Shift+P` shortcut for the performance widget (likely to avoid potential conflicts, though not directly tied to the crashes).\n   - Codecov’s allowed coverage drop threshold was relaxed from 0.5% to 1% to reduce spurious coverage failures.\n   - The CI workflow jobs for code quality (flake8, black, isort, import-lint), manifest checking, localization syntax checks, and pip-install smoke tests were restored to their normal behavior after temporary simplifications during debugging.\n\nAfter these changes, the CI stopped encountering the earlier segfaults, and a team member confirmed that the tests also stopped ending with segfaults on their local machine.",
        "semantic_memory": "This fix highlights several generalizable patterns for dealing with GUI frameworks, Qt/vispy, and performance instrumentation in automated test environments:\n\n1. **Use a virtual display for GUI tests in headless CI**: When running tests that interact with Qt or any GUI toolkit in CI, running them in a truly headless environment without a display server can lead to crashes or undefined behavior. The correct pattern is to run tests under a virtual display such as Xvfb. On GitHub Actions, wrapping test commands in an action like `GabrielBB/xvfb-action` is usually more reliable and simpler than using per-test workarounds like `pytest-xvfb`.\n\n2. **Isolate complex GUI instrumentation tests into subprocesses**: Tests that heavily instrument the GUI event loop (e.g., by overriding QApplication.notify or installing low-level performance timers) are fragile when run in the main test process. By moving such tests into a subprocess and launching the application there, the main test process remains clean. This encapsulation prevents lingering global state (like an overridden QApplication) from affecting other tests and makes it safer to start/stop the Qt event loop.\n\n3. **Always ensure a valid Qt application context before calling GUI-dependent utilities**: Utilities like `sys_info()` that indirectly trigger `vispy.use_app()` or other environment-dependent logic should be tested only in the presence of an explicit Qt application (via a fixture such as `qapp`). Without this, the utility may try to create its own application in a way that conflicts with the test runner or headless CI, causing segfaults. Making the test explicitly depend on a `qapp` fixture ensures a consistent, safe environment.\n\n4. **Avoid relying on fragile global test ordering**: The original perf test required being run last due to tricky QApplication teardown and notify overrides. Relying on global test order is brittle and hard to maintain. Instead, design tests to be self-contained (e.g., using subprocesses, fixtures that create and tear down their own environment) so they can run in any order.\n\n5. **Prefer environment-driven configuration for integration tests**: For features like perf tracing, configuring the system via environment variables and config files (e.g., `NAPARI_PERFMON`, `NAPARI_CONFIG`) makes it easier to programmatically drive the application from tests and from separate processes, rather than reaching into internal state.\n\n6. **Use CI-level tools instead of test-level hacks where possible**: Moving from `pytest-xvfb` inside tox to using Xvfb at the workflow level simplifies configuration and keeps test environments closer to how the app is actually used. CI workflows become the right place to configure OS-level dependencies (X server, libraries) rather than encoding those details into test code.\n\n7. **Coverage and CI stability tradeoffs**: It can be reasonable to relax strict coverage thresholds slightly (e.g., allowing a 1% drop) to avoid spurious CI failures, especially when changes introduce or rearrange complex tests like GUI integration tests that are hard to measure perfectly.",
        "procedural_memory": [
            "Step-by-step approach to diagnosing and fixing Qt/GUI-related CI segfaults and perf tracing test instability:",
            "Step 1: Reproduce and localize the failures.\n- Observe where CI is failing: look for segfaults, abrupt test process termination, or tests that hang around Qt/vispy or performance monitoring logic.\n- Run the problematic tests locally with increased verbosity, and if possible, under a headless-like environment (e.g., using Xvfb locally) to mirror CI conditions.",
            "Step 2: Check for missing or incorrect display configuration.\n- Verify whether tests that create Qt windows are running in a headless environment without a display.\n- If so, configure a virtual display for all test runs:\n  - On GitHub Actions, wrap your test command using an Xvfb action such as:\n    - `uses: GabrielBB/xvfb-action@v1`\n    - `with: run: tox` (or your test command).\n  - Remove redundant per-test-level Xvfb workarounds (e.g., `pytest-xvfb`), unless they are still needed for local environments.",
            "Step 3: Ensure tests requiring Qt use a proper Qt app fixture.\n- For tests that call utilities that may indirectly start Qt (e.g., via vispy’s `use_app()`), make sure they depend on a `qapp` pytest fixture.\n- Example pattern:\n  - `def test_sys_info(qapp):`\n  - Call your utility (e.g., `sys_info()`) inside this test so that a valid QApplication already exists.\n- This avoids having multiple or inconsistently created QApplications, which can lead to segfaults, especially in headless CI.",
            "Step 4: Isolate performance tracing / QApplication-instrumentation into a subprocess.\n- If a test needs to override QApplication.notify, install performance timers, or exercise complex GUI instrumentation, avoid doing it in the main test process.\n- Instead:\n  - Write a small script string that runs your application in the desired way (e.g., opens a viewer, sets a QTimer to quit after N milliseconds, then calls the main event loop).\n  - From the test, create a temporary configuration file (e.g., a JSON for perfmon) with appropriate settings, including where to write output (trace files).\n  - Set environment variables in the test (e.g., `NAPARI_PERFMON` pointing to the config, `NAPARI_CONFIG` to a neutral value).\n  - Use `subprocess.run([sys.executable, '-c', SCRIPT], env=env, check=True)` to run the script in a separate process.\n  - After the subprocess exits, assert on the existence, non-emptiness, and structure of any produced artifacts (trace files, logs, etc.).",
            "Step 5: Remove reliance on global test ordering.\n- Eliminate patterns where a particular test must be run last or first.\n- If a test previously modified global state (like a custom QApplication subclass), refactor it so that it runs in its own process or uses fixtures with proper setup/teardown.\n- Delete any `pytest_collection_modifyitems` hacks that reorder tests, once tests are self-contained.",
            "Step 6: Restore and verify previously disabled tests.\n- If you temporarily commented out or skipped large parts of your test suite to isolate the issue, gradually re-enable them after fixing the root causes.\n- Run the entire test suite locally and in CI, ideally across the key platforms (Linux, Windows, macOS) and Python versions that were problematic before.",
            "Step 7: Adjust CI configuration and coverage expectations.\n- Once CI is stable, verify workflows include:\n  - Xvfb wrapping where GUI tests are run.\n  - Necessary OS libraries installed (e.g., `libxcb-*` on Linux for Qt).\n  - Any pip-install smoke tests wrapped in Xvfb as well.\n- Optionally relax coverage thresholds slightly in tools like Codecov (`threshold: 1%`) to avoid failures from minor coverage fluctuations introduced by new or reorganized tests.",
            "Step 8: Document environment-driven behavior for future maintainers.\n- Document the meaning of environment variables like `NAPARI_PERFMON` and `NAPARI_CONFIG`, and how they are used in tests.\n- Note any gotchas (e.g., a certain test requires the viewer to be shown in the subprocess to avoid segfaults) so future changes don’t reintroduce hidden instability."
        ]
    }
}