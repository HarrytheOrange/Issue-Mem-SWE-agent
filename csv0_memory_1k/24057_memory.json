{
    "search_index": {
        "description_for_embedding": "Home Assistant integration for Stockholm public transit (SL) via the HASL library. Adds a `hasl` sensor platform with multiple sensor types (departures, system status, train location, version). Implements shared in-memory and file-based caching of API responses, configurable throttling via scan_interval and `Throttle`, and an optional external enable/disable sensor. Exposes a `hasl.clear_cache` service to reset cache and force fresh API calls.",
        "keywords": [
            "homeassistant",
            "hasl",
            "SL",
            "public transit",
            "Stockholm",
            "sensor platform",
            "departures",
            "status",
            "train location",
            "api caching",
            "Throttle",
            "scan_interval",
            "hass.data",
            "clear_cache service",
            "requirements_all",
            "manifest.json"
        ]
    },
    "agent_memory": {
        "episodic_memory": "This pull request adds a new Home Assistant integration for Stockholm public transit (SL) using the external `hasl` Python package (version 2.2.0). The new domain `hasl` is introduced with a manifest and multiple sensor entities: departure boards (`SLDeparturesSensor`), traffic status (`SLStatusSensor`), train location (`SLTrainLocationSensor`), and a version sensor (`SLVersionSensor`). The platform supports configuration via `configuration.yaml`, including SL API keys (RI4, SI2, TL2), site IDs, lines, directions, traffic classes, train types, and sensor properties such as `min`, `time`, `deviations`, `refresh`, and `updated`.\n\nTo avoid excessive API usage and share data across sensors, the implementation combines three layers of rate limiting and caching: Home Assistant's `scan_interval`, the `Throttle` decorator wrapped around `_update` methods, and a manual cache stored both in `hass.data[DOMAIN]` (to track last update timestamps) and in a JSON file (`haslcache.json`) for response payloads. Each API type (RI4, SI2, TL2) uses a unique cache key that includes its API key and site ID. Before making a network request, the sensor checks whether valid cached data exists and whether API minimization is enabled; if so, it reuses the cached response instead of hitting the API again.\n\nThe component's `__init__.py` registers a `hasl.clear_cache` service. This service clears all cached entries from `hass.data[DOMAIN]` and truncates `haslcache.json` to an empty JSON object. On the next sensor refresh, all sensors will re-fetch data from the SL APIs. In addition, many of the sensors accept an `enabled_sensor` entity ID; when provided, they only update while that referenced entity’s state is `on`, enabling conditional API usage (for example, only fetching departures while someone is home).\n\nThe PR also updates `.coveragerc` to omit the new `homeassistant/components/hasl/*` integration from coverage statistics and adds the `hasl` library to `requirements_all.txt`. The `CODEOWNERS` file is updated to assign ownership of the `hasl` component to the contributor. Overall, this PR demonstrates how to implement a multi-sensor Home Assistant integration backed by a shared, minimized API access pattern and a custom maintenance service.",
        "semantic_memory": "Generalizable insights from this change revolve around building Home Assistant integrations that communicate with external web APIs while minimizing API calls and exposing multiple logical views as separate sensors:\n\n1. **Designing a multi-sensor platform component**: A single sensor platform (`hasl`) can expose several distinct sensor types by interpreting a `sensor_type` config option (`departures`, `status`, `trainlocation`, etc.). In `setup_platform`, you loop over configured sensor blocks, choose the appropriate sensor class based on `sensor_type`, and instantiate entities with type-specific parameters (API keys, site IDs, traffic classes, etc.). This pattern is reusable for any integration that has multiple logical data views backed by a shared API.\n\n2. **Combining throttling and custom caching**: Relying solely on `scan_interval` or `Throttle` is often insufficient if multiple entities share the same external API. This integration uses both `Throttle(interval)(self._update)` to limit calls per entity and a shared cache in `hass.data[DOMAIN]` plus an on-disk JSON cache. Before hitting the API, it consults a last-update timestamp; if the same API data was fetched recently, it reuses the cached payload. This pattern is essential when dealing with rate-limited or credit-based APIs and can be adapted to other integrations.\n\n3. **Per-API cache keying**: The use of compound keys like `ri2_<ri4key>_<siteid>` and `si2_<si2key>_<siteid>` ensures that each unique API/parameter combination has its own cache entry. This is a general best practice when caching external API responses in a shared store (memory or disk), preventing cross-contamination between sensors that query different endpoints or locations.\n\n4. **Optional external enable/disable control**: Several sensor classes accept an `enabled_sensor` entity ID. The update logic checks the referenced entity and only performs API calls while its state is `on`. This is a flexible pattern to tie expensive or noisy updates to a user-defined condition (e.g., presence, schedule, or manual switch), and can be reused in other integrations that should be conditionally active.\n\n5. **Exposing maintenance operations as services**: The `hasl.clear_cache` service wraps internal cache-reset logic (clearing in-memory data and the JSON cache file) in a user-invocable Home Assistant service. This is a robust pattern: whenever an integration maintains local cache or derived data, it can provide a service to reset or rebuild that state without requiring a restart.\n\n6. **Configuration schema with voluptuous**: The component uses `PLATFORM_SCHEMA` extended with `vol.Optional`, `vol.Required`, `vol.In`, `vol.Range`, and `cv.time_period`/`cv.positive_timedelta` to validate configuration. This ensures that user-provided YAML is checked at startup and that types and allowed values are constrained. This is a reusable approach for any integration: define a strict schema to avoid runtime errors and simplify assumptions inside the entity code.\n\n7. **Representing rich data as attributes**: Instead of overloading the main sensor state, detailed structures (e.g., departure lists, deviation lists, status events) are placed into `device_state_attributes` (or `extra_state_attributes` in newer HA). The state itself remains a simple, human-readable value (e.g., minutes until next departure, last update timestamp). This pattern can be generalized to any entity that has both a primary numeric or string state and a richer data payload.\n\n8. **Home Assistant integration structure**: The PR demonstrates the full set of files needed to add a new integration: `manifest.json` (domain, name, documentation, requirements, codeowners), the component code under `homeassistant/components/<domain>/`, an entry in `requirements_all.txt`, a `services.yaml` describing services, and proper CODEOWNERS. This structure is common to any new Home Assistant integration and can be used as a template.",
        "procedural_memory": [
            "Step-by-step instructions on how to diagnose and fix or implement similar Home Assistant integrations with shared API access and caching:",
            "Step 1: Define the integration domain and manifest\n- Choose a unique domain (e.g., `hasl`).\n- Create `homeassistant/components/<domain>/manifest.json` specifying:\n  - `domain`, `name`, `documentation` URL.\n  - `requirements` list with any external Python packages.\n  - `codeowners` and `dependencies` as needed.\n- Add the requirement to `requirements_all.txt` with a comment noting the component that uses it.",
            "Step 2: Implement the component package and services\n- Create `homeassistant/components/<domain>/__init__.py` and set up the integration domain constant and any module-level version info.\n- Use `setup(hass, config)` to initialize `hass.data[DOMAIN]` as a shared in-memory store.\n- If you maintain cache or derived data, implement a service (e.g., `clear_cache`) that resets it.\n- Register the service via `hass.services.register(DOMAIN, 'clear_cache', handler)`.\n- Document these services in `homeassistant/components/<domain>/services.yaml` so they appear in Home Assistant’s UI.",
            "Step 3: Define a robust configuration schema\n- In `sensor.py` (or equivalent platform file), import `PLATFORM_SCHEMA` and extend it with your integration-specific options.\n- Use `vol.Required` and `vol.Optional` with appropriate validators (e.g., `cv.string`, `cv.boolean`, `cv.time_period`, `vol.In`, `vol.Range`).\n- For composite configurations like `sensors`, use `vol.All(cv.ensure_list, [vol.Schema({...})])` and restrict allowed values for things like `sensor_type`.\n- Validate API keys, IDs, and nested options at configuration time to prevent runtime errors.",
            "Step 4: Implement sensor classes for each logical data view\n- For each type of data (departures, status, train location, version), create a dedicated `Entity` subclass.\n- In `setup_platform`, loop over the configured sensors, inspect `sensor_type`, and instantiate the appropriate class with the correct subset of configuration parameters.\n- Provide the `name`, `state`, and `device_state_attributes` (or `extra_state_attributes`) properties for each sensor.\n- Use the state for a single concise value (e.g., minutes until next departure or last update timestamp) and attributes for structured data (lists of departures, deviations, events).",
            "Step 5: Integrate external APIs with caching and throttling\n- Import the external API client(s) from your dependency (e.g., `from hasl import ri4api, si2api, tl2api, fpapi`).\n- Instantiate API clients in each sensor’s constructor with required keys and parameters.\n- Wrap the internal `_update` method with `self.update = Throttle(interval)(self._update)` to enforce per-entity rate limiting.\n- Use `scan_interval` in configuration as the `interval` passed to `Throttle` to give users control over the update frequency.",
            "Step 6: Implement shared in-memory and file-based caching\n- Use `hass.data[DOMAIN]` to store last update times for each API/parameter combination. Build a unique cache key for each distinct query (e.g., `f\"ri4_{ri4key}_{siteid}\"`).\n- Before making an API call, check whether `hass.data[DOMAIN][cache_key]` exists and whether `now() - last_update < interval` (and whether API minimization is enabled).\n- If data is still fresh and minimization is enabled, reuse cached response data instead of hitting the API again.\n- For resilience across restarts, optionally maintain a JSON cache file (e.g., `haslcache.json` in the configuration directory). Implement `getCache(key)` and `putCache(key, value)` helpers to read/write this file.\n- Handle file I/O errors gracefully and default to empty structures if the cache cannot be read.",
            "Step 7: Add conditional update control via an external sensor\n- Accept an `enabled_sensor` config option that references another entity ID (e.g., a toggle or presence sensor).\n- At the beginning of your `_update` method, retrieve that entity’s state with `self._hass.states.get(self._enabled_sensor)`.\n- Only perform API calls when the referenced entity is `on` (or in whatever state you choose as 'enabled').\n- Expose this as an attribute (e.g., `refresh_enabled`) so users can see whether updates are currently active.",
            "Step 8: Parse and normalize API-specific data\n- When the external API returns human-readable times or mixed formats (like 'Nu', '5 min', or 'HH:MM'), implement a parser function that converts these into normalized values (e.g., minutes until departure).\n- For list-based results, post-process each item into a consistent structure: include line numbers, destinations, directions, time differences, expected timestamps, and an icon.\n- Apply filters based on config parameters (e.g., limit departures by line, direction, or time window before adding them to the sensor’s attribute list).",
            "Step 9: Add icons, translations, and derived attributes\n- Create lookup tables to map API status codes to human-friendly labels (e.g., 'EventGood' -> 'Good') and to Home Assistant Material Design icons (e.g., 'EventMajor' -> 'mdi:close').\n- For each traffic type or event, set a type-specific icon to improve UI readability.\n- Compute derived attributes such as `deviation_count`, `next_departure_minutes`, `next_departure_time`, and formatted `last_refresh` timestamps for use in automations and dashboards.",
            "Step 10: Wire up repository metadata and ownership\n- Add the new component path to `CODEOWNERS` so someone is clearly responsible for maintenance.\n- If coverage should not block merging initially, add the component path to `.coveragerc` under `omit` (with the intention to add targeted tests later).\n- Ensure all lints and tests pass (`tox`) before submitting.",
            "Step 11: Diagnose issues in similar components\n- If a multi-sensor integration is making more API calls than expected, inspect whether `Throttle` is applied correctly and whether caching keys really match per query.\n- Check `hass.data[DOMAIN]` to verify that last update timestamps are being set after successful API calls.\n- Confirm that the cache file path is correct and that the JSON is valid; implement error handling for corrupted cache files.\n- Use Home Assistant’s developer tools to inspect sensor attributes and confirm that expected fields (departures, deviations, events, last_refresh) are being populated correctly.\n- If data appears stale, ensure that API minimization logic is not overly aggressive (consider comparing intervals and toggling a config flag like `api_minimization`)."
        ]
    }
}