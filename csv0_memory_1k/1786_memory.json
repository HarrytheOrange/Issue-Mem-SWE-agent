{
    "search_index": {
        "description_for_embedding": "Experimental MutualInformationImportanceEvaluator for Optuna using multivariate Parzen estimators. It estimates parameter importance via mutual information between parameters and objective scores, supports both sample-average and Monte Carlo mutual information estimation, and handles various Optuna distributions (uniform, log-uniform, discrete/int uniform, int-loguniform, categorical). The PR was closed due to instability and credibility concerns (negative or uninformative MI estimates), but includes an implementation pattern for KDE-based MI and multivariate Parzen sampling/log-pdf.",
        "keywords": [
            "Optuna",
            "MutualInformationImportanceEvaluator",
            "parameter importance",
            "mutual information",
            "Parzen estimator",
            "multivariate TPE",
            "KDE",
            "Monte Carlo estimation",
            "log_pdf",
            "sampling",
            "categorical distribution",
            "Scott's rule",
            "importance evaluation instability"
        ]
    },
    "agent_memory": {
        "episodic_memory": "This PR attempted to introduce a new parameter importance evaluator into Optuna, named MutualInformationImportanceEvaluator. The idea was to measure the importance of each hyperparameter by estimating the mutual information (MI) between that parameter and the objective score using multivariate Parzen estimators, adapted from the multivariate TPE implementation.\n\nInitial implementation: The first version constructed Parzen estimators for: (1) the score alone, (2) each parameter alone, and (3) the joint of each parameter with the score. It then used a sample-average estimate of mutual information:\n\n  I(X;Y) ≈ E[ log p^(x,y) - log p^(x) - log p^(y) ],\n\nwhere p^ are Parzen KDEs evaluated at the observed (parameter, score) samples. This estimate was computed directly from the trials: complete, pruned, and their intermediate values. Scores for pruned trials were encoded as (step, value)-like pairs (using a tuple ordering scheme) to incorporate partial information.\n\nProblems observed: The sample-average MI estimator could yield negative mutual information due to estimator bias and finite sample noise. On benchmarks, the resulting importance values were sometimes unstable or inconsistent with existing importance evaluators (e.g., FanovaImportanceEvaluator). After the PR author re-ran experiments, they found:\n- Sample-average estimation produced unstable and sometimes negative MI values.\n- Monte Carlo-based estimation (discussed below) produced strictly positive but often small and less discriminative MI values, making the importance ranking less informative.\n\nMonte Carlo enhancement: To address negative MI estimates, a second approach was added. A sample method was implemented for _MultivariateParzenEstimator, enabling Monte Carlo sampling from the estimated joint distribution p^(x, y). The MutualInformationImportanceEvaluator gained a constructor argument n_MC:\n- If n_MC is None: use the original sample-average estimate over the observed trials.\n- If n_MC is set: sample n_MC points from the joint Parzen estimator (param, score), then compute MI as an expectation over those samples:\n\n  I(X;Y) ≈ E_{(x,y) ~ p^(x,y)}[ log p^(x,y) - log p^(x) - log p^(y) ],\n\nwhere p^(x) and p^(y) are estimated with separate Parzen estimators. This Monte Carlo approach avoids negative MI in expectation but tended to flatten differences between parameters, producing less informative importance scores.\n\nParzen estimator refactor: To support the Monte Carlo path and general robustness, _MultivariateParzenEstimator was expanded and corrected:\n- Introduced sample(rng, size) to draw from the mixture-of-kernels KDE:\n  - For numeric distributions, it samples a kernel index according to the mixture weights and then samples from a truncated normal (scipy.stats.truncnorm) within the parameter bounds.\n  - For categorical distributions, it samples according to per-kernel categorical probabilities.\n- Implemented _transform_to_uniform and _transform_from_uniform that map between the internal KDE space and original Optuna distributions:\n  - Log transforms for LogUniform and IntLogUniform.\n  - Proper rounding/clipping for DiscreteUniform, IntUniform, and IntLogUniform to respect grid/step constraints and bounds.\n- Renamed _n_observations to _n_weights to reflect that KDE components (kernels) correspond to observed points plus an optional prior kernel.\n- Implemented _calculate_weights based on the new _n_weights and optional prior weight, normalizing to a mixture distribution.\n- Implemented _precompute_sigmas0 using Scott's rule with a configurable magnitude factor (default 0.2), computing initial bandwidth per sample.\n- Implemented _calculate_categorical_params and _calculate_parzen_est_params to create, respectively, categorical kernel weights and Gaussian kernel means/bandwidths per parameter, accounting for optional prior and magic clipping of sigmas.\n- Implemented _sample_from_categorical_dist to sample indices from categorical probability vectors.\n\nOrdering of results: The evaluator returns importances sorted descending by MI value, now as an OrderedDict rather than a plain dict, preserving sort order for downstream consumers.\n\nOutcome: After discussions and experiments, the author concluded that the mutual information-based importance evaluator, in its current form, had too many issues (unstable estimates, questionable credibility, and less benefit over existing methods). Instead of merging, they decided to close this PR and open a dedicated issue to discuss the concept further (Issue #1794). No bug in production code was fixed; rather, an experimental feature was prototyped, evaluated, and ultimately not merged due to quality concerns.",
        "semantic_memory": "Generalizable insights from this episode:\n\n1. Mutual information estimation via KDE is delicate\n- Estimating mutual information from finite samples using KDE/Parzen estimators is highly sensitive to bandwidth choice, boundary handling, and sample size.\n- Naive sample-average MI estimates (E[log p^(x,y) - log p^(x) - log p^(y)]) can produce negative values due to estimator bias and noise, even though true mutual information is non-negative.\n- Monte Carlo integration over an estimated joint distribution (sampling from p^(x,y)) can reduce negative estimates but may still suffer from bias and variance tradeoffs, sometimes producing uniformly small MI scores that are not informative for ranking parameters.\n\n2. Valid importance metrics need both stability and interpretability\n- An importance evaluator used in practice must not only be theoretically appealing but also empirically stable and interpretable across realistic datasets and benchmarks.\n- If a new importance metric is inconsistent with existing, more established evaluators (e.g., fANOVA) and yields erratic or counterintuitive rankings, it may not be suitable for production despite an elegant formulation.\n\n3. Multivariate Parzen estimators for mixed distributions\n- A reusable pattern for implementing multivariate Parzen estimators in hyperparameter optimization is:\n  - Represent each parameter in an internal continuous space where possible, via transformations (e.g., log for log-uniform).\n  - Use mixture of Gaussian kernels (possibly truncated) for numeric dimensions, and mixture of categorical distributions for categorical dimensions.\n  - Use an initial bandwidth strategy like Scott's rule with an adjustable magnitude to scale sigmas with number of samples and dimensionality.\n  - Include an optional prior component (a broad kernel) to avoid degenerate behavior when few observations are present.\n  - Ensure transformations back to the original domain respect discrete grids and bounds (rounding, clipping).\n\n4. Design of probabilistic APIs for importance and sampling\n- Having the Parzen estimator expose both log_pdf and sample makes it applicable both for density-based scoring (e.g., TPE-like acquisition) and for Monte Carlo estimation of derived information-theoretic quantities (like mutual information).\n- Explicitly tracking the number of mixture components (_n_weights) separately from higher-level concepts like \"observations\" avoids confusion when prior components are added.\n- When returning ranked results (such as parameter importances), using an ordered mapping (OrderedDict or a stable list structure) is preferable to plain dicts, because consumers often rely on ranking.\n\n5. Experimental features should be validated before integration\n- Even when a feature is implemented correctly from a mathematical perspective, empirical validation (benchmarking, comparison to existing tools, stability analysis) is critical.\n- If a feature shows significant instability or unclear benefit, it is better to keep it out of the main API and move discussion to an issue, instead of merging and having to maintain a questionable feature.\n\nThese patterns and lessons apply beyond Optuna: any system that uses KDE-based MI estimation, importance ranking, or TPE-style samplers will face similar design and validation challenges.",
        "procedural_memory": [
            "Step-by-step instructions for designing, validating, and debugging a mutual-information-based importance evaluator using Parzen estimators:",
            "Step 1: Clarify the estimator definition",
            "Decide precisely how mutual information will be estimated. For example: I(X;Y) ≈ E[log p^(x,y) - log p^(x) - log p^(y)] where p^ are Parzen KDEs. Specify whether the expectation is over observed data points (sample-average estimator) or over samples drawn from an estimated distribution (Monte Carlo estimator).",
            "Step 2: Implement a robust multivariate Parzen estimator",
            "Implement a reusable multivariate KDE that supports your parameter types:",
            "- For numeric parameters (uniform, log-uniform, int/discrete), transform them into a continuous internal space (e.g., log for log-uniform).",
            "- Use Gaussian kernels with bandwidth determined by a rule like Scott's rule, optionally scaled by a tunable constant.",
            "- Enforce bounds by using truncated Gaussians when sampling, and use CDF differences when computing discretized log-probabilities.",
            "- For categorical parameters, model each kernel as a categorical distribution over choices, with probabilities derived from counts plus optional priors.",
            "- Provide both log_pdf(samples) and sample(rng, size) methods so that you can use the KDE for scoring and Monte Carlo integration.",
            "Step 3: Handle transformations and discrete constraints correctly",
            "For each distribution type, define consistent forward and backward transformations:",
            "- Forward: Map trial values to internal continuous space (e.g., log(x) for log-uniform) before fitting the KDE.",
            "- Backward: When sampling, transform back and enforce domain constraints:",
            "  * DiscreteUniform: round and clip to [low, high] with step q.",
            "  * IntUniform: round to nearest multiple of step within [low, high].",
            "  * IntLogUniform: exponentiate, round, and clip to integer bounds.",
            "  * Categorical: use sampled indices directly.",
            "Verify that sampled values always lie in the valid domain.",
            "Step 4: Compute MI via sample-average (data-based estimator)",
            "Implement the simple estimator first:",
            "- Build three KDEs per parameter: p^(score), p^(param), and p^(param, score).",
            "- Evaluate log_pdf at each observed (param, score) pair.",
            "- Compute per-sample contributions: log p^(x,y) - log p^(x) - log p^(y).",
            "- Average these contributions to get the estimated mutual information for that parameter.",
            "Test on synthetic data where you know which parameters are important (e.g., simple functions where only some inputs influence the output). Check for:",
            "- Correct ranking of important vs unimportant parameters.",
            "- Occurrence of negative MI estimates and their frequency/magnitude.",
            "Step 5: Add Monte Carlo-based MI estimation if needed",
            "If the sample-average estimator is too noisy or frequently negative:",
            "- Implement Monte Carlo estimation:",
            "  * Sample (x, y) from the joint KDE p^(x,y) using the sample method.",
            "  * Evaluate log probabilities under the marginal KDEs and the joint KDE at these points.",
            "  * Estimate MI as the average of log p^(x,y) - log p^(x) - log p^(y) over the Monte Carlo samples.",
            "- Experiment with different n_MC values to trade off variance and runtime.",
            "Be aware that this can still produce biased or less discriminative estimates; validate empirically.",
            "Step 6: Validate against known or baseline importance methods",
            "Compare your MI-based importance rankings with established baselines (e.g., fANOVA, random forest feature importance, permutation importance) on multiple benchmark problems.",
            "Evaluate:",
            "- Stability: Do rankings change drastically when you rerun with different seeds or subsamples?",
            "- Consistency: Do obviously irrelevant parameters get low importance, and relevant ones get higher importance?",
            "- Calibration: Are MI values interpretable or at least monotonically correlated with other importance measures?",
            "Step 7: Diagnose instability and credibility problems",
            "If you observe negative MI or instability, investigate:",
            "- Bandwidth choice: Try different scaling factors for Scott's rule.",
            "- Prior kernel: Adjust or introduce a prior component to avoid overfitting to few samples.",
            "- Boundary effects: Ensure that truncation and CDF-based normalization are correct at parameter bounds.",
            "- Sample size: Evaluate performance as a function of number of trials.",
            "If Monte Carlo MI appears too flat or uninformative, examine whether KDE p^(x,y) is over-smoothed and whether you are effectively integrating over a distribution that nearly factorizes.",
            "Step 8: Decide on integration vs. postponement",
            "Before integrating the new evaluator into a public API:",
            "- Confirm that it provides clear advantages or complementary insights to existing importance evaluators.",
            "- Document any known limitations (e.g., negative values, high variance for small samples).",
            "- If behavior remains questionable, keep the code experimental and move the discussion to an issue instead of merging. Describe the observed problems and potential future directions.",
            "Step 9: Ensure deterministic and ordered outputs",
            "When returning importance scores:",
            "- Sort parameters by their importance score in descending order.",
            "- Use an OrderedDict or an ordered list of (param, score) pairs so that consumers can rely on the ordering.",
            "Step 10: Encapsulate Parzen logic for reuse",
            "Factor the Parzen estimator into its own module/class with a clean interface so that it can be reused by samplers (like TPE) and other metrics (like MI). This reduces duplication and keeps algorithmic changes localized."
        ]
    }
}