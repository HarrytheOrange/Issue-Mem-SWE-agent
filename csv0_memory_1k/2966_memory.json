{
    "search_index": {
        "description_for_embedding": "Fix for napari labels layer nD anisotropic painting when layer scale contains negative values. The bug came from using raw scale (including negative components) to normalize brush radius and cursor size, which broke brush geometry when axes were flipped. The fix normalizes using absolute scale values and adds tests for 3D painting with mixed positive/negative anisotropic scales.",
        "keywords": [
            "napari",
            "labels layer",
            "nD painting",
            "anisotropic painting",
            "negative scale",
            "axis flip",
            "sphere_indices",
            "brush size",
            "cursor size",
            "data_to_world transform",
            "np.abs scale",
            "geometry bug",
            "pytest parametrize list iterator"
        ]
    },
    "agent_memory": {
        "episodic_memory": "In this incident, painting in napari’s Labels layer failed when the layer had a negative scale in one or more dimensions (e.g. flipped axes with anisotropic voxel sizes). A prior PR (#2962) added anisotropic nD painting support but implicitly assumed all scale components were positive. The core bug lived in `sphere_indices(radius, scale)` where the code normalized the scale as `scale_normalized = scale / min(scale)`. When any component of `scale` was negative, `min(scale)` became negative and the normalization produced incorrect brush radii and index selection. Similarly, `_calculate_cursor_size` in `labels.py` computed `min_scale = min(scale[d] for d in dims_displayed)` without considering sign, leading to inconsistent cursor sizes when scales were negative.\n\nThe visible symptom: painting in a 3D labels layer with negative scale components either painted in the wrong shape/extent or not where expected. To reproduce and guard against regressions, a new test `test_paint_3d_negative_scale` was added, parameterized over combinations of positive and negative anisotropic scales (e.g. scale components `[-2, 2]`, `[-0.5, 0.5]`). The test constructs a 4D labels array (time + 3D), applies a mix of positive and negative scale and a translate, sets `n_edit_dimensions = 3` and a specific `brush_size`, paints at a known coordinate, and asserts that the label sum per time-slice is `[0, 95, 0]`, ensuring the brush footprint is correct and isolated to the intended frame regardless of scale sign.\n\nThe fix itself was straightforward: in `_labels_utils.sphere_indices`, the scale is first converted to absolute values, and normalization is done using the minimum of those absolute values:\n\n- Before: `scale_normalized = np.asarray(scale, dtype=float) / np.min(scale)`\n- After:  `abs_scale = np.abs(scale)` then `scale_normalized = np.asarray(abs_scale, dtype=float) / np.min(abs_scale)`\n\nIn `Labels._calculate_cursor_size`, the minimum scale across displayed dimensions is now computed using absolute values:\n\n- Before: `min_scale = np.min([scale[d] for d in self._dims_displayed])`\n- After:  `min_scale = np.min([abs(scale[d]) for d in self._dims_displayed])`\n\nAdditionally, the test’s `@pytest.mark.parametrize` call was updated to wrap `itertools.product` in `list(...)` to ensure pytest receives a concrete collection rather than a bare iterator.\n\nAfter these changes, painting with any combination of positive and negative anisotropic scales behaves correctly, and cursor size matches the effective voxel sizes in world space.",
        "semantic_memory": "1. **Absolute scale for geometric computations**: When working with geometric operations (e.g. brush radius, distance-based masks, kernel footprints) in coordinate-transformed spaces, scale values represent voxel/element spacing magnitude. If a scale can be negative (commonly used to encode axis flips or reflections in transforms), geometric computations should use the *absolute* scale values. Using the signed scale directly in radius/normalization (`min(scale)`, `radius / scale`) can invert or distort the geometry.\n\n2. **Separation of orientation and magnitude**: In a transformation pipeline, scale often bundles two concepts: magnitude (spacing) and orientation (sign / flip). Many algorithms care only about magnitude (e.g. isotropy/anisotropy, brush size, cursor radius) and should ignore orientation. Use `abs(scale)` for magnitude-based logic. Orientation should be handled separately via rotation/flip transforms rather than affecting the metric used for distance-based operations.\n\n3. **Normalization with potential negative values**: Any normalization step like `x / min(x)` or `x / max(x)` must consider sign. If negative values are allowed, the extremum may be negative, yielding confusing results (e.g. larger quantities mapped to smaller normalized values). For scales or other quantities representing distances or sizes, normalize by `min(abs(x))` or otherwise constrained positive quantities.\n\n4. **Brush and cursor size in transformed spaces**: In interactive tools (painting, selection, etc.), the user-facing cursor size and the internal brush footprint must both be consistent with the data-to-world transform. Cursor size should be derived from brush size in data coordinates multiplied by the *magnitude* of the scale factors in displayed dimensions. If scales are negative, ignore the sign when mapping brush size to cursor size.\n\n5. **Robust testing across transform variations**: Bugs involving transforms often appear only under specific combinations (anisotropic + negative scale, rotated axes, etc.). Parameterized tests that iterate over many combinations (e.g. all sign combinations of relevant scale components, and multiple anisotropy patterns) are a powerful way to guard against regressions. In Python/pytest, `itertools.product` over sets of positive and negative values yields a compact yet thorough test matrix.\n\n6. **Test expectations based on invariants, not exact shapes**: In this fix, rather than asserting exact voxel coordinates, the test asserts aggregate invariants (e.g. the sum of labels per frame equals `[0, 95, 0]`). This approach ensures that the correct region is painted and isolated to the intended dimension slice, while remaining resilient to small internal changes in index ordering.\n\n7. **Transform conventions influence downstream APIs**: Design decisions like allowing negative scale components in a transformation matrix must be propagated through all code paths that interpret `scale`. If some paths treat `scale` purely as spacing and others as a signed factor, inconsistencies appear. A best practice is to define a clear convention (e.g. scale = length, rotation/flip in a separate matrix) and centralize handling of sign/direction.",
        "procedural_memory": [
            "Step-by-step instructions on how to diagnose and fix similar issues.",
            "Step 1: Reproduce the issue under varying transform configurations.\n- Create a minimal data set (e.g. a small 3D image/labels array).\n- Apply transforms that include anisotropic scale and negative scale components (axis flips), possibly with translation.\n- Use the interactive tool (e.g. brush/painting) to observe whether the shape, position, or size of the effect is incorrect. Record the configurations where the behavior breaks.",
            "Step 2: Inspect how transforms and scales are used in geometry calculations.\n- Locate the code that computes geometric shapes (e.g. brush footprints, distance masks, kernels) and cursor sizes.\n- Look for operations like `radius / scale`, `min(scale)`, `max(scale)`, or similar normalization using the raw scale values.\n- Determine whether `scale` can be negative (e.g. because it includes axis flip semantics) from the transform pipeline or API documentation.",
            "Step 3: Separate magnitude and orientation.\n- Conceptually separate scale’s magnitude (spacing) from orientation (sign/flip).\n- Identify which computations depend purely on spacing (distance, radius, area, volume) and which depend on orientation.\n- For the magnitude-only computations, plan to use `abs(scale)` instead of the raw scale.",
            "Step 4: Update normalization and size calculations to use absolute values where appropriate.\n- Change normalization from using raw scale to absolute scale, e.g. `abs_scale = np.abs(scale); scale_normalized = abs_scale / np.min(abs_scale)`.\n- For any cursor or brush-size computation depending on `min(scale)` or similar, switch to `min(abs(scale))` or explicitly take `abs(scale[d])` for relevant dimensions.\n- Ensure that orientation-dependent logic (e.g. actual coordinate mapping) still uses the full signed transform if needed, but that distance-based metrics use magnitudes only.",
            "Step 5: Strengthen tests with parameterized coverage over scale sign and anisotropy.\n- Add tests that cover a matrix of scale combinations, e.g. `itertools.product([-s, s], ...)` for each dimension.\n- Use `pytest.mark.parametrize('scale', list(itertools.product(...)))` to ensure pytest has a concrete sequence of parameter values.\n- In each test, apply the relevant transform (scale + optional translate), perform the operation (painting, selection), and assert invariants such as:\n  - The affected slice(s) along a particular axis have the expected aggregate value (sum, count of changed voxels).\n  - Neighboring slices remain unmodified.",
            "Step 6: Validate behavior interactively and check regression implications.\n- After implementing the fix, manually verify the tool behavior with different transformations: all-positive scale, mixed positive/negative, highly anisotropic spacing.\n- Consider the broader architecture: if other components plan to absorb negative scale into rotation matrices or otherwise restructure transforms, confirm that using `abs(scale)` in geometric code is consistent with those plans.\n- Run the full test suite and confirm coverage on the affected modules remains high and the new tests pass.",
            "Step 7: Document transform assumptions.\n- Update internal docs or comments to clarify that:\n  - Negative scale components are allowed and represent axis flips.\n  - All geometry-/distance-based operations must use absolute scale values.\n- This reduces future reintroductions of similar bugs when transforms are refactored."
        ]
    }
}