{
    "search_index": {
        "description_for_embedding": "Home Assistant Osram Lightify light platform was rewritten to fix performance and correctness issues: broken throttling caused excessive bridge I/O, group states were derived in a confusing/incorrect way, and all devices were treated as full RGBW bulbs regardless of capabilities. The integration now uses python-lightify 1.0.7.2 with built-in throttling and change tracking, separates fast light-status polling from slower group-configuration polling, derives supported_features from each device's reported capabilities, and simplifies attribute handling to rely on the core Light entity behavior.",
        "keywords": [
            "osramlightify",
            "Osram Lightify",
            "Home Assistant",
            "light platform",
            "python-lightify",
            "performance",
            "throttling",
            "polling interval",
            "group state",
            "supported_features",
            "device capabilities",
            "bridge I/O",
            "update_all_light_status",
            "update_group_list"
        ]
    },
    "agent_memory": {
        "episodic_memory": "In this incident, the Home Assistant Osram Lightify integration had several interconnected issues. The original component performed expensive I/O on every update by always calling both `update_all_light_status()` and `update_group_list()` together, and it attempted to use Home Assistant's `util.Throttle` decorator but always invoked the updater with `no_throttle=True`, effectively disabling throttling. This led to many unnecessary network requests to the Lightify bridge and poor performance, especially since group and scene configuration rarely changes. Additionally, group entities' states were implemented in a confusing way (derived from the first light in the group) and unique IDs for groups were based on the list of member light IDs, which is not actually a stable or unique identifier in Lightify. On top of that, the integration treated all devices as if they were full RGBW + color temperature bulbs, ignoring each device's actual supported feature set.\n\nThe fix rewrote the Osram Lightify light platform almost from scratch while preserving backward compatibility where possible. The python-lightify dependency was upgraded from 1.0.6.1 to 1.0.7.2 to gain built-in throttling and change-tracking support. The bridge integration was redesigned around two separate update paths: `update_lights()` uses `bridge.update_all_light_status(interval_lightify_status)` to poll light status frequently, and `update_groups()` uses `bridge.update_group_list(interval_lightify_conf)` to refresh groups on a much slower schedule. These intervals are configurable via `interval_lightify_status` (default 5 seconds) and `interval_lightify_conf` (default 3600 seconds), while still allowing `scan_interval` to control HA-level polling. The code now uses python-lightify's `lights_changed()` and `groups_updated()` counters to detect whether anything actually changed, and individual entities only recompute their dynamic attributes when a change is reported.\n\nA new `Luminary` base class was introduced for both lights and groups. It separates static attributes (unique ID, supported features, effect list, min/max color temperature) from dynamic attributes (on/off state, brightness, color temperature, RGB color), and derives `supported_features` from the device's reported capabilities (`lum`, `temp`, `rgb`). Color and temperature attributes are now expressed through the standardized HA light properties (brightness 0–255, hs_color, color_temp in mireds), and the integration leverages the generic `Light` entity's `state_attributes` logic instead of re-implementing it. The random color effect is exposed only on RGB-capable devices via `effect_list` and `EFFECT_RANDOM`.\n\nGroup entities are now built from the library's group objects using their `idx()` for internal tracking and `lights()` membership, though the unique ID for groups intentionally remains the legacy value (a stringified list of light IDs) to avoid breaking existing installations, even though this is known to be a flawed identifier. The setup logic also respects configuration flags `allow_lightify_nodes` and `allow_lightify_groups` to control which entities are created. Overall, this refactor substantially reduces unnecessary network traffic, aligns the integration with device capabilities, and produces more accurate and maintainable entity behavior without user-visible breaking changes.",
        "semantic_memory": "This fix illustrates several general best practices for designing and refactoring device integrations, especially in polling-based home automation systems:\n\n1. **Leverage underlying library throttling and change tracking.** If the device SDK or library (here, python-lightify) provides built-in throttling, caching, or 'changed since' semantics (`lights_changed()`, `groups_updated()`), prefer that over implementing your own crude polling throttle. This can drastically reduce network I/O and avoid duplicated logic. A common antipattern is wrapping library calls in a generic throttle decorator and then unintentionally bypassing it (e.g., always calling with `no_throttle=True`).\n\n2. **Separate fast-changing dynamic data from slow-changing configuration.** Light on/off state and brightness usually need near real-time updates, while group or scene configuration changes rarely. Splitting updates into two paths with different intervals (status vs. configuration) can significantly reduce load on bridges and devices and improve perceived responsiveness.\n\n3. **Derive supported features from actual capabilities.** Do not assume all devices support the same features. Instead, query each device's capabilities (`supported_features()` or equivalent) and map them to platform-specific feature flags (`SUPPORT_BRIGHTNESS`, `SUPPORT_COLOR_TEMP`, `SUPPORT_COLOR`, `SUPPORT_EFFECT`, `SUPPORT_TRANSITION`). This prevents exposing controls that do not work for a given device and keeps UI and automation behavior accurate.\n\n4. **Reuse generic platform behavior where possible.** The Home Assistant `Light` entity already defines standard properties and `state_attributes` generation. Overriding this with custom logic often introduces bugs, inconsistencies, and maintenance overhead. It is better to implement the core properties (`is_on`, `brightness`, `hs_color`, `color_temp`, `supported_features`, etc.) correctly and rely on the base class to build the state payload.\n\n5. **Model entities with clear static vs. dynamic attributes.** A clean separation between static attributes (unique ID, supported features, min/max ranges) and dynamic attributes (current state, brightness, color) makes code simpler to reason about and update. Static attributes should be recomputed only when the underlying object changes; dynamic attributes should be updated only when the library reports a change.\n\n6. **Treat unique IDs as stable identifiers and avoid breaking them.** Even if the existing unique ID scheme is flawed (e.g., using the list of group members, which is neither unique nor stable), changing it is a breaking change for users because entity IDs, automations, and configurations may depend on it. When refactoring, either preserve the existing behavior or introduce a migration path.\n\n7. **Minimize per-entity remote calls in property getters.** All expensive I/O should live in shared update routines that refresh local caches, not in each entity property access. Entities should read from cached state, and a central update coordinator should be responsible for synchronizing the cache with the physical devices.\n\n8. **Be cautious with global or generic configuration knobs.** Reusing global options like `scan_interval` may seem convenient but can introduce tight coupling and hidden behavior. Sometimes it is clearer and safer to define component-specific configuration options (like `interval_lightify_status`, `interval_lightify_conf`) with well-documented semantics.\n\nThese patterns apply broadly to any integration that talks to hardware bridges or cloud APIs: use the library's change detection, split update frequencies by data type, expose only supported features, and centralize I/O to keep entities lightweight and responsive.",
        "procedural_memory": [
            "Step-by-step instructions on how to diagnose and fix similar issues.",
            "Step 1: Identify symptoms and bottlenecks\n- Look for signs of excessive I/O: slow UI updates, high CPU or network usage, or complaints about performance when many entities are present.\n- Inspect the integration's update logic: see how often it calls the underlying library or API, and whether expensive operations (like fetching configuration or group lists) are being done on every poll.",
            "Step 2: Review throttling and polling mechanisms\n- Check if the integration uses a generic throttling decorator or timer (e.g., a framework-provided `Throttle`).\n- Verify how the update function is actually called (e.g., are calls made with `no_throttle=True` or similar flags that bypass throttling?).\n- Confirm whether throttling is applied consistently across all code paths that trigger updates.",
            "Step 3: Inspect the underlying library's capabilities\n- Read the library/SDK documentation to see if it already supports:\n  - Rate limiting or throttling.\n  - Caching of results.\n  - Change tracking (e.g., timestamps, version counters, or 'dirty' flags).\n- Prefer using these library-level capabilities instead of re-implementing them in the integration.",
            "Step 4: Separate dynamic state polling from static/configuration updates\n- Categorize data into fast-changing (on/off, brightness, sensor values) and slow-changing (group membership, scenes, device metadata).\n- Introduce separate update routines and intervals for these categories (e.g., `update_status` every few seconds, `update_config` every minutes or hours).\n- Make the longer-interval configuration polling optional or less frequent by default if configuration rarely changes.",
            "Step 5: Introduce a central update function or coordinator\n- Implement a central function that performs bridge or API updates and returns a 'change marker' (timestamp or counter) indicating if anything changed during the last call.\n- Have each entity call this central updater in its `update()` method and only recompute its dynamic attributes when the marker has advanced.\n- Avoid placing I/O directly in entity property getters; properties should read from cached data populated by the central updater.",
            "Step 6: Derive supported features from device capabilities\n- For each device, query its capabilities via the library (e.g., `supported_features()` or equivalent flags).\n- Map these capabilities to the platform's feature flags (e.g., brightness, color temperature, RGB color, effects, transitions).\n- Use these flags to conditionally implement behavior and to expose only the controls that make sense for that device.",
            "Step 7: Align entity properties with platform conventions\n- Implement the standard properties expected by the platform (e.g., `is_on`, `brightness` 0–255, `hs_color`, `color_temp` in mireds for Home Assistant).\n- Let the platform's base entity class handle attribute serialization (`state_attributes`) when possible, instead of manually assembling state dictionaries.\n- Only override behavior when there is a strong reason (e.g., custom effects), and keep those overrides minimal.",
            "Step 8: Reassess group and aggregate entity semantics\n- For group entities, decide how their state should be derived (e.g., any member on => group on, average brightness, etc.).\n- Use the library's group constructs if available rather than manually approximating using a single member.\n- Choose unique IDs for groups that are stable and truly identify the group (e.g., a numeric index or bridge-specific ID), and document any backward-compatibility constraints.",
            "Step 9: Preserve or carefully migrate unique IDs\n- Before changing unique ID calculation, analyze how existing users might be impacted (entity renames, lost automations).\n- If a change is necessary, consider a migration path (e.g., mapping old IDs to new ones) or clearly mark the change as breaking and provide upgrade guidance.\n- If possible, retain the legacy ID even if it is imperfect, to avoid breaking existing setups.",
            "Step 10: Test and validate behavior\n- Add or adapt tests to cover different device capabilities (brightness-only, color-temp-only, RGB) and ensure `supported_features` and attributes behave correctly.\n- Manually test with a real bridge or simulated responses to confirm reduced network calls and correct, timely updates.\n- Verify that configuration options (polling intervals, group inclusion flags, etc.) behave as documented and that default values are sensible.",
            "Step 11: Document configuration and behavior\n- Update user-facing documentation to describe new configuration options, default values, and their effects on performance.\n- Explain any constraints (e.g., `scan_interval` relationships to custom intervals) and recommended settings for typical users versus power users.\n- Note any known limitations or intentionally preserved quirks (such as legacy unique ID behavior) so future maintainers understand the design trade-offs."
        ]
    }
}