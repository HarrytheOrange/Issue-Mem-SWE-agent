{
    "search_index": {
        "description_for_embedding": "Removal of the Home Assistant 'liveboxplaytv' integration (Orange Livebox Play TV) because it depended on web scraping of a third-party site (via BeautifulSoup/pyteleloisirs), which broke when the site changed and violated ADR-0004 (no web scraping). The fix is not to patch the scraper but to delete the integration, its dependencies, and associated ownership/coverage configuration.",
        "keywords": [
            "liveboxplaytv",
            "Orange Livebox Play TV",
            "Home Assistant",
            "media_player",
            "web scraping",
            "ADR0004",
            "pyteleloisirs",
            "BeautifulSoup",
            "integration removal",
            "breaking change",
            "requirements_all.txt",
            "manifest.json",
            "CODEOWNERS",
            "coverage configuration"
        ]
    },
    "agent_memory": {
        "episodic_memory": "In this incident, the Home Assistant integration `liveboxplaytv` (Orange Livebox Play TV) stopped working because the external website it scraped changed. The integration relied on HTML scraping via libraries like Beautiful Soup and `pyteleloisirs` to fetch program and channel metadata. This design violated Architecture Decision Record ADR-0004, which prohibits integrations based on web scraping of third-party sites due to inherent fragility and maintainability issues. Instead of attempting to repair the scraper, the maintainers decided to remove the integration entirely as a breaking change.\n\nThe pull request deleted the entire `homeassistant/components/liveboxplaytv` integration: `__init__.py`, `manifest.json`, and `media_player.py`. The `media_player.py` file previously implemented a `MediaPlayerDevice` that controlled the Livebox (power, volume, channel, play/pause) and enriched media info (program title, duration, remaining time, images) by scraping teleloisirs data through `pyteleloisirs`. The removal also updated the repository's meta-files: it removed the `liveboxplaytv` entry from `.coveragerc` (so its file is no longer excluded from coverage), removed the code owner mapping in `CODEOWNERS`, and dropped the dependencies `liveboxplaytv==2.0.3` and `pyteleloisirs==3.6` from `requirements_all.txt`. The associated documentation change is handled in a separate docs PR.\n\nThe root cause was that the underlying scraped site changed, breaking functionality that was already considered architecturally unacceptable per ADR-0004. The resolution was to treat this as an opportunity to enforce the architectural guideline: remove the non-compliant integration rather than perpetuate reliance on unstable scraping logic.",
        "semantic_memory": "This case illustrates a broader principle: integrations that rely on web scraping third-party sites are inherently fragile and often violate architectural guidelines in mature systems. When a platform defines ADRs (Architecture Decision Records) such as \"no web scraping\" (ADR-0004 in Home Assistant), adhering to them is more important than patching short-lived breakages.\n\nGeneralizable lessons:\n- Web scraping external websites for core integration functionality is a liability: HTML structures change, anti-bot mechanisms evolve, and legal/terms-of-service issues can arise. Architectures should favor stable, documented APIs or device protocols.\n- ADRs codify architectural decisions; once established, they should guide maintenance and triage. When a component conflicts with an ADR and breaks, the preferred response may be removal or re-architecture, not incremental fixes.\n- Removing an integration involves more than deleting its code: associated dependencies, code ownership, coverage configuration, and documentation must be consistently updated to avoid dead code, unused dependencies, and user confusion.\n- Breaking changes should be explicitly communicated (e.g., in release notes, via issue/PR templates) explaining what was removed, why (architectural violation, instability), and what users can do (e.g., use alternative integrations or APIs if available).\n- Feature richness (like scraped program metadata and thumbnails) should not override architectural integrity and reliability. If such richness can't be obtained through stable APIs, it may be better to ship a simpler but robust integration.\n\nMore abstractly, this case is a pattern where a previously accepted shortcut (scraping) is later deprecated by governance mechanisms (ADRs) and systematically removed when it becomes problematic, reinforcing long-term maintainability standards.",
        "procedural_memory": [
            "Step-by-step instructions on how to diagnose and fix similar issues.",
            "Step 1: Confirm the failure mode and its root cause\n- Observe user reports or failing tests indicating that an integration relying on external content (e.g., program listings, metadata) is broken.\n- Reproduce the issue locally to verify that the integration fails due to changes in an external website or undocumented behavior.\n- Inspect the integration’s code for dependencies on HTML scraping libraries (e.g., BeautifulSoup, pyteleloisirs) or brittle parsing of unstructured content.",
            "Step 2: Check architectural policies (ADRs) and project guidelines\n- Review existing Architecture Decision Records or equivalent documents to see if there is a policy regarding web scraping or similar practices.\n- If an ADR (like ADR-0004) explicitly prohibits web scraping-based integrations, confirm that the current integration is in violation.\n- Consider whether any stable, documented API or protocol can be used instead; if not, continued reliance on scraping is likely unacceptable.",
            "Step 3: Decide between patching vs. deprecating/removing\n- If the integration fundamentally depends on scraping and no compliant alternative exists, recognize that even a short-term fix will be fragile and policy-violating.\n- Discuss with maintainers whether the right course is to deprecate and remove the integration rather than patch it.\n- Document the rationale: architectural violation, ongoing maintenance burden, and fragility, rather than just the immediate breakage.",
            "Step 4: Implement integration removal cleanly\n- Delete the component package directory (e.g., `homeassistant/components/<integration_name>/`) including `__init__.py`, platform modules (such as `media_player.py`), and `manifest.json`.\n- Remove any references from coverage configuration (e.g., `.coveragerc`) so there are no references to now-deleted files.\n- Update `CODEOWNERS` to remove ownership entries for the deleted integration.\n- Remove integration-specific dependencies from global requirements files (e.g., `requirements_all.txt`, `requirements_test.txt`), including both the device library and any scraping/auxiliary libraries.\n- Ensure that any usage in tests, scripts, or sample configurations is removed or updated.",
            "Step 5: Update documentation and communicate the breaking change\n- Open or update documentation PRs to reflect that the integration is no longer available.\n- In the PR body or changelog, clearly describe:\n  - What has been removed (e.g., Orange Livebox Play TV integration).\n  - Why it was removed (web scraping dependency broke and violates ADR-0004).\n  - Any potential alternatives or migration advice if available.\n- Mark the change as breaking so end-users and integrators can adjust expectations.",
            "Step 6: Validate and merge\n- Run the project’s test suite to ensure removing the integration and its dependencies does not break unrelated modules.\n- Run any tooling required for manifest/requirements validation (e.g., `python3 -m script.hassfest`, `python3 -m script.gen_requirements_all`).\n- Address any CI failures due to missing references or unused dependencies and ensure the repository is in a consistent state before merging.",
            "Step 7: For future designs, avoid similar pitfalls\n- When designing new integrations, prioritize official APIs, documented protocols, and stable data sources.\n- Use ADRs to guide architectural choices from the start, avoiding patterns (like scraping) that are known to be fragile or disallowed.\n- If feature requirements seem to mandate scraping, reconsider the scope of the integration or engage with the upstream provider to obtain an official API instead."
        ]
    }
}