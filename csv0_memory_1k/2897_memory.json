{
    "search_index": {
        "description_for_embedding": "Optuna samplers SkoptSampler and PyCmaSampler were returning NumPy scalar types and wrong numeric types from sample_relative (e.g., np.floating or float for integer distributions). New shared tests for sample_relative across multiple samplers exposed the issue. The fix ensures sample_relative returns proper Python built-in types (float or int) consistent with distributions, and adds robust tests using OrderedDict and dummy estimators.",
        "keywords": [
            "Optuna",
            "sample_relative",
            "SkoptSampler",
            "PyCmaSampler",
            "CmaEsSampler",
            "TPESampler",
            "BoTorchSampler",
            "NumPy scalar",
            "np.floating",
            "np.integer",
            "type mismatch",
            "integer distribution",
            "IntUniformDistribution",
            "IntLogUniformDistribution",
            "CategoricalDistribution",
            "OrderedDict search_space",
            "integration.skopt",
            "integration.cma",
            "sampler tests"
        ]
    },
    "agent_memory": {
        "episodic_memory": "In this incident, the Optuna project extended its shared sampler test suite to cover the sample_relative method for multiple samplers (TPESampler with multivariate=True, CmaEsSampler, SkoptSampler, and PyCmaSampler). Previously, only sample_independent had generic tests, and each sampler that implemented sample_relative tended to test it in its own dedicated test file.\n\nWhen shared tests for sample_relative were added, they imposed two key expectations:\n1) Sampled values must lie within the distribution bounds or be valid categorical choices.\n2) Sampled values must be Python built-in types (int or float), not NumPy scalar types (np.floating/np.integer), and must obey the semantics of integer vs continuous distributions.\n\nTo implement these tests, the author introduced parametrize_relative_sampler in tests/samplers_tests/test_samplers.py and added three tests:\n- test_sample_relative_numerical: checks numeric distributions (Uniform, LogUniform, DiscreteUniform, IntUniform, IntLogUniform) for range correctness and type (float for continuous, int for integer distributions) and ensures no NumPy scalar types.\n- test_sample_relative_categorical: checks that categorical values come from the choices and that they are Python ints (no NumPy scalars).\n- test_sample_relative_mixed: checks mixed numerical + categorical search spaces for correct ranges/choices and types.\n\nThey used OrderedDict for search_space to preserve parameter order and aligned the style with existing sample_independent tests: create a study with the target sampler, call study.ask with the search_space once, tell the result, and then repeatedly call sample_relative via a helper function to gather multiple samples for vectorized assertions. For SkoptSampler, they configured the underlying skopt optimizer with base_estimator='dummy' and n_initial_points=1 to keep tests light and deterministic.\n\nThese tests exposed type issues in integration layers:\n- In optuna.integration.cma._to_optuna_params, for UniformDistribution and LogUniformDistribution, CMA-ES produced np.floating values. For UniformDistribution, they explicitly cast cma_param_value to float, and for LogUniformDistribution they used math.exp(cma_param_value), which yields a Python float, ensuring built-in numeric types are returned.\n- In optuna.integration.skopt.SkoptSampler.ask, the skopt optimizer returns NumPy scalars for many distributions. The code previously only did minimal postprocessing. The fix added:\n  * For UniformDistribution, LogUniformDistribution, DiscreteUniformDistribution: cast value = float(value) to convert np.floating to float.\n  * For DiscreteUniformDistribution: then apply value = value * distribution.q + distribution.low.\n  * For IntUniformDistribution: compute integer values using value = int(value * distribution.step + distribution.low) so the result is a Python int.\n  * For IntLogUniformDistribution: round and clamp to [low, high] and cast to int.\n\nAdditional type checks were added to the new tests to ensure that:\n- For numeric sample_relative tests, each returned value is not an instance of np.floating or np.integer.\n- For integer distributions (IntUniformDistribution, IntLogUniformDistribution), the result is a Python int; otherwise, for continuous numeric distributions, it is a Python float.\n- For categorical distributions, results are Python ints and valid choices.\n\nA side discussion arose about why BoTorchSampler was not included in the shared sampler tests. When locally added, BoTorchSampler showed issues: NaN handling in one test and OrderedDict assumptions in sample_relative. These were deemed out of scope for this PR, and a separate PR (#2928) was opened to address BoTorch-specific fixes before adding it to the generic sampler tests.\n\nAfter these changes, the new shared sample_relative tests passed, coverage increased slightly, and SkoptSampler/PyCmaSampler now conform to the type expectations enforced by both sample_independent and sample_relative tests.",
        "semantic_memory": "This fix highlights several generalizable lessons about sampling libraries, integration layers, and testing strategy:\n\n1. **Normalize external library types at boundaries**: Libraries like NumPy or other optimization backends often return specialized scalar types (np.float64, np.int64, etc.). Public APIs usually expect standard Python types. When writing integration code or wrappers (e.g., between an optimizer and a sampling API), add explicit conversions at the boundaries.\n\n2. **Respect distribution semantics in type conversions**: Different distributions have different natural value types:\n   - Uniform/LogUniform/DiscreteUniform: typically float outputs (even when discrete in step size, the domain is continuous-like, but may need rounding/quantization).\n   - IntUniform/IntLogUniform: must result in Python int values, not float, and especially not NumPy integer scalars.\n   - Categorical: must return one of the explicitly specified choices, which may be type-sensitive (e.g., ints vs strings). Returning a float 1.0 instead of int 1 can be semantically wrong.\n   Any integration/wrapper logic that transforms optimizer outputs back into parameter values must preserve these semantics.\n\n3. **Use ordered search spaces where order matters**: When sampling correlated parameters (sample_relative) or mapping parameter vectors to names, the order of parameters becomes important. Python dicts are ordered as of 3.7, but relying on that implicitly can lead to subtle issues, especially if the original code assumes an OrderedDict or must be compatible with older versions. Using collections.OrderedDict in tests and interfaces can make this requirement explicit and robust.\n\n4. **Centralize common tests across implementations**: Instead of having separate test suites per sampler, a parametrized generic test (e.g., test_sample_relative_* run against multiple sampler classes) ensures a consistent contract and quickly reveals discrepancies when adding new samplers or changing integrations.\n\n5. **Ensure type consistency between independent and relative sampling**: If an API offers both sample_independent and sample_relative, they should obey the same type and range contracts. Tests should assert this, preventing regressions where one path returns Python types and another returns NumPy scalars or mis-typed values.\n\n6. **Lightweight configurations for integration tests**: When using heavy external dependencies (skopt, CMA-ES, BoTorch), tests should configure them in \"dummy\" or minimal modes (e.g., base_estimator='dummy', small n_initial_points) to make tests fast and stable while still validating the integration logic.\n\n7. **Avoid leaking third-party numeric idiosyncrasies**: Downstream users should not have to care whether a value came from NumPy, scikit-optimize, CMA-ES, etc. Enforcing a clean, consistent type contract at the API boundary hides backend quirks and simplifies user code and type checking.\n\n8. **Tests should assert both value range and type**: Many bugs are about type semantics rather than just numeric ranges. It is worth asserting not only that values are within bounds or among choices, but also that they are of the expected Python type (int vs float) and not framework-specific types.",
        "procedural_memory": [
            "How to diagnose and fix type/contract issues in sampler integration layers similar to this case:",
            "Step 1: Identify the contract for sampler outputs.",
            "Determine what the public API promises for sample_independent and sample_relative: allowed distributions, expected value ranges, and crucially, expected Python types (e.g., float vs int, no NumPy scalar types). If this contract is not documented, infer it from existing tests and code for other samplers.",
            "Step 2: Write or extend generic tests that enforce the contract.",
            "Add parametrized tests that run the same sample_relative (and sample_independent) checks across multiple sampler implementations. For each distribution type:",
            "- Assert that values are within [low, high] or valid categorical choices.",
            "- Assert that numeric types are Python built-ins (int or float), not np.floating or np.integer.",
            "- Assert that integer distributions yield ints and continuous distributions yield floats.",
            "Use OrderedDict for search_space if mapping vectors to named parameters depends on ordering.",
            "Step 3: Run tests and observe which samplers fail.",
            "Execute the test suite to see which samplers or integration layers violate the contract. Note whether the failure is due to NumPy scalar types, wrong rounding, wrong value ranges, NaNs, or ordering assumptions.",
            "Step 4: Trace the data flow through integration/wrapper code.",
            "For failing samplers, inspect the code that transforms backend optimizer outputs into Optuna parameters (e.g., SkoptSampler.ask, CMA-ES _to_optuna_params, BoTorchSampler.sample_relative). Look for places where:",
            "- Optimizer returns NumPy scalars or arrays.",
            "- Parameters are converted from continuous indices to discrete/int values.",
            "- Log-space transformations (log / exp) are applied.",
            "Step 5: Normalize types at the boundaries.",
            "Introduce explicit conversions in the integration code so that outputs match the API contract:",
            "- For Uniform/LogUniform/DiscreteUniform: cast NumPy scalars to float (value = float(value)) before applying any transformations.",
            "- For IntUniform: compute the value from index/step and cast to int (value = int(value * step + low)).",
            "- For IntLogUniform: round, clamp to [low, high], and cast to int.",
            "- For log-based transforms (e.g., CMA-ES in log space): use math.exp to get a Python float from possibly NumPy inputs.",
            "Step 6: Maintain range and choice integrity.",
            "Ensure that after type conversions, values also respect distribution ranges and possible numerical edge cases:",
            "- Use rounding and clamping for integer distributions (e.g., min(max(value, low), high)).",
            "- For discrete uniform, ensure quantization is correct and does not drift outside the range due to rounding errors.",
            "- For categorical distributions, ensure that the mapping selects exactly one of the provided choices by index or lookup.",
            "Step 7: Re-run tests and refine.",
            "Run the test suite again. If certain tests still fail (e.g., due to ordering assumptions or NaNs), refine the logic:",
            "- Use OrderedDict where necessary to provide deterministic parameter order.",
            "- Replace heavy base estimators with dummy/cheap ones for tests.",
            "- Fix NaN handling by ensuring the backend optimizer is only called when sufficient prior data is present, or by handling startup phases explicitly.",
            "Step 8: Align sample_relative with sample_independent behavior.",
            "Compare the code and tests for sample_relative with those for sample_independent. Ensure that both paths share the same conversion and validation logic where appropriate, so that they cannot diverge in type or range behavior. Consider factoring out shared conversion utilities.",
            "Step 9: Document assumptions and contracts.",
            "Once the fixes are in place, document the expected behavior of sampler outputs, including type guarantees for each distribution. This helps future contributors maintain consistency and prevents regressions.",
            "Step 10: Plan for additional samplers (e.g., BoTorch).",
            "Before adding new samplers to the shared tests, run them locally with the generic tests and note any failures. If issues are discovered (e.g., reliance on OrderedDict, NaN values), handle them in separate focused PRs, then include the sampler in the common parametrized tests to keep coverage consistent."
        ]
    }
}