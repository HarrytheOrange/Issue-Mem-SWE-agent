{
    "search_index": {
        "description_for_embedding": "Optuna’s MLflowCallback gained integration tests verifying the `nest_trials` behavior. When `nest_trials=True` and there is an active MLflow run, each Optuna trial is logged as a child MLflow run tagged with `MLFLOW_PARENT_RUN_ID` and containing the expected params and metrics. When `nest_trials=False` and an MLflow run is already active, the callback is expected to fail with MLflow’s 'Run with UUID ... is already active.' error. These tests guard against regressions in nested MLflow run handling.",
        "keywords": [
            "Optuna",
            "MLflow",
            "MLflowCallback",
            "nest_trials",
            "nested MLflow runs",
            "MLFLOW_PARENT_RUN_ID",
            "active run exists",
            "Run with UUID is already active",
            "hyperparameter optimization logging",
            "integration test"
        ]
    },
    "agent_memory": {
        "episodic_memory": "This pull request did not change production code but added integration tests around Optuna’s MLflow integration to validate previously implemented behavior for `MLflowCallback(nest_trials=...)`. The first test, `test_nest_trials`, configures MLflow with a temporary file-based tracking URI and an experiment named after the Optuna study. It starts a parent MLflow run and then runs an Optuna study optimization with `MLflowCallback(tracking_uri=..., nest_trials=True)` for three trials. After optimization, it uses `MlflowClient` to list runs in the experiment and filters child runs by the presence of the `MLFLOW_PARENT_RUN_ID` tag. The test asserts:\n\n- The total number of runs is `n_trials + 1` (3 child trial runs + 1 parent run).\n- There are exactly `n_trials` child runs.\n- Each child run’s `MLFLOW_PARENT_RUN_ID` tag equals the parent run’s `run_id`.\n- Each child run logs the expected parameters (`x`, `y`, `z`) and metric (`value`).\n\nThis confirms that when `nest_trials=True`, the MLflow callback creates properly nested child runs per Optuna trial and logs params/metrics correctly.\n\nThe second test, `test_mlflow_callback_fails_when_nest_trials_is_false_and_active_run_exists`, verifies the failure path. It sets up MLflow similarly, creates an `MLflowCallback` with `nest_trials=False`, and an Optuna study. It then manually starts an active MLflow run via `mlflow.start_run()`, and inside that context, calls `study.optimize` with the callback. The test asserts that this call raises an exception with a message matching `\"Run with UUID \\w+ is already active.\"`, which is MLflow’s standard error when trying to start another run while one is active and nesting is not allowed. This ensures that the callback does not silently log into an existing run or create unintended nested runs when `nest_trials` is disabled, and that the underlying MLflow behavior is preserved. Together, these tests provide regression coverage for correct nested-run behavior and error handling in Optuna’s MLflow integration.",
        "semantic_memory": "When integrating hyperparameter optimization frameworks (like Optuna) with experiment tracking systems (like MLflow), two key behaviors must be clearly defined and tested:\n\n1. **Nested runs vs. top-level runs**: If the optimization is executed inside an existing MLflow run, and you want each trial logged as a separate run, you should explicitly use nested runs. In MLflow, nested runs are typically represented by setting `MLFLOW_PARENT_RUN_ID` on child runs. A higher-level controller (e.g., an Optuna callback) must:\n   - Start a new MLflow run for each trial when `nest_trials=True`.\n   - Tag each child run with the parent run’s ID so that tracking UIs and APIs can reconstruct the hierarchy.\n   - Ensure that all trial parameters and metrics are logged on the correct child run, not the parent.\n\n2. **Handling already active runs when nesting is disabled**: If `nest_trials` (or equivalent) is `False` and an MLflow run is already active, starting new runs for each trial is either invalid or ambiguous. The safest behavior is to fail fast, surfacing MLflow’s own error (e.g., \"Run with UUID ... is already active.\") rather than silently reusing the active run or attempting unsupported nesting. This makes misconfiguration obvious and avoids corrupting experiment logs.\n\n3. **Integration tests as contracts**: Adding integration tests that exercise both the successful nested case and the failure case with an active run effectively establishes a contract between the optimization framework and MLflow. These tests:\n   - Guard against regressions when MLflow or the integration code changes.\n   - Ensure that parameters and metrics are consistently logged across trials.\n   - Document expected behavior for contributors and users.\n\nOverall, a robust MLflow integration should: clearly expose a `nest_trials`-like configuration, use `MLFLOW_PARENT_RUN_ID` for child runs, validate state when a run is already active, and be backed by integration tests that hit the actual MLflow tracking APIs.",
        "procedural_memory": [
            "To diagnose and fix issues with nested MLflow runs in a hyperparameter optimization integration (e.g., Optuna’s MLflowCallback), follow these steps:",
            "Step 1: Reproduce the context with and without an active MLflow run.\n- Write (or run) a small script that:\n  - Sets `mlflow.set_tracking_uri` to a temporary or test tracking store.\n  - Sets an experiment via `mlflow.set_experiment`.\n  - Optionally starts a parent run with `mlflow.start_run()`.\n  - Runs your optimizer (e.g., `study.optimize`) with its MLflow callback, varying `nest_trials=True` and `nest_trials=False`.",
            "Step 2: Inspect created MLflow runs programmatically.\n- Use `from mlflow.tracking import MlflowClient` with the same tracking URI.\n- List experiments and obtain the relevant `experiment_id`.\n- Call `search_runs([experiment_id])` to retrieve all runs.\n- Partition runs into parent and child runs by checking for the `MLFLOW_PARENT_RUN_ID` tag in `run.data.tags`.",
            "Step 3: Verify nesting semantics when nesting is enabled.\n- When `nest_trials=True` and an outer `mlflow.start_run()` is active:\n  - Assert that the total number of runs is `num_trials + 1` (children + single parent).\n  - Assert that the number of child runs equals the number of trials.\n  - Assert that for each child run, `run.data.tags[MLFLOW_PARENT_RUN_ID]` equals the parent run’s `run_id`.\n  - Assert that each child run’s parameters and metrics match what your objective function logs (e.g., keys like `x`, `y`, `z` for params and `value` for metrics). If these checks fail, adjust the callback to start MLflow runs per trial and set the parent tag correctly.",
            "Step 4: Verify failure behavior when nesting is disabled and a run is active.\n- Start a run manually: `with mlflow.start_run():`.\n- Inside this context, call the optimizer with `nest_trials=False`.\n- Confirm that this raises an exception consistent with MLflow’s behavior, e.g., matching `\"Run with UUID \\w+ is already active.\"`.\n- If your integration does not raise and instead silently reuses or incorrectly nests runs, tighten the integration logic to either:\n  - Explicitly disallow this configuration and raise a clear error, or\n  - Explicitly support it by switching to nested runs when appropriate.",
            "Step 5: Encode expectations as integration tests.\n- Add tests similar to `test_nest_trials` and `test_mlflow_callback_fails_when_nest_trials_is_false_and_active_run_exists`:\n  - Use a temporary directory-based MLflow tracking URI.\n  - Configure experiments and studies.\n  - Run optimizations under the desired MLflow context.\n  - Assert on the number of runs, their tags (especially `MLFLOW_PARENT_RUN_ID`), and their params/metrics.\n- This ensures future changes in either the optimizer integration or MLflow do not break the expected behavior.",
            "Step 6: Document the behavior for users.\n- Clearly document what `nest_trials` (or equivalent) does:\n  - That `True` means each trial becomes a nested MLflow run under any active parent.\n  - That `False` requires no active MLflow run or will result in an error.\n- Encourage users to structure their MLflow runs accordingly when using the callback."
        ]
    }
}