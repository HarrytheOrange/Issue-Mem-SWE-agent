{
    "search_index": {
        "description_for_embedding": "CI workflows were installing PyTorch via a custom `-f https://download.pytorch.org/...` index with platform-specific CPU-only wheels in setup.py extras. This PR attempted to simplify installation by removing the `-f` option from all GitHub Actions workflows and unifying the torch/torchvision requirements to generic versions (e.g., `torch==1.8.0`), relying on default PyPI resolution. However, this caused example CI jobs to fail, likely due to large binary downloads exhausting disk space, so the PR was eventually closed without merging.",
        "keywords": [
            "pip",
            "PyTorch",
            "torch",
            "torchvision",
            "torchaudio",
            "GitHub Actions",
            "CI",
            "disk space",
            "large binaries",
            "custom index",
            "pip -f",
            "legacy-resolver",
            "setup.py extras_require",
            "optuna",
            "examples workflow",
            "integration tests"
        ]
    },
    "agent_memory": {
        "episodic_memory": "In this incident, the repository was using a custom PyTorch wheel index (`-f https://download.pytorch.org/whl/torch_stable.html`) and platform-specific CPU-only wheel specifiers in `setup.py` extras (e.g., `torch==1.8.0+cpu ; sys_platform!='darwin'`). The motivation behind the PR was to 'install large PyTorch package' and thereby remove the `-f` option and simplify the dependency definitions. The code changes:\n\n- In `.github/workflows/examples.yml`, the example job installation was changed from:\n  - `pip install --progress-bar off $(ls dist/*.tar.gz)[example] -f https://download.pytorch.org/whl/torch_stable.html`\n  to:\n  - `pip install --progress-bar off $(ls dist/*.tar.gz)[example]`\n\n- In `.github/workflows/tests-integration.yml`, integration and test dependencies were changed from using `--use-deprecated=legacy-resolver` and `-f`:\n  - `pip install --use-deprecated=legacy-resolver --progress-bar off .[tests]`\n  - `pip install --use-deprecated=legacy-resolver --progress-bar off .[integration] -f https://download.pytorch.org/whl/torch_stable.html`\n  to simpler invocations:\n  - `pip install --progress-bar off .[tests]`\n  - `pip install --progress-bar off .[integration]`\n\n- In `.github/workflows/coverage.yml`, the same simplification was applied: remove `--use-deprecated=legacy-resolver` and the `-f` torch index, leaving only standard `pip install --progress-bar off .[tests|optional|integration|codecov]`.\n\n- In `setup.py`, multiple extras (`example`, `integration`, and another extras group combining ML frameworks) previously specified platform-conditional CPU-only torch and torchvision wheels:\n  - `torch==1.8.0 ; sys_platform=='darwin'`\n  - `torch==1.8.0+cpu ; sys_platform!='darwin'`\n  - `torchvision==0.9.0 ; sys_platform=='darwin'`\n  - `torchvision==0.9.0+cpu ; sys_platform!='darwin'`\n\n  These were replaced by generic PyPI specs without platform qualifiers or `+cpu` suffixes:\n  - `torch==1.8.0`\n  - `torchvision==0.9.0`\n  (with `torchaudio==0.8.0` unchanged).\n\n- The examples workflow was also updated to run on pull requests (adding `pull_request: {}`) presumably to verify that the simplified installation works in PRs.\n\nAfter these changes, the example jobs on GitHub Actions started failing sporadically. A maintainer observed that failure logs for the skorch example showed issues around downloads. Another maintainer suspected that the failures were due to lack of disk space caused by the large torch binaries now being installed (potentially GPU-enabled wheels from PyPI instead of smaller CPU-only ones from the specified index). Because of these CI reliability issues and not having time to resolve them, the maintainer decided to close the PR without merging. The net result: the attempt to remove the `-f` PyTorch index and simplify torch-related requirements was abandoned due to CI resource constraints.",
        "semantic_memory": "This case illustrates several general patterns and best practices around Python dependency management and CI stability:\n\n1. **Large binary dependencies can break CI via resource limits**: Switching from CPU-only wheels or a custom wheel index to full, generic PyTorch wheels from PyPI significantly increases download size and disk usage. In constrained environments (e.g., GitHub-hosted runners), this can cause disk space exhaustion or timeouts during installation, especially in jobs that install many extras (tests, integrations, examples).\n\n2. **Custom indices and wheel variants exist for a reason**: Using `-f https://download.pytorch.org/whl/torch_stable.html` and platform-specific specifiers (including `+cpu` builds) may look messy, but they often ensure that the correct, smaller, or compatible binaries are installed. Removing these without a resource and compatibility analysis can introduce performance or stability regressions in CI.\n\n3. **Platform markers in `extras_require` can significantly affect what pip downloads**: Using markers like `sys_platform=='darwin'` vs `!= 'darwin'` to pick different wheel variants (GPU vs CPU, OS-specific builds) is a powerful tool, but simplifying them to a single generic requirement changes resolution behavior across all platforms.\n\n4. **CI workflows are tightly coupled to dependency choices**: Changes in `setup.py` dependencies often require corresponding changes in CI workflows (and vice versa). While the PR correctly updated the workflows to match the new dependency strategy (removing `-f` and the legacy resolver), it did not account for the impact on CI resource usage.\n\n5. **Test coverage tools are insensitive to infra failures**: Codecov reported no coverage change because the code itself didn't change in ways that affected test lines, but that obscures the fact that CI jobs failed due to environment/setup problems. Infra-related failures may not show up as coverage diffs, but they are critical for successful merges.\n\n6. **Conservative approach to infrastructure changes**: When modifying how heavyweight ML libraries (PyTorch, TensorFlow, etc.) are installed, particularly in a multi-job CI setup, it's often safer to test these changes in an isolated branch or job, measure disk usage and runtime, and roll them out incrementally. A seemingly minor change to a pip invocation (`-f` flag, resolver options) can have large downstream effects.\n\n7. **Running example suites in PRs is useful but costly**: Adding `pull_request` triggers for example workflows increases early detection of breakage due to dependency changes, but it also increases CI load. In this case, it quickly surfaced that the new installation strategy was problematic.\n\nOverall, the lesson is that dependency simplification and cleanup must be balanced against CI constraints, especially when large ML frameworks are involved. Removing custom indexes and platform markers should be validated in terms of compatibility, download size, install time, and CI resource availability.",
        "procedural_memory": [
            "Step-by-step strategy for diagnosing and handling similar issues (large ML dependencies causing CI failures):",
            "Step 1: Identify the symptom in CI logs.",
            "Inspect failing CI job logs to determine where failures occur. Check if they happen during `pip install` rather than during tests. Look for messages about disk space, timeouts, or `No space left on device` errors, or repeated download attempts for large wheels (e.g., torch, torchvision).",
            "Step 2: Compare dependency specifications before and after the change.",
            "Diff `setup.py`, `pyproject.toml`, or requirements files and CI workflow files. Pay particular attention to:\n- Added or removed `-f`/`--find-links` URLs.\n- Changes to version pins for large packages like torch.\n- Removal of platform markers (e.g., `; sys_platform=='darwin'`).\n- Changes to pip options (e.g., legacy resolver vs default resolver).",
            "Step 3: Determine what wheels are being installed now.",
            "Reproduce locally (or in a similar container) with `pip install -vvv` and the exact command used in CI. Observe which wheel URLs pip resolves for packages like `torch` and `torchvision`. Confirm whether you're now pulling larger GPU-enabled wheels from PyPI instead of smaller CPU-only wheels from a dedicated index.",
            "Step 4: Measure disk usage and install time.",
            "On a representative environment, run the CI install commands and monitor:\n- Total download size (e.g., via pip logs or network monitoring).\n- Disk usage before and after installation (`df -h`).\n- Installation time. This helps confirm whether resource limits are being exceeded.",
            "Step 5: Decide on a dependency strategy.",
            "Based on findings, choose one of the following or a combination:\n- Reintroduce the custom wheel index (`-f` or `--extra-index-url`) if it provides smaller or more appropriate wheels.\n- Reinstate platform-specific markers and `+cpu` variants to keep wheel sizes manageable.\n- Split extras and CI jobs so heavy dependencies are installed only where necessary (e.g., separate jobs for examples, integration tests, and coverage).",
            "Step 6: Update CI workflows in sync with dependency changes.",
            "Ensure GitHub Actions workflows (or equivalent CI configs) match the dependency strategy:\n- If using a custom index, include `-f` or `--extra-index-url` in the relevant `pip install` commands.\n- If changing extras, adjust which extras are installed in which jobs.\n- Remove legacy or unnecessary pip flags only after confirming that resolution and performance remain acceptable.",
            "Step 7: Add targeted verification jobs.",
            "If making a risky change (e.g., removing `-f` for torch), add or keep a dedicated workflow (like the examples workflow) that runs on PRs to verify these specific paths. Limit the scope so failures are easy to attribute to the dependency change.",
            "Step 8: Roll out changes incrementally.",
            "Instead of changing all workflows and dependency definitions at once, start with a single job or environment. Confirm stability and resource usage, then propagate the change to other jobs.",
            "Step 9: Provide clear documentation in the PR.",
            "When altering installation methods for large libraries, document in the PR description:\n- Why the change is being made.\n- Expected impact on wheel selection, disk usage, and CI runtime.\n- Any follow-up mitigation steps (e.g., increasing runner disk space, splitting jobs).",
            "Step 10: If failures persist and time is limited, revert or close.",
            "If CI remains unstable and the underlying resource issue cannot be quickly resolved, consider reverting the change or closing the PR to avoid prolonged breakage. Document the reason (e.g., 'large torch binaries exceed CI disk space') so future efforts can take this into account."
        ]
    }
}