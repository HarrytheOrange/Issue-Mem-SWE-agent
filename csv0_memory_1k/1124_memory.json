{
    "search_index": {
        "description_for_embedding": "CI was unintentionally installing CUDA-enabled PyTorch and torchvision because the dependency specifiers used `>=1.4.0+cpu`, which allowed pip to pick CUDA builds. The fix was to pin the CPU-only wheels exactly (`torch==1.4.0+cpu`, `torchvision==0.5.0+cpu`) in `extras_require` so CI installs the non-CUDA versions reliably.",
        "keywords": [
            "Optuna",
            "CI",
            "CircleCI",
            "PyTorch",
            "torch",
            "torchvision",
            "CUDA",
            "CPU-only",
            "pip dependency resolution",
            "version pinning",
            "extras_require",
            "setup.py",
            "torch>=1.4.0+cpu",
            "torch==1.4.0+cpu",
            "torchvision==0.5.0+cpu",
            "wrong package variant installed",
            "GPU wheel",
            "environment mismatch"
        ]
    },
    "agent_memory": {
        "episodic_memory": "In this incident, the project’s `setup.py` defined extra dependencies for integrations that included PyTorch and torchvision as `torch>=1.4.0+cpu` and `torchvision>=0.5.0+cpu`. On CircleCI, this resulted in pip resolving these constraints to CUDA-enabled wheels instead of the intended CPU-only ones. That led to CI trying to download and install large CUDA builds, which is unnecessary and potentially problematic on non-GPU CI machines.\n\nThe root cause was the use of a lower-bound version specifier (`>=`) with a local version suffix (`+cpu`). pip’s resolution logic, package metadata, and available wheels meant that the constraints did not reliably force selection of CPU-only wheels; instead, compatible CUDA variants could be chosen.\n\nThe fix was to pin the CPU-only PyTorch and torchvision versions exactly in `get_extras_require()` inside `setup.py`. The code was changed from:\n- `torch>=1.4.0+cpu` to `torch==1.4.0+cpu`\n- `torchvision>=0.5.0+cpu` to `torchvision==0.5.0+cpu`\n\nThese changes were applied in both relevant extras-groups (the ones including PyTorch) so that CI consistently installs the CPU-only variants, avoiding CUDA installation in the CI environment. The behavior was confirmed by comparing CI logs from a fork using `>=` versus `==`.",
        "semantic_memory": "When a project depends on libraries that have multiple build variants (e.g., CPU vs CUDA builds of PyTorch), loose version constraints such as `>=` can allow pip to select an unintended variant, especially in automated environments like CI where the hardware and drivers may not match the GPU builds.\n\nPinning to exact versions (e.g., `torch==1.4.0+cpu`) is a robust strategy in CI to:\n- Ensure reproducibility of the environment.\n- Control which variant (CPU vs GPU) is installed.\n- Avoid accidental installation of large or incompatible binary wheels.\n\nFor libraries that use local version identifiers or build tags (like `+cpu`), relying on range specifiers (`>=`, `<=`, `~=`) can interact poorly with pip’s resolution algorithm and wheel availability. In such cases, exact pins or carefully tested constraints are safer.\n\nMore generally, CI environments should: (1) pin or tightly constrain critical binary dependencies, (2) explicitly choose CPU-only variants when GPUs are not required, and (3) verify installation logs to ensure the correct wheels are being installed. This reduces flakiness, unexpected failures, and unnecessary resource usage in CI pipelines.",
        "procedural_memory": [
            "Diagnosing and fixing unintended CUDA (or wrong variant) installs in CI for packages like PyTorch:",
            "Step 1: Observe symptoms in CI",
            "- Look for unusually large downloads, long install times, or installation failures related to GPU drivers or CUDA in CI logs.",
            "- Check logs for lines indicating CUDA-enabled wheels (e.g., references to `cu101`, `cu102`, `cu11x` or similar) when you expect CPU-only installs.",
            "Step 2: Inspect dependency specifications",
            "- Open `setup.py`, `pyproject.toml`, `requirements.txt`, or equivalent to see how PyTorch / torchvision (or similar packages) are specified.",
            "- Note if you are using range specifiers like `>=` or `~=` combined with special build tags like `+cpu`.",
            "Step 3: Reproduce locally (optional but helpful)",
            "- In a clean virtual environment, run the same pip install command that CI is running.",
            "- Confirm which package variant is actually installed (`pip show torch`, or check wheel filenames in the logs).",
            "Step 4: Determine desired variant and version policy",
            "- Decide whether CI should use CPU-only builds (common when no GPU is available) and whether you require strict reproducibility.",
            "- If reproducibility and variant control are important, prefer exact version pins over loose constraints.",
            "Step 5: Pin to the correct variant",
            "- Change dependency specifiers from loose constraints to exact pins, for example:\n  - `torch>=1.4.0+cpu` → `torch==1.4.0+cpu`\n  - `torchvision>=0.5.0+cpu` → `torchvision==0.5.0+cpu`.",
            "- Apply this change consistently across all extras/groups that use these dependencies (e.g., in `get_extras_require()` for each integration).",
            "Step 6: Run CI again and verify",
            "- Re-run the CI pipeline and inspect the install logs to confirm that the CPU-only wheels are being installed and that CUDA-related downloads do not occur.",
            "- Ensure there are no new version conflicts introduced by the pins.",
            "Step 7: Generalize as a practice",
            "- For any library with multiple binary variants (CPU vs GPU, different backends, etc.), establish a CI policy to pin exact versions and explicitly choose the intended variant.",
            "- Consider creating separate extras or requirement files for CPU vs GPU setups to avoid ambiguity (e.g., `requirements-cpu.txt`, `requirements-gpu.txt`)."
        ]
    }
}