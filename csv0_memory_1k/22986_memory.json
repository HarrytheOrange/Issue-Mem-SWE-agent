{
    "search_index": {
        "description_for_embedding": "Home Assistant PR that refactors the old 'pollen' sensor into a new 'iqvia' component using the pyiqvia library. It generalizes from pollen.com-only allergy data to broader IQVIA data (allergy, asthma, disease), centralizes data fetching in the component, shares data between sensors via a dispatcher, and introduces a breaking configuration change from 'pollen' to 'iqvia' with a new YAML schema.",
        "keywords": [
            "homeassistant",
            "iqvia",
            "pollen.com",
            "pollen",
            "pyiqvia",
            "pypollencom",
            "sensor component refactor",
            "shared data coordinator",
            "async_track_time_interval",
            "dispatcher",
            "breaking change",
            "configuration schema change",
            "InvalidZipError",
            "external API integration"
        ]
    },
    "agent_memory": {
        "episodic_memory": "This PR replaces the legacy 'pollen' sensor platform with a new 'iqvia' component in Home Assistant. Previously, the integration used the pypollencom library and was scoped to Pollen.com allergies. The author realized that IQVIA is the parent provider for multiple related sites (pollen.com, flustar.com, etc.), so they generalized the integration.\n\nThe core changes:\n- The directory `homeassistant/components/pollen` was renamed to `homeassistant/components/iqvia`, including `__init__.py`, `manifest.json`, and `sensor.py`.\n- The manifest was updated to use the `iqvia` domain and documentation path, and to swap dependency `pypollencom==2.2.3` for `pyiqvia==0.2.0` (with numpy already present via requirements files).\n- The configuration model changed from a pure sensor platform with a `pollen:` key to a top-level component keyed by `iqvia:`. In `configuration.yaml` the new schema is:\n  \n  ```yaml\n  iqvia:\n    zip_code: \"12345\"\n    monitored_conditions: [...]\n  ```\n\nData architecture changes:\n- A new `const.py` file defines the domain (`'iqvia'`), data keys (`DATA_CLIENT`, `DATA_LISTENER`), dispatcher topic (`TOPIC_DATA_UPDATE`), all sensor type identifiers (e.g., `TYPE_ALLERGY_FORECAST`, `TYPE_ASTHMA_INDEX`, `TYPE_DISEASE_FORECAST`), and the `SENSORS` mapping from type -> (class name, friendly name, icon).\n- `__init__.py` was rewritten to turn IQVIA into a proper component:\n  - It defines `CONFIG_SCHEMA` using the `iqvia` domain, requiring `zip_code` and optional `monitored_conditions` drawn from `SENSORS`.\n  - On `async_setup`, it creates an aiohttp session, instantiates a `pyiqvia.Client` and an `IQVIAData` object, calls `async_update` once to validate the zip code and seed data, and handles `IQVIAError` (posting a persistent notification and aborting setup) and `InvalidZipError` at data-fetch time.\n  - If setup succeeds, it stores `IQVIAData` under `hass.data[DOMAIN][DATA_CLIENT]`, triggers `discovery.load_platform` for `sensor`, and sets up a periodic refresh using `async_track_time_interval`. The refresh callback calls `iqvia.async_update()` and then broadcasts `TOPIC_DATA_UPDATE` via the dispatcher.\n- `IQVIAData` encapsulates all communication with the external IQVIA service. Its `async_update` method selectively calls the appropriate pyiqvia endpoints based on which sensor types are configured (allergy forecast/historic/current, asthma forecast/historic/current, disease forecast). Each call is wrapped by `_get_data`, which catches `IQVIAError` and logs the error while leaving other data intact. If an `InvalidZipError` occurs, it logs and clears `self.data` entirely.\n- `IQVIAEntity` (a new base entity) lives in `__init__.py` and is used by all IQVIA sensors. It holds common state: attributes (including attribution string), icon, type, name, zip code, and current state. Availability is based on the presence of the required data key in `IQVIAData.data` (with special handling for index sensors that rely on aggregated `TYPE_ALLERGY_INDEX` or `TYPE_ASTHMA_INDEX`). It registers a dispatcher listener for `TOPIC_DATA_UPDATE` so that all entities update when data is refreshed centrally.\n\nSensor layer changes (`sensor.py`):\n- The sensor platform no longer defines its own config schema or instantiates its own client. Instead, `async_setup_platform` reads the shared `IQVIAData` instance from `hass.data[DOMAIN][DATA_CLIENT]` and creates sensors for every `iqvia.sensor_types` entry, using the central `SENSORS` mapping. It uses the zip code stored inside `IQVIAData`.\n- The previous `BaseSensor` has been removed; sensor classes now derive from `IQVIAEntity` imported from the component.\n- `ForecastSensor`, `HistoricalSensor`, and `IndexSensor` each implement `async_update` by reading from `self._iqvia.data` and computing averages or selecting the appropriate forecast period. They also populate attributes like `ATTR_LOCATION`, `ATTR_RATING`, `ATTR_LEVEL`, `ATTR_TREND`, and—for allergy forecasts—`ATTR_OUTLOOK` and `ATTR_SEASON` from the `TYPE_ALLERGY_OUTLOOK` data. Trend is derived via a helper function that computes a moving average over time.\n- The low-level data class `IQVIAData` that had been previously located in `sensor.py` was moved into `__init__.py` and adapted (no more Throttle; refresh is now controlled entirely by the component timer/dispatcher).\n\nHousekeeping:\n- `requirements_all.txt` and `requirements_test_all.txt` were updated to remove `pypollencom` and add `pyiqvia` under the iqvia section. The `numpy` dependency remains but is now attributed to the IQVIA component instead of pollen.\n- `.coveragerc` was updated to omit the new `homeassistant/components/iqvia/*` paths from coverage reporting and to remove the old pollen sensor path.\n- `CODEOWNERS` was updated to add `homeassistant/components/iqvia/* @bachya` and remove the `pollen` ownership entry.\n\nOverall, the incident here is a deliberate, breaking refactor: the 'pollen' sensor was replaced by 'iqvia', configuration and domain names changed, and responsibility for data fetching and fan-out was moved from per-sensor logic into a centralized component with a shared data coordinator design.",
        "semantic_memory": "This change illustrates several general integration patterns and best practices relevant to building and refactoring Home Assistant components and, more broadly, any event-driven integration that consumes an external API:\n\n1. **Generalizing a narrow integration to a parent provider**:\n   - When a sensor/integration is tied to a single endpoint (e.g., pollen.com) but the actual provider (IQVIA) offers multiple related datasets (allergy, asthma, disease/flu), it is preferable to model the integration around the provider (iqvia) instead of the individual site (pollen). This allows multiple feature sets to share configuration, network clients, and error handling.\n   - Renaming from `pollen` to `iqvia` while expanding capabilities ensures the name reflects the true data source and leaves room for future features.\n\n2. **Centralized data coordinator pattern**:\n   - Instead of each sensor instance creating its own client and performing its own polling, a shared data object (`IQVIAData`) is created at the component level.\n   - The component schedules periodic updates (via `async_track_time_interval` or an equivalent scheduler) and updates the shared data object once per interval.\n   - Entities subscribe to a dispatcher topic (`TOPIC_DATA_UPDATE`) and react when new data is available. This minimizes duplicate network traffic and ensures all entities stay in sync.\n   - Availability logic in entities is based on the presence of relevant keys in the shared data.\n\n3. **Selective API calls based on configured sensors**:\n   - `IQVIAData.async_update` determines which API endpoints to call by inspecting the configured sensor types. Only the necessary data is requested, reducing load on the external API and speeding updates.\n   - This pattern is useful for any integration with many possible endpoints or metrics; it avoids pointless calls when a user isn’t using those metrics.\n\n4. **Resilient external API error handling**:\n   - The code distinguishes between fatal and non-fatal errors:\n     - `InvalidZipError` indicates misconfiguration and results in logging and clearing all data, since further calls with the same ZIP are pointless.\n     - Other `IQVIAError` instances during individual calls are logged, but the integration continues servicing other types; partial data is still delivered.\n   - `_get_data` encapsulates the try/except logic per request and ensures the data dict always has a key (with `{}`) even on failure. This prevents `KeyError` in consumers and simplifies downstream code.\n   - On initial setup, if any `IQVIAError` occurs when first seeding `IQVIAData`, the component surfaces a persistent notification and aborts setup. This helps users correct configuration quickly.\n\n5. **Separating concerns: infrastructure vs. presentation**:\n   - Component (`__init__.py`): configuration schema, client instantiation, shared data management, scheduling, dispatcher wiring, and base entity (`IQVIAEntity`).\n   - Sensor platform (`sensor.py`): translation of raw data into entity state and attributes, relying solely on the shared data object and base entity.\n   - Constants (`const.py`): domain name, data keys, sensor type identifiers, and the `SENSORS` mapping (entity class name, friendly name, icon). This improves discoverability and makes it easy to add new sensor types.\n\n6. **Breaking configuration changes and migration**:\n   - The integration changes its domain (`pollen` -> `iqvia`) and configuration root key. This is a breaking change and is documented accordingly.\n   - Having a clear example configuration and documentation PR helps users migrate.\n   - Internally, all references to the old domain and dependency are updated, including manifest, requirements, coverage config, and codeowners.\n\n7. **Modern Home Assistant integration practices**:\n   - Defining dependencies in `manifest.json` and `requirements_all.txt` instead of `REQUIREMENTS` variables in code.\n   - Using `async_*` methods throughout, aiohttp sessions from `aiohttp_client.async_get_clientsession`, and dispatcher/event helpers instead of manual threading or polling.\n   - Using `unique_id` to generate stable, domain-friendly entity IDs based on the configured ZIP code and sensor type.\n\nThese patterns are broadly applicable to any system where many related metrics are retrieved from one external API and exposed as multiple entities/resources. Centralizing IO and sharing results via an event bus/dispatcher improves performance, reliability, and code clarity.",
        "procedural_memory": [
            "Step-by-step approach to refactoring a narrow sensor integration into a generalized component with shared data and a new configuration schema:",
            "Step 1: Identify the true provider and scope of data",
            "  - Review the existing integration to see if it is tied to a single endpoint (e.g., pollen.com) when the backing provider (e.g., IQVIA) offers multiple datasets or services (allergy, asthma, disease).",
            "  - Decide on a provider-level domain name (e.g., 'iqvia') that can support expanded capabilities.",
            "Step 2: Rename the integration and update metadata",
            "  - Move the component directory to the new domain name (e.g., `components/pollen` -> `components/iqvia`).",
            "  - Update `manifest.json` with the new `domain`, `name`, and documentation URL.",
            "  - Replace old third-party dependencies (e.g., `pypollencom`) with new ones (e.g., `pyiqvia`) in `manifest.json`, `requirements_all.txt`, and `requirements_test_all.txt`.",
            "  - Update CODEOWNERS and any coverage configuration (`.coveragerc`) to refer to the new path instead of the old one.",
            "Step 3: Centralize constants and sensor type definitions",
            "  - Create a `const.py` file containing the domain, any shared data keys, dispatcher topics, and a mapping of sensor type identifiers to their entity class name, human-readable name, and icon (`SENSORS`).",
            "  - Define well-named constants for all sensor types (e.g., `TYPE_ALLERGY_FORECAST`, `TYPE_ASTHMA_INDEX`, `TYPE_DISEASE_FORECAST`).",
            "Step 4: Introduce a configuration schema and component-level setup",
            "  - In `__init__.py`, define `CONFIG_SCHEMA` using the component domain (e.g., `iqvia:`) and required options such as `zip_code` and `monitored_conditions` based on the `SENSORS` mapping.",
            "  - Implement `async_setup(hass, config)` to:\n    - Read configuration for the domain.\n    - Create an aiohttp session via Home Assistant helpers.\n    - Instantiate the external API client and a shared data coordinator object (e.g., `IQVIAData`).\n    - Perform an initial `async_update` to validate configuration and ensure data can be retrieved.",
            "Step 5: Implement a shared data coordinator",
            "  - In the component, define a class (e.g., `IQVIAData`) that:\n    - Holds the external client and the set of sensor types requested.\n    - Exposes a `data` dictionary for all retrieved data.\n    - Implements `_get_data(method, key)` to wrap each external API call, catching provider-specific errors (e.g., `IQVIAError`), logging them, and ensuring `data[key]` is always set (possibly to `{}` on error).\n    - Implements `async_update` to call only those external endpoints that correspond to the configured sensor types, and to handle fatal errors (e.g., `InvalidZipError`) by logging and resetting `data`.",
            "Step 6: Schedule periodic updates and use a dispatcher",
            "  - In `async_setup`, schedule periodic refreshes using a scheduler like `async_track_time_interval` and a configurable scan interval.",
            "  - In the refresh callback, call `await iqvia.async_update()` and then broadcast a dispatcher signal (e.g., `TOPIC_DATA_UPDATE`).",
            "  - Store the `IQVIAData` instance and the listener/unsubscribe handle in `hass.data[DOMAIN]` for use by platforms and for cleanup if needed.",
            "Step 7: Create a base entity class tying entities to shared data",
            "  - Implement a base entity (e.g., `IQVIAEntity`) in `__init__.py` that:\n    - Stores references to the shared data object, kind/type, name, icon, and zip code.\n    - Implements `available` based on presence of the necessary keys in the shared data dict (with special handling for composite types like daily indices).\n    - Provides `device_state_attributes`, attribution, `unique_id` (derived from zip code and sensor type), and common unit of measurement, if applicable.\n    - Registers a dispatcher listener in `async_added_to_hass` so that all entities update when `TOPIC_DATA_UPDATE` is dispatched.",
            "Step 8: Simplify the sensor platform to use the shared data",
            "  - In `sensor.py`, remove per-platform configuration schemas and client creation; instead, retrieve the shared data object from `hass.data[DOMAIN][DATA_CLIENT]` in `async_setup_platform`.",
            "  - For each configured sensor type (from `iqvia.sensor_types` or equivalent), instantiate the appropriate entity class (`ForecastSensor`, `HistoricalSensor`, `IndexSensor`, etc.) using the `SENSORS` mapping and the zip code stored in the shared data object.",
            "  - Ensure sensor classes subclass the base `IQVIAEntity` and only focus on transforming raw data into state and attributes, not on networking or scheduling.",
            "Step 9: Implement type-specific update logic in entities",
            "  - For forecast entities:\n    - Pull `Location` data from the appropriate key in the shared data dict.\n    - Compute averages, determine rating levels, and compute trends (e.g., via a moving average helper). \n    - For special cases like allergy forecasts, also read outlook and season from additional data keys and expose them via attributes.",
            "  - For historical and index entities:\n    - Select the correct subset of data based on the sensor type (today/tomorrow/yesterday, etc.).\n    - Compute averages and trends similarly.\n    - Guard against missing data by returning early if the relevant data is `None` or empty.",
            "Step 10: Handle initial setup errors and surface them to users",
            "  - On initial `async_setup`, wrap creation and initial update of the shared data coordinator in a try/except that catches provider-specific errors.\n  - For configuration errors (e.g., invalid zip code), log a clear error and show a persistent notification advising the user to fix configuration and restart.\n  - For transient API issues, you may choose to let the component initialize and rely on the periodic refresh and logging to recover.",
            "Step 11: Communicate and document breaking changes",
            "  - Update documentation to reflect the new component domain (`iqvia` instead of `pollen`), configuration schema, and available sensors.\n  - Mark the change as breaking in release notes and provide a concrete migration snippet from the old configuration to the new one.\n  - Ensure all references to the old domain in code, tests, coverage configuration, and maintainers metadata are updated or removed."
        ]
    }
}