{
    "search_index": {
        "description_for_embedding": "Home Assistant neato integration tests were performing real I/O (login to Neato/Vorwerk via pybotvac). The fix refactors NeatoHub vendor selection and updates tests to mock pybotvac Account and raise NeatoLoginException to simulate failures. New tests verify config entry creation from YAML, synchronization between configuration.yaml and config entries, and correct handling when a new configuration is invalid.",
        "keywords": [
            "Home Assistant",
            "neato integration",
            "pybotvac",
            "NeatoHub",
            "config entry",
            "configuration.yaml",
            "I/O in tests",
            "network calls in tests",
            "mocking external services",
            "NeatoLoginException",
            "Account",
            "Vorwerk",
            "vendor selection",
            "async_setup_component",
            "MockConfigEntry"
        ]
    },
    "agent_memory": {
        "episodic_memory": "In this change set, the Home Assistant neato integration had tests that inadvertently performed real I/O by using the actual pybotvac Account and vendor classes (Neato/Vorwerk), which could trigger real network logins during tests. To address this, the integration code and tests were adjusted.\n\nOn the integration side, async_setup_entry previously instantiated NeatoHub with both the Account class and a vendor class (Neato or Vorwerk) injected from outside:\n\n  NeatoHub(hass, entry.data, Account, Neato/Vorwerk)\n\nThis was refactored so that NeatoHub now only receives Account and decides internally which vendor to use:\n\n  async_setup_entry: hass.data[NEATO_LOGIN] = NeatoHub(hass, entry.data, Account)\n\nInside NeatoHub.__init__, vendor selection is now based on the config's CONF_VENDOR field:\n\n  if self.config[CONF_VENDOR] == \"vorwerk\": self._vendor = Vorwerk()\n  else: self._vendor = Neato()\n\nThis makes the hub behavior more consistent and easier to test without passing vendor classes around.\n\nOn the test side (tests/components/neato/test_init.py), several improvements were made:\n\n1. New configuration variants were introduced:\n   - VALID_CONFIG (Neato, valid username/password)\n   - DIFFERENT_CONFIG (Vorwerk, different credentials)\n   - INVALID_CONFIG (still present but not used in updated tests)\n\n2. Fixtures were introduced/renamed to explicitly mock the external login logic:\n   - config_flow fixture: patches \"homeassistant.components.neato.config_flow.Account\" to return True, simulating a successful config flow login without network access.\n   - hub fixture: patches \"homeassistant.components.neato.Account\" to return True, simulating a successful hub login during component setup.\n\n3. Tests were expanded and clarified:\n   - test_no_config_entry: Verifies that setting up the neato component without any YAML config works and returns True.\n   - test_create_valid_config_entry: Verifies that when VALID_CONFIG is present in configuration.yaml, a new config entry is created with the correct username, password, and vendor fields. This uses both config_flow and hub fixtures to avoid I/O.\n   - test_config_entries_in_sync: Adds a MockConfigEntry with VALID_CONFIG, then runs async_setup_component with the same VALID_CONFIG and ensures the existing entry remains unchanged (in sync case).\n   - test_config_entries_not_in_sync: Adds a MockConfigEntry with DIFFERENT_CONFIG (different credentials and vendor), then runs async_setup_component with VALID_CONFIG. The test asserts that after setup completes, the config entry has been updated to match VALID_CONFIG, confirming that the integration resynchronizes when configuration.yaml and the stored entry differ.\n   - test_config_entries_not_in_sync_error: Simulates the case where an existing config entry is VALID_CONFIG, but configuration.yaml now provides DIFFERENT_CONFIG and the login with the new config fails. Instead of patching a custom try_login method on NeatoConfigFlow, the test now patches the external dependency:\n\n       with patch(\"homeassistant.components.neato.config_flow.Account\", side_effect=NeatoLoginException()):\n           assert not async_setup_component(...)\n\n     This raises NeatoLoginException during config flow login, causing setup to fail. The test then asserts that the existing config entry remains unchanged (username/password/vendor stay as in VALID_CONFIG), confirming that a failed update does not corrupt or replace the working entry.\n\nOverall, the incident was about eliminating real network I/O from tests, clarifying the vendor selection logic in NeatoHub, and strengthening tests around config entry synchronization and error handling when new configuration credentials are invalid.",
        "semantic_memory": "Generalizable insights from this change:\n\n1. **Avoid real I/O in tests**: Tests should not perform real network calls, device communication, or file system operations if avoidable. Instead, patch external libraries or boundary points with mocks or fakes. In this case, tests previously triggered real pybotvac Account logins; the fix was to patch Account in both the integration module and its config_flow module.\n\n2. **Patch at the integration boundary, not internal details**: Mocks are most robust when applied at the boundary to external dependencies rather than to internal methods. The change moved from patching a specific config flow method (`NeatoConfigFlow.try_login`) to patching the pybotvac `Account` object itself with a return value or an exception. This way, tests remain valid even if the integration’s internal implementation changes, as long as the external dependency contract stays similar.\n\n3. **Use exceptions from external libraries to simulate failures**: When simulating error paths, raise the real exception types provided by the external library (e.g., `NeatoLoginException`) instead of inventing custom error tokens. This exercises the integration’s real error-handling logic and keeps tests aligned with actual runtime behavior.\n\n4. **Centralize configuration-based behavior inside the domain logic**: NeatoHub was refactored to determine vendor (Neato vs Vorwerk) based on configuration internally instead of requiring the caller to supply the vendor class. Centralizing such logic improves cohesion and reduces the complexity of constructing the object in tests and production code.\n\n5. **Test config entry and YAML synchronization thoroughly**: For systems that support both configuration.yaml and config entries, it is important to test:\n   - The creation of a config entry from YAML.\n   - The behavior when YAML and existing entries are in sync (no changes performed).\n   - The behavior when they are not in sync and an update is needed.\n   - The behavior when an attempted update fails (e.g., login error) and how the system should preserve or roll back existing entries.\n\n6. **Use helper utilities for configuration entries**: Home Assistant provides `MockConfigEntry`, `async_setup_component`, and `async_block_till_done()` to test async configuration flows and integration setup. Leveraging these utilities allows realistic yet fully controlled testing of the lifecycle of integrations without actual side effects.\n\n7. **Separate fixtures for different layers of behavior**: The test file uses distinct fixtures to mock account behavior at different layers (config_flow vs hub). This makes it clear which part of the system is being exercised in each test and prevents accidental coupling between unrelated behaviors.",
        "procedural_memory": [
            "To diagnose and fix tests that perform unwanted I/O or have fragile config entry behavior, follow these steps:",
            "Step 1: Identify I/O sources in tests",
            " - Scan tests for direct use of external SDKs, network clients, device APIs, or real file operations.",
            " - In this case, tests were indirectly causing network login by allowing the neato integration to instantiate the real pybotvac Account.",
            " - Use stack traces or logging (if needed) to confirm when tests hit the network or devices.",
            "Step 2: Locate integration boundaries to patch",
            " - Determine where the application code interacts with the external library (e.g., `homeassistant.components.neato.Account` and `homeassistant.components.neato.config_flow.Account`).",
            " - Prefer patching these integration points rather than deeply internal methods or class internals.",
            "Step 3: Replace real external calls with mocks",
            " - Use `unittest.mock.patch` to replace external objects with test doubles.",
            "   Example: `with patch(\"homeassistant.components.neato.Account\", return_value=True): ...`",
            " - For configuration flows, patch the corresponding path as well: `with patch(\"homeassistant.components.neato.config_flow.Account\", return_value=True): ...`",
            " - Ensure these patches are provided as pytest fixtures so multiple tests can reuse them consistently.",
            "Step 4: Simulate both success and failure paths using real exception types",
            " - For successful flows, set `return_value` on the mocked object (e.g., `Account` returns a truthy object indicating login success).",
            " - For failure paths, set `side_effect` to raise the real library exceptions (e.g., `NeatoLoginException`) so the integration’s error handling is exercised realistically.",
            "   Example: `with patch(\"homeassistant.components.neato.config_flow.Account\", side_effect=NeatoLoginException()): ...`",
            "Step 5: Refactor domain logic to be easier to test",
            " - If constructing core classes requires injecting many low-level dependencies (like vendor classes), consider moving configuration-based decisions into the class itself.",
            " - Example: In NeatoHub, use the configuration’s vendor field (`CONF_VENDOR`) to internally select `Neato()` vs `Vorwerk()` instead of passing vendor classes from the outside.",
            " - This reduces duplication and simplifies test setup.",
            "Step 6: Add tests covering config entry lifecycle",
            " - Use `MockConfigEntry` to simulate existing entries: `MockConfigEntry(domain=NEATO_DOMAIN, data=CONFIG).add_to_hass(hass)`.",
            " - Use `async_setup_component` with a YAML-like config dict to simulate configuration.yaml input.",
            " - Call `await hass.async_block_till_done()` to ensure all async tasks complete before asserting.",
            " - Verify cases:",
            "   * No config entry exists: a valid YAML config should create a new entry with expected fields.",
            "   * Config entry and YAML in sync: setup should succeed and not alter the entry.",
            "   * Config entry and YAML out of sync: setup should update or replace the entry to match YAML.",
            "   * Update failure due to login error: setup should fail and the existing valid entry should remain unchanged.",
            "Step 7: Assert on configuration state after setup",
            " - After setup, call `entries = hass.config_entries.async_entries(DOMAIN)` and assert on:",
            "   * The number of entries (e.g., one entry exists).",
            "   * The data fields (username, password, vendor) match the expected configuration.",
            "   * The component setup return value (`True` or `False`) matches expected success/failure semantics.",
            "Step 8: Keep tests and fixtures descriptive and aligned with behavior",
            " - Name fixtures based on their purpose (e.g., `config_flow` for config flow login mocking, `hub` for hub login mocking).",
            " - Use configuration constants (VALID_CONFIG, DIFFERENT_CONFIG) to clearly express test intent when verifying sync vs non-sync scenarios."
        ]
    }
}