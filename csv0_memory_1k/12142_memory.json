{
    "search_index": {
        "description_for_embedding": "Home Assistant SQL sensor platform that exposes SQL query results as sensors. The implementation uses SQLAlchemy, validates and shares a DB connection via recorder defaults, enforces a safe LIMIT 1 on queries, handles SQLAlchemyError exceptions gracefully, logs connection/query issues instead of crashing, and supports templates, additional attributes, and configurable scan intervals.",
        "keywords": [
            "Home Assistant",
            "sql sensor",
            "homeassistant.components.sensor.sql",
            "SQLSensor",
            "sqlalchemy",
            "CONF_DB_URL",
            "DEFAULT_URL",
            "DEFAULT_DB_FILE",
            "sessionmaker",
            "scoped_session",
            "SQLAlchemyError",
            "database connection validation",
            "sensor update error handling",
            "configuration schema",
            "scan_interval"
        ]
    },
    "agent_memory": {
        "episodic_memory": "This pull request adds a new SQL-based sensor platform to Home Assistant and iteratively hardens it. Initially, a basic sensor was created that used SQLAlchemy to connect to a database using a db_url, executed a query to derive the sensor state, and exposed the result and row data as attributes. Early versions created a new engine and sessionmaker in each sensor instance and raised generic exceptions when a query returned no results. The db_url was required and hardcoded separately from the recorder component.\n\nDuring review, the implementation was reworked to integrate better with Home Assistant conventions and to be more robust:\n- The configuration schema was implemented using voluptuous, defining 'queries' (each with name, query, column, optional unit_of_measurement, and optional value_template) and a db_url. Initially db_url was required; later it was made optional and, if omitted, falls back to the recorder's DEFAULT_URL and DEFAULT_DB_FILE.\n- The code was refactored to import CONF_DB_URL, DEFAULT_URL, and DEFAULT_DB_FILE from homeassistant.components.recorder, ensuring consistent DB configuration between the SQL sensor and the recorder.\n- At setup time, the platform now creates a SQLAlchemy engine and a single scoped_session factory and runs a dummy 'SELECT 1;' query to validate db_url. If the connection or test query fails (any SQLAlchemyError), an error is logged and the platform aborts setup instead of partially initializing broken sensors.\n- The validated scoped_session is passed into each SQLSensor instance instead of the raw db_url, so all sensors share the same underlying connection configuration and do not recreate engines.\n- The SQLSensor constructor normalizes queries by appending 'LIMIT 1;' if the user did not specify a LIMIT, to avoid unbounded fetches when only a single row is meaningful as state.\n- The sensor's update method now wraps execution in a try/except around SQLAlchemyError: if the query fails, it logs the error and returns without updating the state, preventing crashes. If the query executes but yields no non-None data for the specified column, it logs an error and returns False instead of raising.\n- The session is explicitly closed after each update.\n- Value templates (CONF_VALUE_TEMPLATE) have hass injected at setup, and are used to post-process the retrieved column value when present.\n- The default state is initialized to None instead of STATE_UNKNOWN, aligning with Home Assistant's base Entity default behavior.\n- Tests were added to verify behavior, using an in-memory SQLite database ('sqlite://') instead of a file-based 'sqlite:///test.db'. The test config runs a simple 'SELECT count(*) value FROM sqlite_master;' query and asserts that the resulting sensor state is '0'.\n\nThe PR discussion clarifies that query frequency is controlled by Home Assistant's standard 'scan_interval' option, like other polling-based entities, and that documentation was added in the separate docs repository.",
        "semantic_memory": "Generalizable lessons from this work:\n\n1. Centralized database configuration and reuse:\n- When multiple components access the same application database, they should share configuration (e.g., URL format, default DB file) from a single source instead of hardcoding their own defaults. This avoids drift and ensures that changes to the DB location or structure propagate consistently.\n- Creating a single SQLAlchemy engine and scoped_session at platform setup and passing a session factory into entities is more efficient and avoids redundant connections, especially when multiple sensors rely on the same DB.\n\n2. Validate external resources at setup:\n- For components that depend on external resources (databases, APIs, devices), validate the connection during setup. Here, a simple 'SELECT 1;' is executed to confirm db_url is valid and reachable.\n- If the validation fails, log a clear error and abort setup rather than creating half-functional entities. This produces faster, clearer failure modes for users and avoids runtime errors during regular updates.\n\n3. Defensive database query execution:\n- Wrap all DB operations in try/except blocks for the provider-specific error types (e.g., SQLAlchemyError). Log meaningful context (query string and error message), and fail gracefully without crashing the entire integration.\n- Handle empty result sets explicitly. If a query returns no rows or the target column is None, log a warning/error rather than raising an untyped exception. The entity can leave state unchanged or mark itself as unavailable, depending on platform conventions.\n\n4. Avoid unbounded queries for single-value sensors:\n- Sensors typically represent a single value. If users provide arbitrary SQL, enforce a safe upper bound such as 'LIMIT 1' when appropriate to prevent fetching unbounded result sets unnecessarily.\n- Small transformations like appending 'LIMIT 1;' when no LIMIT is present can significantly reduce load on the DB while still matching user expectations.\n\n5. Correct use of configuration schemas and templates:\n- Use a structured schema (voluptuous) to validate complex configuration: lists of queries, per-query fields (name, query, column, unit, template), and optional or required keys. This catches misconfiguration early.\n- When value templates are used in a templating framework that relies on context (like Home Assistant's Jinja2 templates), remember to attach the main application context (e.g., template.hass = hass) before rendering.\n\n6. Error-handling and logging strategy for sensors:\n- Sensors should not raise generic exceptions during update; instead, they should log errors and skip or gracefully degrade. This keeps the background scheduler stable while still surfacing issues.\n- Logging messages should include enough context for debugging (query, db_url) but avoid leaking sensitive data like credentials in URLs.\n\n7. Testing database-backed components:\n- For unit tests, use ephemeral, in-memory databases (e.g., SQLite in-memory) to avoid filesystem dependencies and to ensure tests are deterministic and isolated.\n- Simple queries against system tables (like sqlite_master) can verify connectivity and basic behavior without requiring a full schema.\n\n8. Polling frequency as configurable behavior:\n- For polling sensors that query expensive resources like databases, reuse the platform's existing polling controls (e.g., scan_interval) instead of inventing custom frequency settings. This keeps UX consistent and reduces complexity.\n",
        "procedural_memory": [
            "How to design and harden a database-backed sensor or similar polling integration:",
            "Step 1: Define a clear configuration schema using a validation library. Include required fields such as query, column name, and any identifiers (e.g., sensor name). Add optional fields like unit_of_measurement and value_template. Group multiple queries as a list if you need multiple sensors per platform instance.",
            "Step 2: Centralize and reuse database configuration. If the larger application already has a DB configuration (e.g., a recorder or ORM module), import constants like CONF_DB_URL, DEFAULT_URL, or default DB filenames from there rather than redefining them.",
            "Step 3: At platform setup, resolve the db_url: either using the configured value or falling back to a shared default (such as DEFAULT_URL.format(hass_config_path=...)). Do not create engines inside each entity; instead, create one SQLAlchemy engine and a scoped_session or connection pool at setup.",
            "Step 4: Validate the database connection early. After creating the engine/session factory, open a session and run a trivial query (e.g., SELECT 1;). If this raises a SQLAlchemyError, log an error stating that the DB_URL is invalid or unreachable, and abort platform setup. This prevents half-working entities.",
            "Step 5: Pass the validated session factory into each entity's constructor. Entities should store a reference to the sessionmaker/scoped_session rather than the raw URL, so they reuse the same pooled connection settings defined at setup.",
            "Step 6: Normalize the user-provided queries to suit the sensor’s data model. For single-value sensors, ensure the query only returns a single row by appending 'LIMIT 1;' if no LIMIT is present. This protects the DB and avoids unnecessary data transfer.",
            "Step 7: In the entity's update method, handle DB operations defensively. Wrap session creation and execute() calls in a try/except for SQLAlchemyError. On error, log a message with the query string and the exception message, then return without raising.",
            "Step 8: Read the desired column from the result row identified by configuration (e.g., r[column_name]). Copy any additional columns into device attributes if that’s useful. If no rows are returned or the desired column is None, log a warning/error and return without raising; optionally set the state to a special unavailable/unknown value per framework conventions.",
            "Step 9: If templating is supported, ensure the template objects have access to the application context (e.g., template.hass = hass) and render the column value through the template. Use a safe rendering method that can handle JSON or missing data gracefully (such as async_render_with_possible_json_value(data, None)).",
            "Step 10: Always close sessions after use. After processing results, call sess.close() in a finally block or after the loop to ensure proper cleanup and avoid connection leaks.",
            "Step 11: Expose the polling frequency via the platform’s existing mechanism (e.g., scan_interval) rather than creating custom timers. Document how often the sensor updates and how users can adjust it.",
            "Step 12: Write tests using an in-memory or test-specific database. In tests, configure the sensor with a sqlite:// or similar ephemeral DB URL and run simple queries against built-in tables to verify that setup, update, and state/attribute mapping work. Avoid dependencies on external DB servers or persistent data.",
            "Step 13: Ensure logging messages do not leak sensitive information (such as raw credentials in db_url). When logging db_url, strip or mask credentials if necessary.",
            "Step 14: Review entity defaults. Initialize state to the framework’s expected default (often None) and rely on the base entity behavior rather than introducing conflicting sentinel values (e.g., mixing STATE_UNKNOWN and None) unless explicitly needed."
        ]
    }
}